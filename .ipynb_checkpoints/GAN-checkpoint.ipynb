{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ganetwork import GAN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "ds = datasets.load_iris()\n",
    "X, y = minmax_scale(ds.data), ds.target\n",
    "\n",
    "generator = Sequential([\n",
    "    Dense(input_dim=10, output_dim=20),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=10),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=X.shape[1]),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "discriminator = Sequential([\n",
    "    Dense(input_dim=X.shape[1], output_dim=20),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=10),\n",
    "    Activation('tanh'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gan = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, d_loss: 0.662497, g_loss: 0.711230\n",
      "Epoch 1, d_loss: 0.669854, g_loss: 0.714208\n",
      "Epoch 2, d_loss: 0.668793, g_loss: 0.698090\n",
      "Epoch 3, d_loss: 0.690137, g_loss: 0.692856\n",
      "Epoch 4, d_loss: 0.671251, g_loss: 0.692016\n",
      "Epoch 5, d_loss: 0.677245, g_loss: 0.693314\n",
      "Epoch 6, d_loss: 0.685528, g_loss: 0.719723\n",
      "Epoch 7, d_loss: 0.689980, g_loss: 0.697437\n",
      "Epoch 8, d_loss: 0.676851, g_loss: 0.732507\n",
      "Epoch 9, d_loss: 0.690935, g_loss: 0.687885\n",
      "Epoch 10, d_loss: 0.690414, g_loss: 0.699371\n",
      "Epoch 11, d_loss: 0.686825, g_loss: 0.697411\n",
      "Epoch 12, d_loss: 0.694498, g_loss: 0.705855\n",
      "Epoch 13, d_loss: 0.705983, g_loss: 0.705174\n",
      "Epoch 14, d_loss: 0.697491, g_loss: 0.696895\n",
      "Epoch 15, d_loss: 0.703889, g_loss: 0.682717\n",
      "Epoch 16, d_loss: 0.703287, g_loss: 0.704068\n",
      "Epoch 17, d_loss: 0.706799, g_loss: 0.681106\n",
      "Epoch 18, d_loss: 0.701999, g_loss: 0.692879\n",
      "Epoch 19, d_loss: 0.716645, g_loss: 0.697442\n",
      "Epoch 20, d_loss: 0.715151, g_loss: 0.698208\n",
      "Epoch 21, d_loss: 0.711687, g_loss: 0.691323\n",
      "Epoch 22, d_loss: 0.708835, g_loss: 0.681455\n",
      "Epoch 23, d_loss: 0.706027, g_loss: 0.686148\n",
      "Epoch 24, d_loss: 0.711803, g_loss: 0.689816\n",
      "Epoch 25, d_loss: 0.708825, g_loss: 0.688519\n",
      "Epoch 26, d_loss: 0.708944, g_loss: 0.692646\n",
      "Epoch 27, d_loss: 0.705959, g_loss: 0.682900\n",
      "Epoch 28, d_loss: 0.709550, g_loss: 0.687957\n",
      "Epoch 29, d_loss: 0.708525, g_loss: 0.692390\n",
      "Epoch 30, d_loss: 0.704968, g_loss: 0.691389\n",
      "Epoch 31, d_loss: 0.706188, g_loss: 0.694766\n",
      "Epoch 32, d_loss: 0.704214, g_loss: 0.691391\n",
      "Epoch 33, d_loss: 0.704026, g_loss: 0.696663\n",
      "Epoch 34, d_loss: 0.701966, g_loss: 0.696332\n",
      "Epoch 35, d_loss: 0.700009, g_loss: 0.695876\n",
      "Epoch 36, d_loss: 0.700340, g_loss: 0.693757\n",
      "Epoch 37, d_loss: 0.697762, g_loss: 0.698524\n",
      "Epoch 38, d_loss: 0.696564, g_loss: 0.690637\n",
      "Epoch 39, d_loss: 0.701329, g_loss: 0.701087\n",
      "Epoch 40, d_loss: 0.693554, g_loss: 0.704662\n",
      "Epoch 41, d_loss: 0.692690, g_loss: 0.692520\n",
      "Epoch 42, d_loss: 0.687485, g_loss: 0.706941\n",
      "Epoch 43, d_loss: 0.688438, g_loss: 0.689769\n",
      "Epoch 44, d_loss: 0.694504, g_loss: 0.716459\n",
      "Epoch 45, d_loss: 0.689895, g_loss: 0.696121\n",
      "Epoch 46, d_loss: 0.686081, g_loss: 0.713453\n",
      "Epoch 47, d_loss: 0.687824, g_loss: 0.708808\n",
      "Epoch 48, d_loss: 0.694546, g_loss: 0.720947\n",
      "Epoch 49, d_loss: 0.686147, g_loss: 0.711224\n",
      "Epoch 50, d_loss: 0.683063, g_loss: 0.707270\n",
      "Epoch 51, d_loss: 0.690732, g_loss: 0.682173\n",
      "Epoch 52, d_loss: 0.690743, g_loss: 0.716457\n",
      "Epoch 53, d_loss: 0.691125, g_loss: 0.696151\n",
      "Epoch 54, d_loss: 0.686274, g_loss: 0.725393\n",
      "Epoch 55, d_loss: 0.691353, g_loss: 0.701651\n",
      "Epoch 56, d_loss: 0.694883, g_loss: 0.707077\n",
      "Epoch 57, d_loss: 0.691285, g_loss: 0.714883\n",
      "Epoch 58, d_loss: 0.687696, g_loss: 0.701071\n",
      "Epoch 59, d_loss: 0.692304, g_loss: 0.684924\n",
      "Epoch 60, d_loss: 0.693174, g_loss: 0.682132\n",
      "Epoch 61, d_loss: 0.700853, g_loss: 0.706621\n",
      "Epoch 62, d_loss: 0.687891, g_loss: 0.677874\n",
      "Epoch 63, d_loss: 0.697078, g_loss: 0.716326\n",
      "Epoch 64, d_loss: 0.703948, g_loss: 0.695915\n",
      "Epoch 65, d_loss: 0.699363, g_loss: 0.683845\n",
      "Epoch 66, d_loss: 0.699551, g_loss: 0.715343\n",
      "Epoch 67, d_loss: 0.698226, g_loss: 0.703846\n",
      "Epoch 68, d_loss: 0.713652, g_loss: 0.702007\n",
      "Epoch 69, d_loss: 0.709295, g_loss: 0.700229\n",
      "Epoch 70, d_loss: 0.711900, g_loss: 0.673224\n",
      "Epoch 71, d_loss: 0.714504, g_loss: 0.685648\n",
      "Epoch 72, d_loss: 0.713335, g_loss: 0.677056\n",
      "Epoch 73, d_loss: 0.700010, g_loss: 0.694049\n",
      "Epoch 74, d_loss: 0.710571, g_loss: 0.697675\n",
      "Epoch 75, d_loss: 0.711685, g_loss: 0.690785\n",
      "Epoch 76, d_loss: 0.714176, g_loss: 0.667250\n",
      "Epoch 77, d_loss: 0.725215, g_loss: 0.688976\n",
      "Epoch 78, d_loss: 0.709824, g_loss: 0.694368\n",
      "Epoch 79, d_loss: 0.715073, g_loss: 0.678611\n",
      "Epoch 80, d_loss: 0.723951, g_loss: 0.705040\n",
      "Epoch 81, d_loss: 0.721376, g_loss: 0.707488\n",
      "Epoch 82, d_loss: 0.720615, g_loss: 0.691223\n",
      "Epoch 83, d_loss: 0.723844, g_loss: 0.678487\n",
      "Epoch 84, d_loss: 0.720224, g_loss: 0.672182\n",
      "Epoch 85, d_loss: 0.734749, g_loss: 0.699585\n",
      "Epoch 86, d_loss: 0.730819, g_loss: 0.685341\n",
      "Epoch 87, d_loss: 0.727914, g_loss: 0.686527\n",
      "Epoch 88, d_loss: 0.727541, g_loss: 0.684136\n",
      "Epoch 89, d_loss: 0.729817, g_loss: 0.702305\n",
      "Epoch 90, d_loss: 0.724386, g_loss: 0.691709\n",
      "Epoch 91, d_loss: 0.721877, g_loss: 0.695240\n",
      "Epoch 92, d_loss: 0.728822, g_loss: 0.691820\n",
      "Epoch 93, d_loss: 0.719649, g_loss: 0.690981\n",
      "Epoch 94, d_loss: 0.722340, g_loss: 0.706240\n",
      "Epoch 95, d_loss: 0.720836, g_loss: 0.696832\n",
      "Epoch 96, d_loss: 0.721011, g_loss: 0.701178\n",
      "Epoch 97, d_loss: 0.717125, g_loss: 0.703696\n",
      "Epoch 98, d_loss: 0.717722, g_loss: 0.699054\n",
      "Epoch 99, d_loss: 0.717784, g_loss: 0.706606\n",
      "Epoch 100, d_loss: 0.713383, g_loss: 0.703849\n",
      "Epoch 101, d_loss: 0.711171, g_loss: 0.702743\n",
      "Epoch 102, d_loss: 0.713021, g_loss: 0.708541\n",
      "Epoch 103, d_loss: 0.712633, g_loss: 0.707318\n",
      "Epoch 104, d_loss: 0.711146, g_loss: 0.713518\n",
      "Epoch 105, d_loss: 0.709793, g_loss: 0.716617\n",
      "Epoch 106, d_loss: 0.700694, g_loss: 0.712452\n",
      "Epoch 107, d_loss: 0.706669, g_loss: 0.706957\n",
      "Epoch 108, d_loss: 0.707588, g_loss: 0.713110\n",
      "Epoch 109, d_loss: 0.699458, g_loss: 0.720099\n",
      "Epoch 110, d_loss: 0.699621, g_loss: 0.714682\n",
      "Epoch 111, d_loss: 0.700694, g_loss: 0.711299\n",
      "Epoch 112, d_loss: 0.696766, g_loss: 0.723178\n",
      "Epoch 113, d_loss: 0.698237, g_loss: 0.704995\n",
      "Epoch 114, d_loss: 0.702363, g_loss: 0.702160\n",
      "Epoch 115, d_loss: 0.703805, g_loss: 0.715005\n",
      "Epoch 116, d_loss: 0.699943, g_loss: 0.710549\n",
      "Epoch 117, d_loss: 0.700765, g_loss: 0.719160\n",
      "Epoch 118, d_loss: 0.688616, g_loss: 0.712004\n",
      "Epoch 119, d_loss: 0.693282, g_loss: 0.719115\n",
      "Epoch 120, d_loss: 0.690691, g_loss: 0.720267\n",
      "Epoch 121, d_loss: 0.694644, g_loss: 0.692486\n",
      "Epoch 122, d_loss: 0.689036, g_loss: 0.730275\n",
      "Epoch 123, d_loss: 0.687511, g_loss: 0.701704\n",
      "Epoch 124, d_loss: 0.684792, g_loss: 0.718241\n",
      "Epoch 125, d_loss: 0.688888, g_loss: 0.732635\n",
      "Epoch 126, d_loss: 0.690603, g_loss: 0.718429\n",
      "Epoch 127, d_loss: 0.694333, g_loss: 0.713656\n",
      "Epoch 128, d_loss: 0.684707, g_loss: 0.726298\n",
      "Epoch 129, d_loss: 0.693138, g_loss: 0.730258\n",
      "Epoch 130, d_loss: 0.692082, g_loss: 0.707210\n",
      "Epoch 131, d_loss: 0.694678, g_loss: 0.697611\n",
      "Epoch 132, d_loss: 0.682064, g_loss: 0.706057\n",
      "Epoch 133, d_loss: 0.702072, g_loss: 0.687284\n",
      "Epoch 134, d_loss: 0.692862, g_loss: 0.724641\n",
      "Epoch 135, d_loss: 0.683349, g_loss: 0.709740\n",
      "Epoch 136, d_loss: 0.684411, g_loss: 0.717487\n",
      "Epoch 137, d_loss: 0.691739, g_loss: 0.705953\n",
      "Epoch 138, d_loss: 0.690856, g_loss: 0.717347\n",
      "Epoch 139, d_loss: 0.689247, g_loss: 0.684394\n",
      "Epoch 140, d_loss: 0.681623, g_loss: 0.674596\n",
      "Epoch 141, d_loss: 0.691559, g_loss: 0.695784\n",
      "Epoch 142, d_loss: 0.679867, g_loss: 0.713023\n",
      "Epoch 143, d_loss: 0.691616, g_loss: 0.689485\n",
      "Epoch 144, d_loss: 0.677890, g_loss: 0.718765\n",
      "Epoch 145, d_loss: 0.683983, g_loss: 0.694879\n",
      "Epoch 146, d_loss: 0.684463, g_loss: 0.677852\n",
      "Epoch 147, d_loss: 0.691225, g_loss: 0.689263\n",
      "Epoch 148, d_loss: 0.688029, g_loss: 0.708104\n",
      "Epoch 149, d_loss: 0.682369, g_loss: 0.675821\n",
      "Epoch 150, d_loss: 0.683236, g_loss: 0.702564\n",
      "Epoch 151, d_loss: 0.690135, g_loss: 0.697837\n",
      "Epoch 152, d_loss: 0.686923, g_loss: 0.690352\n",
      "Epoch 153, d_loss: 0.688019, g_loss: 0.682485\n",
      "Epoch 154, d_loss: 0.676798, g_loss: 0.699261\n",
      "Epoch 155, d_loss: 0.678770, g_loss: 0.685810\n",
      "Epoch 156, d_loss: 0.672600, g_loss: 0.697629\n",
      "Epoch 157, d_loss: 0.679048, g_loss: 0.688195\n",
      "Epoch 158, d_loss: 0.679517, g_loss: 0.699277\n",
      "Epoch 159, d_loss: 0.681472, g_loss: 0.707770\n",
      "Epoch 160, d_loss: 0.679620, g_loss: 0.698919\n",
      "Epoch 161, d_loss: 0.679163, g_loss: 0.697536\n",
      "Epoch 162, d_loss: 0.674057, g_loss: 0.701376\n",
      "Epoch 163, d_loss: 0.675956, g_loss: 0.707484\n",
      "Epoch 164, d_loss: 0.672068, g_loss: 0.694104\n",
      "Epoch 165, d_loss: 0.675068, g_loss: 0.707504\n",
      "Epoch 166, d_loss: 0.673724, g_loss: 0.697746\n",
      "Epoch 167, d_loss: 0.676302, g_loss: 0.700227\n",
      "Epoch 168, d_loss: 0.671999, g_loss: 0.702312\n",
      "Epoch 169, d_loss: 0.670806, g_loss: 0.707111\n",
      "Epoch 170, d_loss: 0.667465, g_loss: 0.704224\n",
      "Epoch 171, d_loss: 0.668739, g_loss: 0.712518\n",
      "Epoch 172, d_loss: 0.666378, g_loss: 0.708032\n",
      "Epoch 173, d_loss: 0.668919, g_loss: 0.708981\n",
      "Epoch 174, d_loss: 0.664084, g_loss: 0.712699\n",
      "Epoch 175, d_loss: 0.666560, g_loss: 0.716330\n",
      "Epoch 176, d_loss: 0.665073, g_loss: 0.726424\n",
      "Epoch 177, d_loss: 0.661233, g_loss: 0.709126\n",
      "Epoch 178, d_loss: 0.661839, g_loss: 0.719787\n",
      "Epoch 179, d_loss: 0.658058, g_loss: 0.707415\n",
      "Epoch 180, d_loss: 0.654996, g_loss: 0.712230\n",
      "Epoch 181, d_loss: 0.666233, g_loss: 0.720110\n",
      "Epoch 182, d_loss: 0.659780, g_loss: 0.730994\n",
      "Epoch 183, d_loss: 0.663536, g_loss: 0.722377\n",
      "Epoch 184, d_loss: 0.656364, g_loss: 0.734399\n",
      "Epoch 185, d_loss: 0.652066, g_loss: 0.739930\n",
      "Epoch 186, d_loss: 0.654536, g_loss: 0.727535\n",
      "Epoch 187, d_loss: 0.651359, g_loss: 0.722998\n",
      "Epoch 188, d_loss: 0.645688, g_loss: 0.730534\n",
      "Epoch 189, d_loss: 0.653204, g_loss: 0.723775\n",
      "Epoch 190, d_loss: 0.653049, g_loss: 0.725852\n",
      "Epoch 191, d_loss: 0.650922, g_loss: 0.743596\n",
      "Epoch 192, d_loss: 0.656764, g_loss: 0.715866\n",
      "Epoch 193, d_loss: 0.654595, g_loss: 0.755333\n",
      "Epoch 194, d_loss: 0.656193, g_loss: 0.721837\n",
      "Epoch 195, d_loss: 0.653523, g_loss: 0.719766\n",
      "Epoch 196, d_loss: 0.657410, g_loss: 0.730539\n",
      "Epoch 197, d_loss: 0.653240, g_loss: 0.736702\n",
      "Epoch 198, d_loss: 0.648510, g_loss: 0.719934\n",
      "Epoch 199, d_loss: 0.648503, g_loss: 0.737658\n"
     ]
    }
   ],
   "source": [
    "gan.train(X, nb_epoch=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
