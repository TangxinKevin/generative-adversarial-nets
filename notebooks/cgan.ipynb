{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sys.path.append('../../generative-adversarial-nets/')\n",
    "from ganetwork import GAN, CGAN\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = datasets.load_iris()\n",
    "X, y = minmax_scale(ds.data), LabelBinarizer().fit_transform(ds.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 1.7360587120056152, generator loss: 0.25952714681625366\n",
      "Epoch: 1, discriminator loss: 1.6409028768539429, generator loss: 0.3065200746059418\n",
      "Epoch: 2, discriminator loss: 1.5620324611663818, generator loss: 0.35903671383857727\n",
      "Epoch: 3, discriminator loss: 1.4981385469436646, generator loss: 0.41509851813316345\n",
      "Epoch: 4, discriminator loss: 1.4498543739318848, generator loss: 0.4746604561805725\n",
      "Epoch: 5, discriminator loss: 1.4139072895050049, generator loss: 0.5398749709129333\n",
      "Epoch: 6, discriminator loss: 1.3876450061798096, generator loss: 0.6131917834281921\n",
      "Epoch: 7, discriminator loss: 1.3744609355926514, generator loss: 0.6837582588195801\n",
      "Epoch: 8, discriminator loss: 1.3720498085021973, generator loss: 0.717760443687439\n",
      "Epoch: 9, discriminator loss: 1.381500482559204, generator loss: 0.7197553515434265\n",
      "Epoch: 10, discriminator loss: 1.3900926113128662, generator loss: 0.7108737230300903\n",
      "Epoch: 11, discriminator loss: 1.401566743850708, generator loss: 0.7144585847854614\n",
      "Epoch: 12, discriminator loss: 1.4056400060653687, generator loss: 0.7152504920959473\n",
      "Epoch: 13, discriminator loss: 1.406506061553955, generator loss: 0.7206834554672241\n",
      "Epoch: 14, discriminator loss: 1.4006174802780151, generator loss: 0.7309315204620361\n",
      "Epoch: 15, discriminator loss: 1.396441102027893, generator loss: 0.7472812533378601\n",
      "Epoch: 16, discriminator loss: 1.3894991874694824, generator loss: 0.7634929418563843\n",
      "Epoch: 17, discriminator loss: 1.3824706077575684, generator loss: 0.7941892743110657\n",
      "Epoch: 18, discriminator loss: 1.3687130212783813, generator loss: 0.7878472805023193\n",
      "Epoch: 19, discriminator loss: 1.349055528640747, generator loss: 0.7914937138557434\n",
      "Epoch: 20, discriminator loss: 1.3379300832748413, generator loss: 0.7938279509544373\n",
      "Epoch: 21, discriminator loss: 1.3252227306365967, generator loss: 0.8104845285415649\n",
      "Epoch: 22, discriminator loss: 1.3173539638519287, generator loss: 0.7991219758987427\n",
      "Epoch: 23, discriminator loss: 1.2857961654663086, generator loss: 0.7799438238143921\n",
      "Epoch: 24, discriminator loss: 1.2691874504089355, generator loss: 0.7890093922615051\n",
      "Epoch: 25, discriminator loss: 1.2603791952133179, generator loss: 0.804763674736023\n",
      "Epoch: 26, discriminator loss: 1.276578426361084, generator loss: 0.8140365481376648\n",
      "Epoch: 27, discriminator loss: 1.2779150009155273, generator loss: 0.8163946270942688\n",
      "Epoch: 28, discriminator loss: 1.2877682447433472, generator loss: 0.8147960901260376\n",
      "Epoch: 29, discriminator loss: 1.2798802852630615, generator loss: 0.8048422932624817\n",
      "Epoch: 30, discriminator loss: 1.308224081993103, generator loss: 0.869677722454071\n",
      "Epoch: 31, discriminator loss: 1.2926139831542969, generator loss: 0.8592014312744141\n",
      "Epoch: 32, discriminator loss: 1.2909252643585205, generator loss: 0.9176727533340454\n",
      "Epoch: 33, discriminator loss: 1.332502841949463, generator loss: 0.8381932973861694\n",
      "Epoch: 34, discriminator loss: 1.2688348293304443, generator loss: 0.9213727116584778\n",
      "Epoch: 35, discriminator loss: 1.2929514646530151, generator loss: 0.7887725234031677\n",
      "Epoch: 36, discriminator loss: 1.2975322008132935, generator loss: 0.7378198504447937\n",
      "Epoch: 37, discriminator loss: 1.3322877883911133, generator loss: 0.7014123201370239\n",
      "Epoch: 38, discriminator loss: 1.339285135269165, generator loss: 0.7628583312034607\n",
      "Epoch: 39, discriminator loss: 1.209821343421936, generator loss: 0.6487414240837097\n",
      "Epoch: 40, discriminator loss: 1.2707411050796509, generator loss: 0.7780523300170898\n",
      "Epoch: 41, discriminator loss: 1.3297984600067139, generator loss: 0.721983790397644\n",
      "Epoch: 42, discriminator loss: 1.3205645084381104, generator loss: 0.7841772437095642\n",
      "Epoch: 43, discriminator loss: 1.4112954139709473, generator loss: 0.7285564541816711\n",
      "Epoch: 44, discriminator loss: 1.3392562866210938, generator loss: 0.7553303837776184\n",
      "Epoch: 45, discriminator loss: 1.4016631841659546, generator loss: 0.701251208782196\n",
      "Epoch: 46, discriminator loss: 1.4158916473388672, generator loss: 0.7385608553886414\n",
      "Epoch: 47, discriminator loss: 1.4178340435028076, generator loss: 0.6599103212356567\n",
      "Epoch: 48, discriminator loss: 1.4037013053894043, generator loss: 0.6712000370025635\n",
      "Epoch: 49, discriminator loss: 1.4123094081878662, generator loss: 0.6918290853500366\n",
      "Epoch: 50, discriminator loss: 1.4103398323059082, generator loss: 0.6896249055862427\n",
      "Epoch: 51, discriminator loss: 1.39296555519104, generator loss: 0.7068415880203247\n",
      "Epoch: 52, discriminator loss: 1.4004241228103638, generator loss: 0.6932615637779236\n",
      "Epoch: 53, discriminator loss: 1.3972437381744385, generator loss: 0.6872997879981995\n",
      "Epoch: 54, discriminator loss: 1.395763635635376, generator loss: 0.6899358034133911\n",
      "Epoch: 55, discriminator loss: 1.3896125555038452, generator loss: 0.6856052279472351\n",
      "Epoch: 56, discriminator loss: 1.3963840007781982, generator loss: 0.6996195316314697\n",
      "Epoch: 57, discriminator loss: 1.395689845085144, generator loss: 0.6830023527145386\n",
      "Epoch: 58, discriminator loss: 1.3941597938537598, generator loss: 0.6838551163673401\n",
      "Epoch: 59, discriminator loss: 1.3918092250823975, generator loss: 0.6848067045211792\n",
      "Epoch: 60, discriminator loss: 1.3943365812301636, generator loss: 0.6854969263076782\n",
      "Epoch: 61, discriminator loss: 1.3912556171417236, generator loss: 0.6859258413314819\n",
      "Epoch: 62, discriminator loss: 1.3920490741729736, generator loss: 0.6885022521018982\n",
      "Epoch: 63, discriminator loss: 1.3907443284988403, generator loss: 0.6878308057785034\n",
      "Epoch: 64, discriminator loss: 1.3920941352844238, generator loss: 0.6888746619224548\n",
      "Epoch: 65, discriminator loss: 1.3916730880737305, generator loss: 0.6897844076156616\n",
      "Epoch: 66, discriminator loss: 1.3891801834106445, generator loss: 0.6907628178596497\n",
      "Epoch: 67, discriminator loss: 1.3909919261932373, generator loss: 0.6900137066841125\n",
      "Epoch: 68, discriminator loss: 1.3907573223114014, generator loss: 0.6936265826225281\n",
      "Epoch: 69, discriminator loss: 1.389811396598816, generator loss: 0.6913837194442749\n",
      "Epoch: 70, discriminator loss: 1.390195608139038, generator loss: 0.691360592842102\n",
      "Epoch: 71, discriminator loss: 1.3897048234939575, generator loss: 0.690925657749176\n",
      "Epoch: 72, discriminator loss: 1.389423131942749, generator loss: 0.6914541721343994\n",
      "Epoch: 73, discriminator loss: 1.3892024755477905, generator loss: 0.6922489404678345\n",
      "Epoch: 74, discriminator loss: 1.3895056247711182, generator loss: 0.6921625137329102\n",
      "Epoch: 75, discriminator loss: 1.389074683189392, generator loss: 0.691727876663208\n",
      "Epoch: 76, discriminator loss: 1.3889381885528564, generator loss: 0.691766619682312\n",
      "Epoch: 77, discriminator loss: 1.3891232013702393, generator loss: 0.6912564635276794\n",
      "Epoch: 78, discriminator loss: 1.3887754678726196, generator loss: 0.6916372776031494\n",
      "Epoch: 79, discriminator loss: 1.3886101245880127, generator loss: 0.6914425492286682\n",
      "Epoch: 80, discriminator loss: 1.3874766826629639, generator loss: 0.6934384107589722\n",
      "Epoch: 81, discriminator loss: 1.3882741928100586, generator loss: 0.6913639307022095\n",
      "Epoch: 82, discriminator loss: 1.3882529735565186, generator loss: 0.691588819026947\n",
      "Epoch: 83, discriminator loss: 1.388427734375, generator loss: 0.6914326548576355\n",
      "Epoch: 84, discriminator loss: 1.3882806301116943, generator loss: 0.6918076276779175\n",
      "Epoch: 85, discriminator loss: 1.3879711627960205, generator loss: 0.6915662288665771\n",
      "Epoch: 86, discriminator loss: 1.3879345655441284, generator loss: 0.6912243962287903\n",
      "Epoch: 87, discriminator loss: 1.3878371715545654, generator loss: 0.6912518739700317\n",
      "Epoch: 88, discriminator loss: 1.3878344297409058, generator loss: 0.6912627816200256\n",
      "Epoch: 89, discriminator loss: 1.3875362873077393, generator loss: 0.691088080406189\n",
      "Epoch: 90, discriminator loss: 1.387986660003662, generator loss: 0.6912815570831299\n",
      "Epoch: 91, discriminator loss: 1.3876144886016846, generator loss: 0.6911799311637878\n",
      "Epoch: 92, discriminator loss: 1.3877856731414795, generator loss: 0.691253662109375\n",
      "Epoch: 93, discriminator loss: 1.3877112865447998, generator loss: 0.6909041404724121\n",
      "Epoch: 94, discriminator loss: 1.3875718116760254, generator loss: 0.6910134553909302\n",
      "Epoch: 95, discriminator loss: 1.3874434232711792, generator loss: 0.6913188695907593\n",
      "Epoch: 96, discriminator loss: 1.3872158527374268, generator loss: 0.6912073493003845\n",
      "Epoch: 97, discriminator loss: 1.3874940872192383, generator loss: 0.6909847259521484\n",
      "Epoch: 98, discriminator loss: 1.3874882459640503, generator loss: 0.6907181739807129\n",
      "Epoch: 99, discriminator loss: 1.386709213256836, generator loss: 0.691313624382019\n",
      "Epoch: 100, discriminator loss: 1.387165904045105, generator loss: 0.6910354495048523\n",
      "Epoch: 101, discriminator loss: 1.3869421482086182, generator loss: 0.6914446949958801\n",
      "Epoch: 102, discriminator loss: 1.3872811794281006, generator loss: 0.6910039186477661\n",
      "Epoch: 103, discriminator loss: 1.3872936964035034, generator loss: 0.6910972595214844\n",
      "Epoch: 104, discriminator loss: 1.3873302936553955, generator loss: 0.6910682916641235\n",
      "Epoch: 105, discriminator loss: 1.3873893022537231, generator loss: 0.6914564371109009\n",
      "Epoch: 106, discriminator loss: 1.3869984149932861, generator loss: 0.6914583444595337\n",
      "Epoch: 107, discriminator loss: 1.3865607976913452, generator loss: 0.6917628049850464\n",
      "Epoch: 108, discriminator loss: 1.3870806694030762, generator loss: 0.6920067071914673\n",
      "Epoch: 109, discriminator loss: 1.3871643543243408, generator loss: 0.6919115781784058\n",
      "Epoch: 110, discriminator loss: 1.3866195678710938, generator loss: 0.6918050050735474\n",
      "Epoch: 111, discriminator loss: 1.3870244026184082, generator loss: 0.692245364189148\n",
      "Epoch: 112, discriminator loss: 1.3867120742797852, generator loss: 0.6926340460777283\n",
      "Epoch: 113, discriminator loss: 1.3869209289550781, generator loss: 0.6925672292709351\n",
      "Epoch: 114, discriminator loss: 1.3868412971496582, generator loss: 0.692629337310791\n",
      "Epoch: 115, discriminator loss: 1.3861873149871826, generator loss: 0.6930153965950012\n",
      "Epoch: 116, discriminator loss: 1.386932134628296, generator loss: 0.6933400630950928\n",
      "Epoch: 117, discriminator loss: 1.3869624137878418, generator loss: 0.6931776404380798\n",
      "Epoch: 118, discriminator loss: 1.386677622795105, generator loss: 0.6932264566421509\n",
      "Epoch: 119, discriminator loss: 1.3870083093643188, generator loss: 0.6931146383285522\n",
      "Epoch: 120, discriminator loss: 1.3868522644042969, generator loss: 0.6932679414749146\n",
      "Epoch: 121, discriminator loss: 1.386852741241455, generator loss: 0.6929229497909546\n",
      "Epoch: 122, discriminator loss: 1.386986494064331, generator loss: 0.6925589442253113\n",
      "Epoch: 123, discriminator loss: 1.386847734451294, generator loss: 0.6922309994697571\n",
      "Epoch: 124, discriminator loss: 1.3868248462677002, generator loss: 0.6917764544487\n",
      "Epoch: 125, discriminator loss: 1.3867454528808594, generator loss: 0.6913018226623535\n",
      "Epoch: 126, discriminator loss: 1.3867435455322266, generator loss: 0.690868079662323\n",
      "Epoch: 127, discriminator loss: 1.386796236038208, generator loss: 0.6902574300765991\n",
      "Epoch: 128, discriminator loss: 1.386790156364441, generator loss: 0.6898602247238159\n",
      "Epoch: 129, discriminator loss: 1.3866050243377686, generator loss: 0.6892398595809937\n",
      "Epoch: 130, discriminator loss: 1.3867312669754028, generator loss: 0.6886423230171204\n",
      "Epoch: 131, discriminator loss: 1.3867383003234863, generator loss: 0.6880964040756226\n",
      "Epoch: 132, discriminator loss: 1.3867303133010864, generator loss: 0.6873964071273804\n",
      "Epoch: 133, discriminator loss: 1.3866875171661377, generator loss: 0.6867168545722961\n",
      "Epoch: 134, discriminator loss: 1.3865889310836792, generator loss: 0.6860371828079224\n",
      "Epoch: 135, discriminator loss: 1.3866193294525146, generator loss: 0.6850301623344421\n",
      "Epoch: 136, discriminator loss: 1.3867197036743164, generator loss: 0.6839279532432556\n",
      "Epoch: 137, discriminator loss: 1.3867268562316895, generator loss: 0.6828693151473999\n",
      "Epoch: 138, discriminator loss: 1.3867545127868652, generator loss: 0.6814754605293274\n",
      "Epoch: 139, discriminator loss: 1.3867169618606567, generator loss: 0.68026202917099\n",
      "Epoch: 140, discriminator loss: 1.3868041038513184, generator loss: 0.6788309812545776\n",
      "Epoch: 141, discriminator loss: 1.3868718147277832, generator loss: 0.6773360371589661\n",
      "Epoch: 142, discriminator loss: 1.3868485689163208, generator loss: 0.6759881377220154\n",
      "Epoch: 143, discriminator loss: 1.3870035409927368, generator loss: 0.6750823855400085\n",
      "Epoch: 144, discriminator loss: 1.3870623111724854, generator loss: 0.6744565367698669\n",
      "Epoch: 145, discriminator loss: 1.3870235681533813, generator loss: 0.6729769706726074\n",
      "Epoch: 146, discriminator loss: 1.3871122598648071, generator loss: 0.6726375222206116\n",
      "Epoch: 147, discriminator loss: 1.387078881263733, generator loss: 0.6720179915428162\n",
      "Epoch: 148, discriminator loss: 1.3870751857757568, generator loss: 0.6711427569389343\n",
      "Epoch: 149, discriminator loss: 1.3870229721069336, generator loss: 0.6709672212600708\n",
      "Epoch: 150, discriminator loss: 1.387441635131836, generator loss: 0.6706808805465698\n",
      "Epoch: 151, discriminator loss: 1.3875274658203125, generator loss: 0.670376181602478\n",
      "Epoch: 152, discriminator loss: 1.3872214555740356, generator loss: 0.670427143573761\n",
      "Epoch: 153, discriminator loss: 1.387366771697998, generator loss: 0.670352578163147\n",
      "Epoch: 154, discriminator loss: 1.3871045112609863, generator loss: 0.6713577508926392\n",
      "Epoch: 155, discriminator loss: 1.3873987197875977, generator loss: 0.6719790697097778\n",
      "Epoch: 156, discriminator loss: 1.3869397640228271, generator loss: 0.672564685344696\n",
      "Epoch: 157, discriminator loss: 1.3870340585708618, generator loss: 0.6732696294784546\n",
      "Epoch: 158, discriminator loss: 1.3870490789413452, generator loss: 0.6736676096916199\n",
      "Epoch: 159, discriminator loss: 1.3870855569839478, generator loss: 0.6743804216384888\n",
      "Epoch: 160, discriminator loss: 1.3868896961212158, generator loss: 0.6749640703201294\n",
      "Epoch: 161, discriminator loss: 1.386981725692749, generator loss: 0.6753400564193726\n",
      "Epoch: 162, discriminator loss: 1.3871383666992188, generator loss: 0.6752270460128784\n",
      "Epoch: 163, discriminator loss: 1.3868467807769775, generator loss: 0.6758073568344116\n",
      "Epoch: 164, discriminator loss: 1.3870253562927246, generator loss: 0.6755478978157043\n",
      "Epoch: 165, discriminator loss: 1.3869330883026123, generator loss: 0.6755712032318115\n",
      "Epoch: 166, discriminator loss: 1.386995553970337, generator loss: 0.6753987073898315\n",
      "Epoch: 167, discriminator loss: 1.3869516849517822, generator loss: 0.6750566959381104\n",
      "Epoch: 168, discriminator loss: 1.3868143558502197, generator loss: 0.6749299764633179\n",
      "Epoch: 169, discriminator loss: 1.3868752717971802, generator loss: 0.6747130155563354\n",
      "Epoch: 170, discriminator loss: 1.3869496583938599, generator loss: 0.6748479604721069\n",
      "Epoch: 171, discriminator loss: 1.3869380950927734, generator loss: 0.6746724843978882\n",
      "Epoch: 172, discriminator loss: 1.3867945671081543, generator loss: 0.6748775243759155\n",
      "Epoch: 173, discriminator loss: 1.3868037462234497, generator loss: 0.675393283367157\n",
      "Epoch: 174, discriminator loss: 1.3869097232818604, generator loss: 0.6757775545120239\n",
      "Epoch: 175, discriminator loss: 1.386850118637085, generator loss: 0.6763509511947632\n",
      "Epoch: 176, discriminator loss: 1.3868528604507446, generator loss: 0.6770618557929993\n",
      "Epoch: 177, discriminator loss: 1.3866182565689087, generator loss: 0.6780522465705872\n",
      "Epoch: 178, discriminator loss: 1.386663794517517, generator loss: 0.6791831851005554\n",
      "Epoch: 179, discriminator loss: 1.3867576122283936, generator loss: 0.6804490089416504\n",
      "Epoch: 180, discriminator loss: 1.3867130279541016, generator loss: 0.6817201375961304\n",
      "Epoch: 181, discriminator loss: 1.3865777254104614, generator loss: 0.6832360625267029\n",
      "Epoch: 182, discriminator loss: 1.386674404144287, generator loss: 0.6845627427101135\n",
      "Epoch: 183, discriminator loss: 1.3865907192230225, generator loss: 0.6856762170791626\n",
      "Epoch: 184, discriminator loss: 1.3865599632263184, generator loss: 0.6868415474891663\n",
      "Epoch: 185, discriminator loss: 1.386581301689148, generator loss: 0.6878823637962341\n",
      "Epoch: 186, discriminator loss: 1.386506199836731, generator loss: 0.6885998845100403\n",
      "Epoch: 187, discriminator loss: 1.3865182399749756, generator loss: 0.6895607113838196\n",
      "Epoch: 188, discriminator loss: 1.38655424118042, generator loss: 0.6902212500572205\n",
      "Epoch: 189, discriminator loss: 1.3865478038787842, generator loss: 0.690946102142334\n",
      "Epoch: 190, discriminator loss: 1.3865089416503906, generator loss: 0.6912693977355957\n",
      "Epoch: 191, discriminator loss: 1.386580228805542, generator loss: 0.6917506456375122\n",
      "Epoch: 192, discriminator loss: 1.3865588903427124, generator loss: 0.6920116543769836\n",
      "Epoch: 193, discriminator loss: 1.3865585327148438, generator loss: 0.6924870014190674\n",
      "Epoch: 194, discriminator loss: 1.386531114578247, generator loss: 0.6926780939102173\n",
      "Epoch: 195, discriminator loss: 1.3865773677825928, generator loss: 0.6929432153701782\n",
      "Epoch: 196, discriminator loss: 1.3865306377410889, generator loss: 0.6931929588317871\n",
      "Epoch: 197, discriminator loss: 1.3865180015563965, generator loss: 0.6932145357131958\n",
      "Epoch: 198, discriminator loss: 1.3865211009979248, generator loss: 0.6934665441513062\n",
      "Epoch: 199, discriminator loss: 1.386481761932373, generator loss: 0.6935213208198547\n",
      "Epoch: 200, discriminator loss: 1.3865067958831787, generator loss: 0.6936789751052856\n",
      "Epoch: 201, discriminator loss: 1.3864672183990479, generator loss: 0.6936984658241272\n",
      "Epoch: 202, discriminator loss: 1.3864805698394775, generator loss: 0.69389808177948\n",
      "Epoch: 203, discriminator loss: 1.3864405155181885, generator loss: 0.6938955783843994\n",
      "Epoch: 204, discriminator loss: 1.386452078819275, generator loss: 0.6940919160842896\n",
      "Epoch: 205, discriminator loss: 1.3864339590072632, generator loss: 0.6941129565238953\n",
      "Epoch: 206, discriminator loss: 1.3864033222198486, generator loss: 0.6942570209503174\n",
      "Epoch: 207, discriminator loss: 1.3864152431488037, generator loss: 0.6943444013595581\n",
      "Epoch: 208, discriminator loss: 1.3863904476165771, generator loss: 0.6944726705551147\n",
      "Epoch: 209, discriminator loss: 1.3863959312438965, generator loss: 0.6945781707763672\n",
      "Epoch: 210, discriminator loss: 1.3863587379455566, generator loss: 0.6947322487831116\n",
      "Epoch: 211, discriminator loss: 1.386385440826416, generator loss: 0.6949389576911926\n",
      "Epoch: 212, discriminator loss: 1.3863297700881958, generator loss: 0.6951708793640137\n",
      "Epoch: 213, discriminator loss: 1.3862721920013428, generator loss: 0.6954163312911987\n",
      "Epoch: 214, discriminator loss: 1.3862907886505127, generator loss: 0.6957017779350281\n",
      "Epoch: 215, discriminator loss: 1.386272668838501, generator loss: 0.6962670087814331\n",
      "Epoch: 216, discriminator loss: 1.3861204385757446, generator loss: 0.6968823671340942\n",
      "Epoch: 217, discriminator loss: 1.3860087394714355, generator loss: 0.6981144547462463\n",
      "Epoch: 218, discriminator loss: 1.3858740329742432, generator loss: 0.699842095375061\n",
      "Epoch: 219, discriminator loss: 1.3858158588409424, generator loss: 0.7033694386482239\n",
      "Epoch: 220, discriminator loss: 1.3843109607696533, generator loss: 0.7122119665145874\n",
      "Epoch: 221, discriminator loss: 1.383850336074829, generator loss: 0.7297338247299194\n",
      "Epoch: 222, discriminator loss: 1.385000228881836, generator loss: 0.7491481900215149\n",
      "Epoch: 223, discriminator loss: 1.3861758708953857, generator loss: 0.7309969663619995\n",
      "Epoch: 224, discriminator loss: 1.3866641521453857, generator loss: 0.7052891850471497\n",
      "Epoch: 225, discriminator loss: 1.3867380619049072, generator loss: 0.6952869296073914\n",
      "Epoch: 226, discriminator loss: 1.386769413948059, generator loss: 0.6926389932632446\n",
      "Epoch: 227, discriminator loss: 1.3865242004394531, generator loss: 0.691571831703186\n",
      "Epoch: 228, discriminator loss: 1.3863661289215088, generator loss: 0.6907865405082703\n",
      "Epoch: 229, discriminator loss: 1.3859654664993286, generator loss: 0.6896146535873413\n",
      "Epoch: 230, discriminator loss: 1.386042594909668, generator loss: 0.6904105544090271\n",
      "Epoch: 231, discriminator loss: 1.3851683139801025, generator loss: 0.6896615624427795\n",
      "Epoch: 232, discriminator loss: 1.3853373527526855, generator loss: 0.6892383694648743\n",
      "Epoch: 233, discriminator loss: 1.3853042125701904, generator loss: 0.6882587671279907\n",
      "Epoch: 234, discriminator loss: 1.3827095031738281, generator loss: 0.6879862546920776\n",
      "Epoch: 235, discriminator loss: 1.385561227798462, generator loss: 0.686493992805481\n",
      "Epoch: 236, discriminator loss: 1.382967233657837, generator loss: 0.6869801878929138\n",
      "Epoch: 237, discriminator loss: 1.3844273090362549, generator loss: 0.6872404217720032\n",
      "Epoch: 238, discriminator loss: 1.386464238166809, generator loss: 0.6842471957206726\n",
      "Epoch: 239, discriminator loss: 1.385646939277649, generator loss: 0.6845988035202026\n",
      "Epoch: 240, discriminator loss: 1.389734148979187, generator loss: 0.6813582181930542\n",
      "Epoch: 241, discriminator loss: 1.389233112335205, generator loss: 0.6824862957000732\n",
      "Epoch: 242, discriminator loss: 1.3910115957260132, generator loss: 0.6825478076934814\n",
      "Epoch: 243, discriminator loss: 1.3906158208847046, generator loss: 0.6837105751037598\n",
      "Epoch: 244, discriminator loss: 1.3902003765106201, generator loss: 0.6854321360588074\n",
      "Epoch: 245, discriminator loss: 1.3889548778533936, generator loss: 0.6866697072982788\n",
      "Epoch: 246, discriminator loss: 1.3891545534133911, generator loss: 0.6868952512741089\n",
      "Epoch: 247, discriminator loss: 1.3887739181518555, generator loss: 0.6877609491348267\n",
      "Epoch: 248, discriminator loss: 1.3884377479553223, generator loss: 0.6891319751739502\n",
      "Epoch: 249, discriminator loss: 1.3877339363098145, generator loss: 0.6897530555725098\n",
      "Epoch: 250, discriminator loss: 1.3882514238357544, generator loss: 0.6899889707565308\n",
      "Epoch: 251, discriminator loss: 1.3875808715820312, generator loss: 0.690894365310669\n",
      "Epoch: 252, discriminator loss: 1.3875130414962769, generator loss: 0.6912114024162292\n",
      "Epoch: 253, discriminator loss: 1.3874510526657104, generator loss: 0.6914383172988892\n",
      "Epoch: 254, discriminator loss: 1.3872644901275635, generator loss: 0.6922679543495178\n",
      "Epoch: 255, discriminator loss: 1.3871796131134033, generator loss: 0.6924033761024475\n",
      "Epoch: 256, discriminator loss: 1.3870015144348145, generator loss: 0.6929613351821899\n",
      "Epoch: 257, discriminator loss: 1.3869743347167969, generator loss: 0.6928858757019043\n",
      "Epoch: 258, discriminator loss: 1.3868019580841064, generator loss: 0.6933738589286804\n",
      "Epoch: 259, discriminator loss: 1.386838436126709, generator loss: 0.6933687329292297\n",
      "Epoch: 260, discriminator loss: 1.386685848236084, generator loss: 0.6935960054397583\n",
      "Epoch: 261, discriminator loss: 1.3867437839508057, generator loss: 0.6937451362609863\n",
      "Epoch: 262, discriminator loss: 1.386650800704956, generator loss: 0.6939167976379395\n",
      "Epoch: 263, discriminator loss: 1.3866300582885742, generator loss: 0.694038987159729\n",
      "Epoch: 264, discriminator loss: 1.3865554332733154, generator loss: 0.6941795945167542\n",
      "Epoch: 265, discriminator loss: 1.3865084648132324, generator loss: 0.694283127784729\n",
      "Epoch: 266, discriminator loss: 1.386464238166809, generator loss: 0.6944087743759155\n",
      "Epoch: 267, discriminator loss: 1.3864233493804932, generator loss: 0.6945174932479858\n",
      "Epoch: 268, discriminator loss: 1.3863917589187622, generator loss: 0.6946433782577515\n",
      "Epoch: 269, discriminator loss: 1.3863507509231567, generator loss: 0.6948124170303345\n",
      "Epoch: 270, discriminator loss: 1.3863165378570557, generator loss: 0.6949127316474915\n",
      "Epoch: 271, discriminator loss: 1.386247158050537, generator loss: 0.6951420903205872\n",
      "Epoch: 272, discriminator loss: 1.3862295150756836, generator loss: 0.6952043175697327\n",
      "Epoch: 273, discriminator loss: 1.3861416578292847, generator loss: 0.6953967809677124\n",
      "Epoch: 274, discriminator loss: 1.3860588073730469, generator loss: 0.6956238746643066\n",
      "Epoch: 275, discriminator loss: 1.3860094547271729, generator loss: 0.6959352493286133\n",
      "Epoch: 276, discriminator loss: 1.3859302997589111, generator loss: 0.6961899995803833\n",
      "Epoch: 277, discriminator loss: 1.3857166767120361, generator loss: 0.6966469883918762\n",
      "Epoch: 278, discriminator loss: 1.3855152130126953, generator loss: 0.697211742401123\n",
      "Epoch: 279, discriminator loss: 1.3851723670959473, generator loss: 0.6976988911628723\n",
      "Epoch: 280, discriminator loss: 1.3844761848449707, generator loss: 0.6987026333808899\n",
      "Epoch: 281, discriminator loss: 1.3833961486816406, generator loss: 0.6992076635360718\n",
      "Epoch: 282, discriminator loss: 1.3816354274749756, generator loss: 0.701217532157898\n",
      "Epoch: 283, discriminator loss: 1.3783589601516724, generator loss: 0.7019560933113098\n",
      "Epoch: 284, discriminator loss: 1.3761415481567383, generator loss: 0.704617977142334\n",
      "Epoch: 285, discriminator loss: 1.37485671043396, generator loss: 0.7100993394851685\n",
      "Epoch: 286, discriminator loss: 1.387947916984558, generator loss: 0.7033363580703735\n",
      "Epoch: 287, discriminator loss: 1.385379433631897, generator loss: 0.6964238286018372\n",
      "Epoch: 288, discriminator loss: 1.3907499313354492, generator loss: 0.6929709315299988\n",
      "Epoch: 289, discriminator loss: 1.3887137174606323, generator loss: 0.6907533407211304\n",
      "Epoch: 290, discriminator loss: 1.388932466506958, generator loss: 0.6886347532272339\n",
      "Epoch: 291, discriminator loss: 1.3874166011810303, generator loss: 0.6886418461799622\n",
      "Epoch: 292, discriminator loss: 1.3865351676940918, generator loss: 0.6878838539123535\n",
      "Epoch: 293, discriminator loss: 1.3857982158660889, generator loss: 0.688071608543396\n",
      "Epoch: 294, discriminator loss: 1.385298252105713, generator loss: 0.6883324384689331\n",
      "Epoch: 295, discriminator loss: 1.3843950033187866, generator loss: 0.6888192892074585\n",
      "Epoch: 296, discriminator loss: 1.3846008777618408, generator loss: 0.6888588666915894\n",
      "Epoch: 297, discriminator loss: 1.3815150260925293, generator loss: 0.6890350580215454\n",
      "Epoch: 298, discriminator loss: 1.3779668807983398, generator loss: 0.6876723170280457\n",
      "Epoch: 299, discriminator loss: 1.3796024322509766, generator loss: 0.6902561187744141\n",
      "Epoch: 300, discriminator loss: 1.3795344829559326, generator loss: 0.6912029981613159\n",
      "Epoch: 301, discriminator loss: 1.3796336650848389, generator loss: 0.6840351819992065\n",
      "Epoch: 302, discriminator loss: 1.393196940422058, generator loss: 0.6893830299377441\n",
      "Epoch: 303, discriminator loss: 1.3939628601074219, generator loss: 0.6901258230209351\n",
      "Epoch: 304, discriminator loss: 1.3918204307556152, generator loss: 0.6900790333747864\n",
      "Epoch: 305, discriminator loss: 1.3936094045639038, generator loss: 0.6916349530220032\n",
      "Epoch: 306, discriminator loss: 1.3919531106948853, generator loss: 0.6925629377365112\n",
      "Epoch: 307, discriminator loss: 1.3911426067352295, generator loss: 0.6925592422485352\n",
      "Epoch: 308, discriminator loss: 1.3899211883544922, generator loss: 0.6936437487602234\n",
      "Epoch: 309, discriminator loss: 1.3893499374389648, generator loss: 0.6936438679695129\n",
      "Epoch: 310, discriminator loss: 1.3883930444717407, generator loss: 0.6940586566925049\n",
      "Epoch: 311, discriminator loss: 1.3883352279663086, generator loss: 0.6937932372093201\n",
      "Epoch: 312, discriminator loss: 1.3875718116760254, generator loss: 0.6937432885169983\n",
      "Epoch: 313, discriminator loss: 1.3879785537719727, generator loss: 0.6939867734909058\n",
      "Epoch: 314, discriminator loss: 1.3874647617340088, generator loss: 0.6938050985336304\n",
      "Epoch: 315, discriminator loss: 1.387251853942871, generator loss: 0.6941901445388794\n",
      "Epoch: 316, discriminator loss: 1.3871071338653564, generator loss: 0.694210410118103\n",
      "Epoch: 317, discriminator loss: 1.3869820833206177, generator loss: 0.6942812204360962\n",
      "Epoch: 318, discriminator loss: 1.3868378400802612, generator loss: 0.6943694353103638\n",
      "Epoch: 319, discriminator loss: 1.3867082595825195, generator loss: 0.6942623257637024\n",
      "Epoch: 320, discriminator loss: 1.3865846395492554, generator loss: 0.6944643259048462\n",
      "Epoch: 321, discriminator loss: 1.3864822387695312, generator loss: 0.6944025754928589\n",
      "Epoch: 322, discriminator loss: 1.386359691619873, generator loss: 0.6945525407791138\n",
      "Epoch: 323, discriminator loss: 1.386225700378418, generator loss: 0.6946734189987183\n",
      "Epoch: 324, discriminator loss: 1.3860312700271606, generator loss: 0.6947299838066101\n",
      "Epoch: 325, discriminator loss: 1.3859175443649292, generator loss: 0.6948760151863098\n",
      "Epoch: 326, discriminator loss: 1.3857589960098267, generator loss: 0.6949007511138916\n",
      "Epoch: 327, discriminator loss: 1.385500192642212, generator loss: 0.6950681805610657\n",
      "Epoch: 328, discriminator loss: 1.3850278854370117, generator loss: 0.6952242851257324\n",
      "Epoch: 329, discriminator loss: 1.3851475715637207, generator loss: 0.6957646608352661\n",
      "Epoch: 330, discriminator loss: 1.3843053579330444, generator loss: 0.6960344910621643\n",
      "Epoch: 331, discriminator loss: 1.383669376373291, generator loss: 0.6964752674102783\n",
      "Epoch: 332, discriminator loss: 1.3825273513793945, generator loss: 0.6975544691085815\n",
      "Epoch: 333, discriminator loss: 1.3797811269760132, generator loss: 0.6983773112297058\n",
      "Epoch: 334, discriminator loss: 1.3773307800292969, generator loss: 0.7017651796340942\n",
      "Epoch: 335, discriminator loss: 1.3764269351959229, generator loss: 0.7020806670188904\n",
      "Epoch: 336, discriminator loss: 1.3704713582992554, generator loss: 0.7023987174034119\n",
      "Epoch: 337, discriminator loss: 1.372913122177124, generator loss: 0.6913942694664001\n",
      "Epoch: 338, discriminator loss: 1.3798235654830933, generator loss: 0.6887697577476501\n",
      "Epoch: 339, discriminator loss: 1.3958419561386108, generator loss: 0.6831246018409729\n",
      "Epoch: 340, discriminator loss: 1.3953657150268555, generator loss: 0.6828158497810364\n",
      "Epoch: 341, discriminator loss: 1.3920252323150635, generator loss: 0.6865522265434265\n",
      "Epoch: 342, discriminator loss: 1.3897240161895752, generator loss: 0.6874440908432007\n",
      "Epoch: 343, discriminator loss: 1.388322353363037, generator loss: 0.6885179877281189\n",
      "Epoch: 344, discriminator loss: 1.3872570991516113, generator loss: 0.6902686953544617\n",
      "Epoch: 345, discriminator loss: 1.3867485523223877, generator loss: 0.6908300518989563\n",
      "Epoch: 346, discriminator loss: 1.3858129978179932, generator loss: 0.6915668845176697\n",
      "Epoch: 347, discriminator loss: 1.385118007659912, generator loss: 0.6917889714241028\n",
      "Epoch: 348, discriminator loss: 1.3840434551239014, generator loss: 0.6924101114273071\n",
      "Epoch: 349, discriminator loss: 1.3829294443130493, generator loss: 0.6922137141227722\n",
      "Epoch: 350, discriminator loss: 1.3820390701293945, generator loss: 0.6925567388534546\n",
      "Epoch: 351, discriminator loss: 1.379103660583496, generator loss: 0.6922758221626282\n",
      "Epoch: 352, discriminator loss: 1.372178077697754, generator loss: 0.6922606229782104\n",
      "Epoch: 353, discriminator loss: 1.3784329891204834, generator loss: 0.6933586001396179\n",
      "Epoch: 354, discriminator loss: 1.3665156364440918, generator loss: 0.693616509437561\n",
      "Epoch: 355, discriminator loss: 1.388105869293213, generator loss: 0.6831632256507874\n",
      "Epoch: 356, discriminator loss: 1.3978921175003052, generator loss: 0.6841159462928772\n",
      "Epoch: 357, discriminator loss: 1.392777442932129, generator loss: 0.6908231377601624\n",
      "Epoch: 358, discriminator loss: 1.3913670778274536, generator loss: 0.6892613172531128\n",
      "Epoch: 359, discriminator loss: 1.3849208354949951, generator loss: 0.6887412667274475\n",
      "Epoch: 360, discriminator loss: 1.3735005855560303, generator loss: 0.6995278596878052\n",
      "Epoch: 361, discriminator loss: 1.3571820259094238, generator loss: 0.7164751887321472\n",
      "Epoch: 362, discriminator loss: 1.3613053560256958, generator loss: 0.7382445931434631\n",
      "Epoch: 363, discriminator loss: 1.369741439819336, generator loss: 0.6983508467674255\n",
      "Epoch: 364, discriminator loss: 1.403134822845459, generator loss: 0.6912486553192139\n",
      "Epoch: 365, discriminator loss: 1.4081387519836426, generator loss: 0.6885617971420288\n",
      "Epoch: 366, discriminator loss: 1.400428295135498, generator loss: 0.6919454336166382\n",
      "Epoch: 367, discriminator loss: 1.3948357105255127, generator loss: 0.6951459646224976\n",
      "Epoch: 368, discriminator loss: 1.3919618129730225, generator loss: 0.694151759147644\n",
      "Epoch: 369, discriminator loss: 1.390197515487671, generator loss: 0.6948549747467041\n",
      "Epoch: 370, discriminator loss: 1.3889786005020142, generator loss: 0.6950008869171143\n",
      "Epoch: 371, discriminator loss: 1.3881559371948242, generator loss: 0.695208728313446\n",
      "Epoch: 372, discriminator loss: 1.3873929977416992, generator loss: 0.6951665878295898\n",
      "Epoch: 373, discriminator loss: 1.386610984802246, generator loss: 0.6952332854270935\n",
      "Epoch: 374, discriminator loss: 1.3860416412353516, generator loss: 0.6954168081283569\n",
      "Epoch: 375, discriminator loss: 1.3849284648895264, generator loss: 0.6958597898483276\n",
      "Epoch: 376, discriminator loss: 1.3836820125579834, generator loss: 0.6967021226882935\n",
      "Epoch: 377, discriminator loss: 1.3817498683929443, generator loss: 0.6981503963470459\n",
      "Epoch: 378, discriminator loss: 1.3765525817871094, generator loss: 0.7039271593093872\n",
      "Epoch: 379, discriminator loss: 1.3662304878234863, generator loss: 0.7056339979171753\n",
      "Epoch: 380, discriminator loss: 1.3589751720428467, generator loss: 0.6975864171981812\n",
      "Epoch: 381, discriminator loss: 1.3550304174423218, generator loss: 0.6796371340751648\n",
      "Epoch: 382, discriminator loss: 1.3548152446746826, generator loss: 0.6711476445198059\n",
      "Epoch: 383, discriminator loss: 1.3857438564300537, generator loss: 0.6678832769393921\n",
      "Epoch: 384, discriminator loss: 1.397498369216919, generator loss: 0.6924393773078918\n",
      "Epoch: 385, discriminator loss: 1.387404441833496, generator loss: 0.700407862663269\n",
      "Epoch: 386, discriminator loss: 1.3880316019058228, generator loss: 0.7029155492782593\n",
      "Epoch: 387, discriminator loss: 1.3869497776031494, generator loss: 0.7021145820617676\n",
      "Epoch: 388, discriminator loss: 1.3857052326202393, generator loss: 0.7012082934379578\n",
      "Epoch: 389, discriminator loss: 1.3821179866790771, generator loss: 0.7000499963760376\n",
      "Epoch: 390, discriminator loss: 1.3758037090301514, generator loss: 0.6999906301498413\n",
      "Epoch: 391, discriminator loss: 1.3720866441726685, generator loss: 0.6939443349838257\n",
      "Epoch: 392, discriminator loss: 1.3617994785308838, generator loss: 0.6884441375732422\n",
      "Epoch: 393, discriminator loss: 1.3494817018508911, generator loss: 0.6482456922531128\n",
      "Epoch: 394, discriminator loss: 1.369628667831421, generator loss: 0.6405733823776245\n",
      "Epoch: 395, discriminator loss: 1.38911771774292, generator loss: 0.6470475196838379\n",
      "Epoch: 396, discriminator loss: 1.4029741287231445, generator loss: 0.6584628820419312\n",
      "Epoch: 397, discriminator loss: 1.3901698589324951, generator loss: 0.6759635210037231\n",
      "Epoch: 398, discriminator loss: 1.3644721508026123, generator loss: 0.7105939984321594\n",
      "Epoch: 399, discriminator loss: 1.342127799987793, generator loss: 0.7757354974746704\n",
      "Epoch: 400, discriminator loss: 1.323289155960083, generator loss: 0.8006381988525391\n",
      "Epoch: 401, discriminator loss: 1.341206669807434, generator loss: 0.7397217750549316\n",
      "Epoch: 402, discriminator loss: 1.4139511585235596, generator loss: 0.6788375973701477\n",
      "Epoch: 403, discriminator loss: 1.413997769355774, generator loss: 0.6868117451667786\n",
      "Epoch: 404, discriminator loss: 1.4017900228500366, generator loss: 0.6932072639465332\n",
      "Epoch: 405, discriminator loss: 1.3935438394546509, generator loss: 0.6940268874168396\n",
      "Epoch: 406, discriminator loss: 1.3851852416992188, generator loss: 0.6952813863754272\n",
      "Epoch: 407, discriminator loss: 1.3787630796432495, generator loss: 0.6959413886070251\n",
      "Epoch: 408, discriminator loss: 1.3732744455337524, generator loss: 0.6956136226654053\n",
      "Epoch: 409, discriminator loss: 1.3671588897705078, generator loss: 0.6907219290733337\n",
      "Epoch: 410, discriminator loss: 1.3594754934310913, generator loss: 0.6940490007400513\n",
      "Epoch: 411, discriminator loss: 1.354517936706543, generator loss: 0.6918016672134399\n",
      "Epoch: 412, discriminator loss: 1.3490073680877686, generator loss: 0.6882268190383911\n",
      "Epoch: 413, discriminator loss: 1.353366732597351, generator loss: 0.6759673357009888\n",
      "Epoch: 414, discriminator loss: 1.3541624546051025, generator loss: 0.666511058807373\n",
      "Epoch: 415, discriminator loss: 1.3708240985870361, generator loss: 0.6577865481376648\n",
      "Epoch: 416, discriminator loss: 1.3790339231491089, generator loss: 0.6545664072036743\n",
      "Epoch: 417, discriminator loss: 1.366686463356018, generator loss: 0.6755576133728027\n",
      "Epoch: 418, discriminator loss: 1.3250839710235596, generator loss: 0.7638000249862671\n",
      "Epoch: 419, discriminator loss: 1.3399183750152588, generator loss: 0.7517479062080383\n",
      "Epoch: 420, discriminator loss: 1.4189434051513672, generator loss: 0.6926829814910889\n",
      "Epoch: 421, discriminator loss: 1.422032117843628, generator loss: 0.6733887791633606\n",
      "Epoch: 422, discriminator loss: 1.432368278503418, generator loss: 0.6905205845832825\n",
      "Epoch: 423, discriminator loss: 1.401817798614502, generator loss: 0.6858113408088684\n",
      "Epoch: 424, discriminator loss: 1.3833171129226685, generator loss: 0.7043806314468384\n",
      "Epoch: 425, discriminator loss: 1.3665450811386108, generator loss: 0.7066927552223206\n",
      "Epoch: 426, discriminator loss: 1.370948314666748, generator loss: 0.7020026445388794\n",
      "Epoch: 427, discriminator loss: 1.3783392906188965, generator loss: 0.6949979066848755\n",
      "Epoch: 428, discriminator loss: 1.3902860879898071, generator loss: 0.689167320728302\n",
      "Epoch: 429, discriminator loss: 1.3902029991149902, generator loss: 0.6869446039199829\n",
      "Epoch: 430, discriminator loss: 1.3892076015472412, generator loss: 0.6820017099380493\n",
      "Epoch: 431, discriminator loss: 1.396385669708252, generator loss: 0.6797957420349121\n",
      "Epoch: 432, discriminator loss: 1.3940975666046143, generator loss: 0.6791607141494751\n",
      "Epoch: 433, discriminator loss: 1.3931154012680054, generator loss: 0.6782359480857849\n",
      "Epoch: 434, discriminator loss: 1.3920429944992065, generator loss: 0.678683876991272\n",
      "Epoch: 435, discriminator loss: 1.3914682865142822, generator loss: 0.6816872358322144\n",
      "Epoch: 436, discriminator loss: 1.3894336223602295, generator loss: 0.6781173944473267\n",
      "Epoch: 437, discriminator loss: 1.393497347831726, generator loss: 0.6729837656021118\n",
      "Epoch: 438, discriminator loss: 1.3989830017089844, generator loss: 0.6563621759414673\n",
      "Epoch: 439, discriminator loss: 1.407641887664795, generator loss: 0.6425192356109619\n",
      "Epoch: 440, discriminator loss: 1.423248052597046, generator loss: 0.6495510935783386\n",
      "Epoch: 441, discriminator loss: 1.4143173694610596, generator loss: 0.6500200629234314\n",
      "Epoch: 442, discriminator loss: 1.403213381767273, generator loss: 0.6577776074409485\n",
      "Epoch: 443, discriminator loss: 1.392149806022644, generator loss: 0.6731265187263489\n",
      "Epoch: 444, discriminator loss: 1.3849148750305176, generator loss: 0.6835066080093384\n",
      "Epoch: 445, discriminator loss: 1.3799242973327637, generator loss: 0.6891058087348938\n",
      "Epoch: 446, discriminator loss: 1.3759486675262451, generator loss: 0.692169189453125\n",
      "Epoch: 447, discriminator loss: 1.3711133003234863, generator loss: 0.6961112022399902\n",
      "Epoch: 448, discriminator loss: 1.365702509880066, generator loss: 0.6960837244987488\n",
      "Epoch: 449, discriminator loss: 1.3620978593826294, generator loss: 0.6983899474143982\n",
      "Epoch: 450, discriminator loss: 1.3555415868759155, generator loss: 0.7025014758110046\n",
      "Epoch: 451, discriminator loss: 1.3412022590637207, generator loss: 0.7027550339698792\n",
      "Epoch: 452, discriminator loss: 1.3098187446594238, generator loss: 0.6984876394271851\n",
      "Epoch: 453, discriminator loss: 1.2266337871551514, generator loss: 0.6301395893096924\n",
      "Epoch: 454, discriminator loss: 1.1476247310638428, generator loss: 0.6112163662910461\n",
      "Epoch: 455, discriminator loss: 1.2068015336990356, generator loss: 0.6194552183151245\n",
      "Epoch: 456, discriminator loss: 1.3566482067108154, generator loss: 0.6232714056968689\n",
      "Epoch: 457, discriminator loss: 1.4468777179718018, generator loss: 0.6524702906608582\n",
      "Epoch: 458, discriminator loss: 1.4143199920654297, generator loss: 0.6816480159759521\n",
      "Epoch: 459, discriminator loss: 1.3526263236999512, generator loss: 0.7037983536720276\n",
      "Epoch: 460, discriminator loss: 1.343531847000122, generator loss: 0.7398155927658081\n",
      "Epoch: 461, discriminator loss: 1.3895747661590576, generator loss: 0.6821292042732239\n",
      "Epoch: 462, discriminator loss: 1.495492935180664, generator loss: 0.6429009437561035\n",
      "Epoch: 463, discriminator loss: 1.5278592109680176, generator loss: 0.6601679921150208\n",
      "Epoch: 464, discriminator loss: 1.5411794185638428, generator loss: 0.6130400896072388\n",
      "Epoch: 465, discriminator loss: 1.4944720268249512, generator loss: 0.6317600011825562\n",
      "Epoch: 466, discriminator loss: 1.462734580039978, generator loss: 0.6634945273399353\n",
      "Epoch: 467, discriminator loss: 1.423863172531128, generator loss: 0.6798404455184937\n",
      "Epoch: 468, discriminator loss: 1.4051027297973633, generator loss: 0.689193844795227\n",
      "Epoch: 469, discriminator loss: 1.3909837007522583, generator loss: 0.6937621831893921\n",
      "Epoch: 470, discriminator loss: 1.3829375505447388, generator loss: 0.698936939239502\n",
      "Epoch: 471, discriminator loss: 1.3739235401153564, generator loss: 0.7024550437927246\n",
      "Epoch: 472, discriminator loss: 1.365710735321045, generator loss: 0.7040951251983643\n",
      "Epoch: 473, discriminator loss: 1.3569040298461914, generator loss: 0.7052756547927856\n",
      "Epoch: 474, discriminator loss: 1.3474117517471313, generator loss: 0.7109570503234863\n",
      "Epoch: 475, discriminator loss: 1.3369207382202148, generator loss: 0.7092145085334778\n",
      "Epoch: 476, discriminator loss: 1.321801781654358, generator loss: 0.7187576293945312\n",
      "Epoch: 477, discriminator loss: 1.3120286464691162, generator loss: 0.7236788272857666\n",
      "Epoch: 478, discriminator loss: 1.3055769205093384, generator loss: 0.7250857353210449\n",
      "Epoch: 479, discriminator loss: 1.295893907546997, generator loss: 0.7327550053596497\n",
      "Epoch: 480, discriminator loss: 1.3015143871307373, generator loss: 0.7187985181808472\n",
      "Epoch: 481, discriminator loss: 1.2984349727630615, generator loss: 0.7142317891120911\n",
      "Epoch: 482, discriminator loss: 1.3218114376068115, generator loss: 0.7010203003883362\n",
      "Epoch: 483, discriminator loss: 1.3644163608551025, generator loss: 0.6874817609786987\n",
      "Epoch: 484, discriminator loss: 1.3787060976028442, generator loss: 0.663603663444519\n",
      "Epoch: 485, discriminator loss: 1.3925156593322754, generator loss: 0.6554753184318542\n",
      "Epoch: 486, discriminator loss: 1.3905375003814697, generator loss: 0.6781420707702637\n",
      "Epoch: 487, discriminator loss: 1.3892927169799805, generator loss: 0.6959681510925293\n",
      "Epoch: 488, discriminator loss: 1.4025657176971436, generator loss: 0.6932493448257446\n",
      "Epoch: 489, discriminator loss: 1.4152443408966064, generator loss: 0.6785475015640259\n",
      "Epoch: 490, discriminator loss: 1.4321401119232178, generator loss: 0.6540907025337219\n",
      "Epoch: 491, discriminator loss: 1.4421828985214233, generator loss: 0.6455442309379578\n",
      "Epoch: 492, discriminator loss: 1.4337133169174194, generator loss: 0.6445381045341492\n",
      "Epoch: 493, discriminator loss: 1.413762092590332, generator loss: 0.661694347858429\n",
      "Epoch: 494, discriminator loss: 1.3918795585632324, generator loss: 0.6836015582084656\n",
      "Epoch: 495, discriminator loss: 1.3776178359985352, generator loss: 0.7017390131950378\n",
      "Epoch: 496, discriminator loss: 1.3687517642974854, generator loss: 0.7100735306739807\n",
      "Epoch: 497, discriminator loss: 1.368476390838623, generator loss: 0.7065420150756836\n",
      "Epoch: 498, discriminator loss: 1.3745710849761963, generator loss: 0.689195990562439\n",
      "Epoch: 499, discriminator loss: 1.3814446926116943, generator loss: 0.6833521127700806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ganetwork.CGAN at 0x11afcf208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_layers=[(7, None), (4, tf.nn.tanh), (4, tf.nn.tanh), (1, None)]\n",
    "generator_layers=[(10, None), (5, tf.nn.tanh), (4, None)]\n",
    "cgan = CGAN(discriminator_layers, generator_layers)\n",
    "cgan.train(X, y, nb_epoch=500, batch_size=5, discriminator_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_label = 0\n",
    "generated = cgan.generate_samples(45, class_label)\n",
    "x = np.append(X[:, 0], generated[:, 0])\n",
    "y = np.append(X[:, 1], generated[:, 1])\n",
    "label = np.append(ds.target[45:], 3 * np.ones([generated.shape[0]]))\n",
    "colors = ['red','green','blue', 'purple']\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(x, y, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "\n",
    "cb = plt.colorbar()\n",
    "loc = np.arange(0,max(label),max(label)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(colors)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
