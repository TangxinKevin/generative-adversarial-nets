{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../generative-adversarial-nets/')\n",
    "from ganetwork import GAN, CGAN\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds = datasets.load_iris()\n",
    "X, y = minmax_scale(ds.data)[45:, 1:3], LabelBinarizer().fit_transform(ds.target[45:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 2.2629032135009766, generator loss: 0.12869450449943542\n",
      "Epoch: 1, discriminator loss: 1.913238763809204, generator loss: 0.20409491658210754\n",
      "Epoch: 2, discriminator loss: 1.4784075021743774, generator loss: 0.42931032180786133\n",
      "Epoch: 3, discriminator loss: 1.3071783781051636, generator loss: 0.716019332408905\n",
      "Epoch: 4, discriminator loss: 1.3655188083648682, generator loss: 0.8017994165420532\n",
      "Epoch: 5, discriminator loss: 1.3397935628890991, generator loss: 0.7732868790626526\n",
      "Epoch: 6, discriminator loss: 1.4039959907531738, generator loss: 0.7966333627700806\n",
      "Epoch: 7, discriminator loss: 1.4140636920928955, generator loss: 0.6046030521392822\n",
      "Epoch: 8, discriminator loss: 1.4305418729782104, generator loss: 0.6029173135757446\n",
      "Epoch: 9, discriminator loss: 1.5013129711151123, generator loss: 0.576368510723114\n",
      "Epoch: 10, discriminator loss: 1.5230919122695923, generator loss: 0.7033706903457642\n",
      "Epoch: 11, discriminator loss: 1.4950225353240967, generator loss: 0.6006908416748047\n",
      "Epoch: 12, discriminator loss: 1.4588837623596191, generator loss: 0.6109620928764343\n",
      "Epoch: 13, discriminator loss: 1.454266905784607, generator loss: 0.6441126465797424\n",
      "Epoch: 14, discriminator loss: 1.4285216331481934, generator loss: 0.6549370884895325\n",
      "Epoch: 15, discriminator loss: 1.404758095741272, generator loss: 0.6658130884170532\n",
      "Epoch: 16, discriminator loss: 1.3763620853424072, generator loss: 0.6807631254196167\n",
      "Epoch: 17, discriminator loss: 1.3551313877105713, generator loss: 0.6936686635017395\n",
      "Epoch: 18, discriminator loss: 1.3318945169448853, generator loss: 0.7034696340560913\n",
      "Epoch: 19, discriminator loss: 1.3160231113433838, generator loss: 0.7182074785232544\n",
      "Epoch: 20, discriminator loss: 1.239725112915039, generator loss: 0.7232770323753357\n",
      "Epoch: 21, discriminator loss: 1.3419673442840576, generator loss: 0.6962072849273682\n",
      "Epoch: 22, discriminator loss: 1.2558441162109375, generator loss: 0.7053210139274597\n",
      "Epoch: 23, discriminator loss: 1.3620355129241943, generator loss: 0.6460572481155396\n",
      "Epoch: 24, discriminator loss: 1.372473955154419, generator loss: 0.716201901435852\n",
      "Epoch: 25, discriminator loss: 1.3074781894683838, generator loss: 0.7657414674758911\n",
      "Epoch: 26, discriminator loss: 1.3207368850708008, generator loss: 0.678862452507019\n",
      "Epoch: 27, discriminator loss: 1.3758004903793335, generator loss: 0.673778235912323\n",
      "Epoch: 28, discriminator loss: 1.4045789241790771, generator loss: 0.698124885559082\n",
      "Epoch: 29, discriminator loss: 1.4027103185653687, generator loss: 0.7014139294624329\n",
      "Epoch: 30, discriminator loss: 1.3962079286575317, generator loss: 0.7133052349090576\n",
      "Epoch: 31, discriminator loss: 1.3909919261932373, generator loss: 0.7053862810134888\n",
      "Epoch: 32, discriminator loss: 1.3902372121810913, generator loss: 0.7104512453079224\n",
      "Epoch: 33, discriminator loss: 1.391446590423584, generator loss: 0.7165819406509399\n",
      "Epoch: 34, discriminator loss: 1.4062355756759644, generator loss: 0.725355327129364\n",
      "Epoch: 35, discriminator loss: 1.3980634212493896, generator loss: 0.716327428817749\n",
      "Epoch: 36, discriminator loss: 1.3922595977783203, generator loss: 0.7061194777488708\n",
      "Epoch: 37, discriminator loss: 1.3748410940170288, generator loss: 0.7329620718955994\n",
      "Epoch: 38, discriminator loss: 1.3752448558807373, generator loss: 0.7300836443901062\n",
      "Epoch: 39, discriminator loss: 1.409712791442871, generator loss: 0.719186007976532\n",
      "Epoch: 40, discriminator loss: 1.4242303371429443, generator loss: 0.6856710910797119\n",
      "Epoch: 41, discriminator loss: 1.3516483306884766, generator loss: 0.7030538320541382\n",
      "Epoch: 42, discriminator loss: 1.3863756656646729, generator loss: 0.7062151432037354\n",
      "Epoch: 43, discriminator loss: 1.4204145669937134, generator loss: 0.6650604605674744\n",
      "Epoch: 44, discriminator loss: 1.3876023292541504, generator loss: 0.6786544322967529\n",
      "Epoch: 45, discriminator loss: 1.3726778030395508, generator loss: 0.6871596574783325\n",
      "Epoch: 46, discriminator loss: 1.3348338603973389, generator loss: 0.6832165122032166\n",
      "Epoch: 47, discriminator loss: 1.3115646839141846, generator loss: 0.7148562669754028\n",
      "Epoch: 48, discriminator loss: 1.3162672519683838, generator loss: 0.7349783182144165\n",
      "Epoch: 49, discriminator loss: 1.3199807405471802, generator loss: 0.7182902097702026\n",
      "Epoch: 50, discriminator loss: 1.288015365600586, generator loss: 0.7046638131141663\n",
      "Epoch: 51, discriminator loss: 1.34810209274292, generator loss: 0.6809743642807007\n",
      "Epoch: 52, discriminator loss: 1.3837757110595703, generator loss: 0.6550353765487671\n",
      "Epoch: 53, discriminator loss: 1.4303745031356812, generator loss: 0.7124091386795044\n",
      "Epoch: 54, discriminator loss: 1.460876226425171, generator loss: 0.6668763756752014\n",
      "Epoch: 55, discriminator loss: 1.4809060096740723, generator loss: 0.6862979531288147\n",
      "Epoch: 56, discriminator loss: 1.5503132343292236, generator loss: 0.6685696840286255\n",
      "Epoch: 57, discriminator loss: 1.4603828191757202, generator loss: 0.6977511644363403\n",
      "Epoch: 58, discriminator loss: 1.4765620231628418, generator loss: 0.7180818319320679\n",
      "Epoch: 59, discriminator loss: 1.4463156461715698, generator loss: 0.6869956254959106\n",
      "Epoch: 60, discriminator loss: 1.444331169128418, generator loss: 0.6916186809539795\n",
      "Epoch: 61, discriminator loss: 1.405059576034546, generator loss: 0.6857486963272095\n",
      "Epoch: 62, discriminator loss: 1.39376699924469, generator loss: 0.7011483311653137\n",
      "Epoch: 63, discriminator loss: 1.3787459135055542, generator loss: 0.7275254130363464\n",
      "Epoch: 64, discriminator loss: 1.430556058883667, generator loss: 0.7185309529304504\n",
      "Epoch: 65, discriminator loss: 1.403986930847168, generator loss: 0.6831331253051758\n",
      "Epoch: 66, discriminator loss: 1.426863193511963, generator loss: 0.6969416737556458\n",
      "Epoch: 67, discriminator loss: 1.4213367700576782, generator loss: 0.6563196182250977\n",
      "Epoch: 68, discriminator loss: 1.4142742156982422, generator loss: 0.662225067615509\n",
      "Epoch: 69, discriminator loss: 1.4299174547195435, generator loss: 0.6783291697502136\n",
      "Epoch: 70, discriminator loss: 1.397265911102295, generator loss: 0.7010124325752258\n",
      "Epoch: 71, discriminator loss: 1.3890564441680908, generator loss: 0.6545330882072449\n",
      "Epoch: 72, discriminator loss: 1.3829271793365479, generator loss: 0.6848794221878052\n",
      "Epoch: 73, discriminator loss: 1.3490569591522217, generator loss: 0.6980075836181641\n",
      "Epoch: 74, discriminator loss: 1.3453667163848877, generator loss: 0.6958149075508118\n",
      "Epoch: 75, discriminator loss: 1.367586374282837, generator loss: 0.7027191519737244\n",
      "Epoch: 76, discriminator loss: 1.3350214958190918, generator loss: 0.6716758608818054\n",
      "Epoch: 77, discriminator loss: 1.342729091644287, generator loss: 0.6876858472824097\n",
      "Epoch: 78, discriminator loss: 1.3686397075653076, generator loss: 0.7021008729934692\n",
      "Epoch: 79, discriminator loss: 1.3466572761535645, generator loss: 0.6829501390457153\n",
      "Epoch: 80, discriminator loss: 1.3761012554168701, generator loss: 0.7097678184509277\n",
      "Epoch: 81, discriminator loss: 1.3614873886108398, generator loss: 0.6783748865127563\n",
      "Epoch: 82, discriminator loss: 1.389601707458496, generator loss: 0.6887189149856567\n",
      "Epoch: 83, discriminator loss: 1.3945198059082031, generator loss: 0.6920033693313599\n",
      "Epoch: 84, discriminator loss: 1.3838346004486084, generator loss: 0.6858775019645691\n",
      "Epoch: 85, discriminator loss: 1.3851920366287231, generator loss: 0.6952705383300781\n",
      "Epoch: 86, discriminator loss: 1.3790091276168823, generator loss: 0.6815587282180786\n",
      "Epoch: 87, discriminator loss: 1.377466082572937, generator loss: 0.6962531805038452\n",
      "Epoch: 88, discriminator loss: 1.3798549175262451, generator loss: 0.6990917921066284\n",
      "Epoch: 89, discriminator loss: 1.378462791442871, generator loss: 0.6955178380012512\n",
      "Epoch: 90, discriminator loss: 1.3644943237304688, generator loss: 0.7134112119674683\n",
      "Epoch: 91, discriminator loss: 1.360979437828064, generator loss: 0.6939868927001953\n",
      "Epoch: 92, discriminator loss: 1.3673326969146729, generator loss: 0.7063881754875183\n",
      "Epoch: 93, discriminator loss: 1.3613102436065674, generator loss: 0.7040039896965027\n",
      "Epoch: 94, discriminator loss: 1.3800575733184814, generator loss: 0.7006703615188599\n",
      "Epoch: 95, discriminator loss: 1.3901829719543457, generator loss: 0.7113991975784302\n",
      "Epoch: 96, discriminator loss: 1.3987960815429688, generator loss: 0.7000483274459839\n",
      "Epoch: 97, discriminator loss: 1.400058627128601, generator loss: 0.705246090888977\n",
      "Epoch: 98, discriminator loss: 1.4036974906921387, generator loss: 0.6901714205741882\n",
      "Epoch: 99, discriminator loss: 1.4083865880966187, generator loss: 0.6935641765594482\n",
      "Epoch: 100, discriminator loss: 1.4096986055374146, generator loss: 0.6949578523635864\n",
      "Epoch: 101, discriminator loss: 1.4345533847808838, generator loss: 0.6818451285362244\n",
      "Epoch: 102, discriminator loss: 1.3893083333969116, generator loss: 0.6955755352973938\n",
      "Epoch: 103, discriminator loss: 1.4231526851654053, generator loss: 0.6628805994987488\n",
      "Epoch: 104, discriminator loss: 1.3687920570373535, generator loss: 0.6656169891357422\n",
      "Epoch: 105, discriminator loss: 1.412367582321167, generator loss: 0.6517679691314697\n",
      "Epoch: 106, discriminator loss: 1.3839064836502075, generator loss: 0.6393209099769592\n",
      "Epoch: 107, discriminator loss: 1.3997236490249634, generator loss: 0.6874655485153198\n",
      "Epoch: 108, discriminator loss: 1.3761227130889893, generator loss: 0.6540144085884094\n",
      "Epoch: 109, discriminator loss: 1.3629150390625, generator loss: 0.6503429412841797\n",
      "Epoch: 110, discriminator loss: 1.373338222503662, generator loss: 0.703822910785675\n",
      "Epoch: 111, discriminator loss: 1.3639711141586304, generator loss: 0.6954025626182556\n",
      "Epoch: 112, discriminator loss: 1.3635010719299316, generator loss: 0.6927030682563782\n",
      "Epoch: 113, discriminator loss: 1.3297725915908813, generator loss: 0.7151550054550171\n",
      "Epoch: 114, discriminator loss: 1.3749430179595947, generator loss: 0.657249391078949\n",
      "Epoch: 115, discriminator loss: 1.3835755586624146, generator loss: 0.7126187086105347\n",
      "Epoch: 116, discriminator loss: 1.3619134426116943, generator loss: 0.6627150774002075\n",
      "Epoch: 117, discriminator loss: 1.3641815185546875, generator loss: 0.6894332766532898\n",
      "Epoch: 118, discriminator loss: 1.379669427871704, generator loss: 0.7013265490531921\n",
      "Epoch: 119, discriminator loss: 1.330029010772705, generator loss: 0.6837243437767029\n",
      "Epoch: 120, discriminator loss: 1.350926399230957, generator loss: 0.7009441256523132\n",
      "Epoch: 121, discriminator loss: 1.3672027587890625, generator loss: 0.6950676441192627\n",
      "Epoch: 122, discriminator loss: 1.3846001625061035, generator loss: 0.6925405859947205\n",
      "Epoch: 123, discriminator loss: 1.401862621307373, generator loss: 0.6830539703369141\n",
      "Epoch: 124, discriminator loss: 1.3929390907287598, generator loss: 0.6936894059181213\n",
      "Epoch: 125, discriminator loss: 1.4247546195983887, generator loss: 0.6940110921859741\n",
      "Epoch: 126, discriminator loss: 1.4250149726867676, generator loss: 0.6816455125808716\n",
      "Epoch: 127, discriminator loss: 1.4461333751678467, generator loss: 0.6984587907791138\n",
      "Epoch: 128, discriminator loss: 1.4100749492645264, generator loss: 0.7056971788406372\n",
      "Epoch: 129, discriminator loss: 1.398566484451294, generator loss: 0.6773843169212341\n",
      "Epoch: 130, discriminator loss: 1.4084570407867432, generator loss: 0.6940752267837524\n",
      "Epoch: 131, discriminator loss: 1.3881018161773682, generator loss: 0.6967856287956238\n",
      "Epoch: 132, discriminator loss: 1.3854312896728516, generator loss: 0.7213121652603149\n",
      "Epoch: 133, discriminator loss: 1.3742907047271729, generator loss: 0.7136008143424988\n",
      "Epoch: 134, discriminator loss: 1.3688944578170776, generator loss: 0.7060914039611816\n",
      "Epoch: 135, discriminator loss: 1.3621842861175537, generator loss: 0.7099943161010742\n",
      "Epoch: 136, discriminator loss: 1.3445279598236084, generator loss: 0.7001249194145203\n",
      "Epoch: 137, discriminator loss: 1.3346889019012451, generator loss: 0.7051788568496704\n",
      "Epoch: 138, discriminator loss: 1.3542121648788452, generator loss: 0.7003435492515564\n",
      "Epoch: 139, discriminator loss: 1.353323221206665, generator loss: 0.7050865292549133\n",
      "Epoch: 140, discriminator loss: 1.3575712442398071, generator loss: 0.7055238485336304\n",
      "Epoch: 141, discriminator loss: 1.3716142177581787, generator loss: 0.6955224275588989\n",
      "Epoch: 142, discriminator loss: 1.3803105354309082, generator loss: 0.7012251019477844\n",
      "Epoch: 143, discriminator loss: 1.3836547136306763, generator loss: 0.6997750401496887\n",
      "Epoch: 144, discriminator loss: 1.387566328048706, generator loss: 0.7018156051635742\n",
      "Epoch: 145, discriminator loss: 1.3765475749969482, generator loss: 0.6848949790000916\n",
      "Epoch: 146, discriminator loss: 1.393688678741455, generator loss: 0.7001804113388062\n",
      "Epoch: 147, discriminator loss: 1.3971993923187256, generator loss: 0.6906043291091919\n",
      "Epoch: 148, discriminator loss: 1.3899760246276855, generator loss: 0.6797680854797363\n",
      "Epoch: 149, discriminator loss: 1.4322131872177124, generator loss: 0.6592208743095398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ganetwork.GAN at 0x110ea56d8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_layers=[(2, None), (6, tf.nn.tanh), (3, tf.nn.tanh), (1, None)]\n",
    "generator_layers=[(4, None), (8, tf.nn.tanh), (2, None)]\n",
    "gan = GAN(discriminator_layers, generator_layers)\n",
    "gan.train(X, nb_epoch=500, batch_size=5, discriminator_steps=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
