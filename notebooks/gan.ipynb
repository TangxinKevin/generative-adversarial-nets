{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation\n",
    "sys.path.append('../../generative-adversarial-nets')\n",
    "from ganetwork import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "ds = datasets.load_iris()\n",
    "X, y = minmax_scale(ds.data), ds.target\n",
    "\n",
    "generator = Sequential([\n",
    "    Dense(input_dim=10, output_dim=20),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=10),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=X.shape[1]),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "discriminator = Sequential([\n",
    "    Dense(input_dim=X.shape[1], output_dim=20),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=10),\n",
    "    Activation('tanh'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gan = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, d_loss: 0.733443, g_loss: 0.686624\n",
      "Epoch 1, d_loss: 0.722468, g_loss: 0.707663\n",
      "Epoch 2, d_loss: 0.703298, g_loss: 0.708029\n",
      "Epoch 3, d_loss: 0.701735, g_loss: 0.649189\n",
      "Epoch 4, d_loss: 0.675640, g_loss: 0.666315\n",
      "Epoch 5, d_loss: 0.641397, g_loss: 0.701814\n",
      "Epoch 6, d_loss: 0.666495, g_loss: 0.709942\n",
      "Epoch 7, d_loss: 0.661050, g_loss: 0.641241\n",
      "Epoch 8, d_loss: 0.667722, g_loss: 0.683763\n",
      "Epoch 9, d_loss: 0.670775, g_loss: 0.681426\n",
      "Epoch 10, d_loss: 0.679071, g_loss: 0.735773\n",
      "Epoch 11, d_loss: 0.686862, g_loss: 0.732229\n",
      "Epoch 12, d_loss: 0.686104, g_loss: 0.736894\n",
      "Epoch 13, d_loss: 0.680512, g_loss: 0.751620\n",
      "Epoch 14, d_loss: 0.713333, g_loss: 0.711745\n",
      "Epoch 15, d_loss: 0.706775, g_loss: 0.578468\n",
      "Epoch 16, d_loss: 0.752495, g_loss: 0.593935\n",
      "Epoch 17, d_loss: 0.712373, g_loss: 0.635918\n",
      "Epoch 18, d_loss: 0.688240, g_loss: 0.661549\n",
      "Epoch 19, d_loss: 0.695684, g_loss: 0.633602\n",
      "Epoch 20, d_loss: 0.698685, g_loss: 0.627408\n",
      "Epoch 21, d_loss: 0.693086, g_loss: 0.650100\n",
      "Epoch 22, d_loss: 0.705320, g_loss: 0.633662\n",
      "Epoch 23, d_loss: 0.705966, g_loss: 0.638929\n",
      "Epoch 24, d_loss: 0.702914, g_loss: 0.657005\n",
      "Epoch 25, d_loss: 0.713948, g_loss: 0.708026\n",
      "Epoch 26, d_loss: 0.698121, g_loss: 0.667088\n",
      "Epoch 27, d_loss: 0.682757, g_loss: 0.734193\n",
      "Epoch 28, d_loss: 0.689361, g_loss: 0.749681\n",
      "Epoch 29, d_loss: 0.667564, g_loss: 0.759078\n",
      "Epoch 30, d_loss: 0.682700, g_loss: 0.731264\n",
      "Epoch 31, d_loss: 0.675608, g_loss: 0.754266\n",
      "Epoch 32, d_loss: 0.684991, g_loss: 0.725418\n",
      "Epoch 33, d_loss: 0.701877, g_loss: 0.730888\n",
      "Epoch 34, d_loss: 0.702258, g_loss: 0.727347\n",
      "Epoch 35, d_loss: 0.720228, g_loss: 0.691276\n",
      "Epoch 36, d_loss: 0.695107, g_loss: 0.648111\n",
      "Epoch 37, d_loss: 0.683402, g_loss: 0.657171\n",
      "Epoch 38, d_loss: 0.729411, g_loss: 0.692545\n",
      "Epoch 39, d_loss: 0.729142, g_loss: 0.715400\n",
      "Epoch 40, d_loss: 0.722815, g_loss: 0.704861\n",
      "Epoch 41, d_loss: 0.739709, g_loss: 0.700500\n",
      "Epoch 42, d_loss: 0.741335, g_loss: 0.691208\n",
      "Epoch 43, d_loss: 0.732005, g_loss: 0.678613\n",
      "Epoch 44, d_loss: 0.697864, g_loss: 0.683738\n",
      "Epoch 45, d_loss: 0.677503, g_loss: 0.666574\n",
      "Epoch 46, d_loss: 0.632953, g_loss: 0.700957\n",
      "Epoch 47, d_loss: 0.592057, g_loss: 0.758327\n",
      "Epoch 48, d_loss: 0.606447, g_loss: 0.803943\n",
      "Epoch 49, d_loss: 0.623207, g_loss: 0.705954\n",
      "Epoch 50, d_loss: 0.654235, g_loss: 0.657841\n",
      "Epoch 51, d_loss: 0.672458, g_loss: 0.674856\n",
      "Epoch 52, d_loss: 0.677984, g_loss: 0.687216\n",
      "Epoch 53, d_loss: 0.618992, g_loss: 0.778371\n",
      "Epoch 54, d_loss: 0.708118, g_loss: 0.692980\n",
      "Epoch 55, d_loss: 0.697772, g_loss: 0.692219\n",
      "Epoch 56, d_loss: 0.711016, g_loss: 0.702245\n",
      "Epoch 57, d_loss: 0.725530, g_loss: 0.714620\n",
      "Epoch 58, d_loss: 0.747713, g_loss: 0.726098\n",
      "Epoch 59, d_loss: 0.786519, g_loss: 0.719707\n",
      "Epoch 60, d_loss: 0.721218, g_loss: 0.664812\n",
      "Epoch 61, d_loss: 0.751242, g_loss: 0.712508\n",
      "Epoch 62, d_loss: 0.694951, g_loss: 0.680722\n",
      "Epoch 63, d_loss: 0.697878, g_loss: 0.687025\n",
      "Epoch 64, d_loss: 0.695451, g_loss: 0.691518\n",
      "Epoch 65, d_loss: 0.669835, g_loss: 0.683754\n",
      "Epoch 66, d_loss: 0.668482, g_loss: 0.698145\n",
      "Epoch 67, d_loss: 0.668723, g_loss: 0.679624\n",
      "Epoch 68, d_loss: 0.670079, g_loss: 0.682137\n",
      "Epoch 69, d_loss: 0.678127, g_loss: 0.681394\n",
      "Epoch 70, d_loss: 0.666912, g_loss: 0.710663\n",
      "Epoch 71, d_loss: 0.669545, g_loss: 0.693193\n",
      "Epoch 72, d_loss: 0.680578, g_loss: 0.665440\n",
      "Epoch 73, d_loss: 0.672965, g_loss: 0.713457\n",
      "Epoch 74, d_loss: 0.678292, g_loss: 0.682177\n",
      "Epoch 75, d_loss: 0.659523, g_loss: 0.673895\n",
      "Epoch 76, d_loss: 0.657565, g_loss: 0.724156\n",
      "Epoch 77, d_loss: 0.673193, g_loss: 0.730784\n",
      "Epoch 78, d_loss: 0.684797, g_loss: 0.681479\n",
      "Epoch 79, d_loss: 0.673073, g_loss: 0.677830\n",
      "Epoch 80, d_loss: 0.677456, g_loss: 0.711699\n",
      "Epoch 81, d_loss: 0.694656, g_loss: 0.709602\n",
      "Epoch 82, d_loss: 0.691494, g_loss: 0.704031\n",
      "Epoch 83, d_loss: 0.699357, g_loss: 0.690731\n",
      "Epoch 84, d_loss: 0.720883, g_loss: 0.680720\n",
      "Epoch 85, d_loss: 0.724787, g_loss: 0.681227\n",
      "Epoch 86, d_loss: 0.733450, g_loss: 0.705857\n",
      "Epoch 87, d_loss: 0.715594, g_loss: 0.686829\n",
      "Epoch 88, d_loss: 0.707157, g_loss: 0.679851\n",
      "Epoch 89, d_loss: 0.708923, g_loss: 0.662054\n",
      "Epoch 90, d_loss: 0.706296, g_loss: 0.671539\n",
      "Epoch 91, d_loss: 0.699728, g_loss: 0.673814\n",
      "Epoch 92, d_loss: 0.691007, g_loss: 0.678559\n",
      "Epoch 93, d_loss: 0.680431, g_loss: 0.698554\n",
      "Epoch 94, d_loss: 0.688044, g_loss: 0.693883\n",
      "Epoch 95, d_loss: 0.673982, g_loss: 0.717310\n",
      "Epoch 96, d_loss: 0.685515, g_loss: 0.692394\n",
      "Epoch 97, d_loss: 0.672917, g_loss: 0.695657\n",
      "Epoch 98, d_loss: 0.687803, g_loss: 0.686338\n",
      "Epoch 99, d_loss: 0.700852, g_loss: 0.696125\n",
      "Epoch 100, d_loss: 0.690140, g_loss: 0.693201\n",
      "Epoch 101, d_loss: 0.689527, g_loss: 0.683895\n",
      "Epoch 102, d_loss: 0.694460, g_loss: 0.687876\n",
      "Epoch 103, d_loss: 0.690545, g_loss: 0.694270\n",
      "Epoch 104, d_loss: 0.694570, g_loss: 0.683387\n",
      "Epoch 105, d_loss: 0.687689, g_loss: 0.685834\n",
      "Epoch 106, d_loss: 0.689389, g_loss: 0.695107\n",
      "Epoch 107, d_loss: 0.679772, g_loss: 0.671474\n",
      "Epoch 108, d_loss: 0.684511, g_loss: 0.691825\n",
      "Epoch 109, d_loss: 0.691228, g_loss: 0.698948\n",
      "Epoch 110, d_loss: 0.693643, g_loss: 0.698446\n",
      "Epoch 111, d_loss: 0.695427, g_loss: 0.699392\n",
      "Epoch 112, d_loss: 0.696718, g_loss: 0.695357\n",
      "Epoch 113, d_loss: 0.698913, g_loss: 0.694406\n",
      "Epoch 114, d_loss: 0.702824, g_loss: 0.697973\n",
      "Epoch 115, d_loss: 0.695842, g_loss: 0.692392\n",
      "Epoch 116, d_loss: 0.701811, g_loss: 0.711543\n",
      "Epoch 117, d_loss: 0.708023, g_loss: 0.717189\n",
      "Epoch 118, d_loss: 0.690353, g_loss: 0.683532\n",
      "Epoch 119, d_loss: 0.697561, g_loss: 0.697911\n",
      "Epoch 120, d_loss: 0.717441, g_loss: 0.684201\n",
      "Epoch 121, d_loss: 0.698828, g_loss: 0.682531\n",
      "Epoch 122, d_loss: 0.695198, g_loss: 0.679088\n",
      "Epoch 123, d_loss: 0.686675, g_loss: 0.690359\n",
      "Epoch 124, d_loss: 0.682348, g_loss: 0.686284\n",
      "Epoch 125, d_loss: 0.690941, g_loss: 0.712686\n",
      "Epoch 126, d_loss: 0.698775, g_loss: 0.711764\n",
      "Epoch 127, d_loss: 0.680209, g_loss: 0.705516\n",
      "Epoch 128, d_loss: 0.685646, g_loss: 0.695382\n",
      "Epoch 129, d_loss: 0.687543, g_loss: 0.708275\n",
      "Epoch 130, d_loss: 0.690008, g_loss: 0.685143\n",
      "Epoch 131, d_loss: 0.694291, g_loss: 0.698533\n",
      "Epoch 132, d_loss: 0.692657, g_loss: 0.692657\n",
      "Epoch 133, d_loss: 0.690486, g_loss: 0.689076\n",
      "Epoch 134, d_loss: 0.691273, g_loss: 0.689626\n",
      "Epoch 135, d_loss: 0.711442, g_loss: 0.681241\n",
      "Epoch 136, d_loss: 0.708924, g_loss: 0.698970\n",
      "Epoch 137, d_loss: 0.711901, g_loss: 0.679204\n",
      "Epoch 138, d_loss: 0.693785, g_loss: 0.664626\n",
      "Epoch 139, d_loss: 0.694545, g_loss: 0.672508\n",
      "Epoch 140, d_loss: 0.692546, g_loss: 0.678219\n",
      "Epoch 141, d_loss: 0.682353, g_loss: 0.709376\n",
      "Epoch 142, d_loss: 0.685184, g_loss: 0.684078\n",
      "Epoch 143, d_loss: 0.674575, g_loss: 0.679666\n",
      "Epoch 144, d_loss: 0.670881, g_loss: 0.660406\n",
      "Epoch 145, d_loss: 0.692863, g_loss: 0.692378\n",
      "Epoch 146, d_loss: 0.688635, g_loss: 0.693042\n",
      "Epoch 147, d_loss: 0.689759, g_loss: 0.683475\n",
      "Epoch 148, d_loss: 0.701828, g_loss: 0.707655\n",
      "Epoch 149, d_loss: 0.682640, g_loss: 0.696941\n",
      "Epoch 150, d_loss: 0.701345, g_loss: 0.712166\n",
      "Epoch 151, d_loss: 0.703772, g_loss: 0.701588\n",
      "Epoch 152, d_loss: 0.703084, g_loss: 0.691691\n",
      "Epoch 153, d_loss: 0.705974, g_loss: 0.662677\n",
      "Epoch 154, d_loss: 0.710893, g_loss: 0.686997\n",
      "Epoch 155, d_loss: 0.704573, g_loss: 0.683432\n",
      "Epoch 156, d_loss: 0.706997, g_loss: 0.674042\n",
      "Epoch 157, d_loss: 0.701438, g_loss: 0.679605\n",
      "Epoch 158, d_loss: 0.695014, g_loss: 0.683654\n",
      "Epoch 159, d_loss: 0.688800, g_loss: 0.688609\n",
      "Epoch 160, d_loss: 0.688473, g_loss: 0.691513\n",
      "Epoch 161, d_loss: 0.689601, g_loss: 0.694310\n",
      "Epoch 162, d_loss: 0.688162, g_loss: 0.690353\n",
      "Epoch 163, d_loss: 0.691178, g_loss: 0.696658\n",
      "Epoch 164, d_loss: 0.689848, g_loss: 0.695773\n",
      "Epoch 165, d_loss: 0.690886, g_loss: 0.692462\n",
      "Epoch 166, d_loss: 0.692869, g_loss: 0.695314\n",
      "Epoch 167, d_loss: 0.694986, g_loss: 0.690685\n",
      "Epoch 168, d_loss: 0.695937, g_loss: 0.690967\n",
      "Epoch 169, d_loss: 0.694499, g_loss: 0.686193\n",
      "Epoch 170, d_loss: 0.698614, g_loss: 0.689543\n",
      "Epoch 171, d_loss: 0.704511, g_loss: 0.680473\n",
      "Epoch 172, d_loss: 0.693952, g_loss: 0.682887\n",
      "Epoch 173, d_loss: 0.679433, g_loss: 0.692601\n",
      "Epoch 174, d_loss: 0.667452, g_loss: 0.686756\n",
      "Epoch 175, d_loss: 0.661915, g_loss: 0.682570\n",
      "Epoch 176, d_loss: 0.660696, g_loss: 0.677291\n",
      "Epoch 177, d_loss: 0.680635, g_loss: 0.698053\n",
      "Epoch 178, d_loss: 0.684952, g_loss: 0.694868\n",
      "Epoch 179, d_loss: 0.688538, g_loss: 0.680982\n",
      "Epoch 180, d_loss: 0.689655, g_loss: 0.697003\n",
      "Epoch 181, d_loss: 0.707075, g_loss: 0.679554\n",
      "Epoch 182, d_loss: 0.704198, g_loss: 0.662950\n",
      "Epoch 183, d_loss: 0.688630, g_loss: 0.672039\n",
      "Epoch 184, d_loss: 0.683229, g_loss: 0.694498\n",
      "Epoch 185, d_loss: 0.681684, g_loss: 0.671144\n",
      "Epoch 186, d_loss: 0.686682, g_loss: 0.689324\n",
      "Epoch 187, d_loss: 0.688769, g_loss: 0.685695\n",
      "Epoch 188, d_loss: 0.686327, g_loss: 0.678097\n",
      "Epoch 189, d_loss: 0.683528, g_loss: 0.721906\n",
      "Epoch 190, d_loss: 0.692604, g_loss: 0.680453\n",
      "Epoch 191, d_loss: 0.692510, g_loss: 0.690831\n",
      "Epoch 192, d_loss: 0.698068, g_loss: 0.686905\n",
      "Epoch 193, d_loss: 0.692350, g_loss: 0.684504\n",
      "Epoch 194, d_loss: 0.699662, g_loss: 0.681480\n",
      "Epoch 195, d_loss: 0.692902, g_loss: 0.688734\n",
      "Epoch 196, d_loss: 0.701126, g_loss: 0.677564\n",
      "Epoch 197, d_loss: 0.693765, g_loss: 0.697686\n",
      "Epoch 198, d_loss: 0.701589, g_loss: 0.678625\n",
      "Epoch 199, d_loss: 0.695863, g_loss: 0.653727\n"
     ]
    }
   ],
   "source": [
    "gan.train(X, nb_epoch=200, batch_size=5, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
