{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation\n",
    "sys.path.append('../../generative-adversarial-nets')\n",
    "from ganetwork import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "ds = datasets.load_iris()\n",
    "X, y = minmax_scale(ds.data), ds.target\n",
    "\n",
    "generator = Sequential([\n",
    "    Dense(input_dim=10, output_dim=20),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=10),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=X.shape[1]),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "discriminator = Sequential([\n",
    "    Dense(input_dim=X.shape[1], output_dim=20),\n",
    "    Activation('tanh'),\n",
    "    Dense(output_dim=10),\n",
    "    Activation('tanh'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gan = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, d_loss: 0.688361, g_loss: 0.547211\n",
      "Epoch 1, d_loss: 0.662959, g_loss: 0.612207\n",
      "Epoch 2, d_loss: 0.662292, g_loss: 0.698085\n",
      "Epoch 3, d_loss: 0.687810, g_loss: 0.688179\n",
      "Epoch 4, d_loss: 0.687969, g_loss: 0.671383\n",
      "Epoch 5, d_loss: 0.686462, g_loss: 0.764448\n",
      "Epoch 6, d_loss: 0.695048, g_loss: 0.739535\n",
      "Epoch 7, d_loss: 0.678516, g_loss: 0.752493\n",
      "Epoch 8, d_loss: 0.690278, g_loss: 0.723806\n",
      "Epoch 9, d_loss: 0.699007, g_loss: 0.730800\n",
      "Epoch 10, d_loss: 0.687783, g_loss: 0.750938\n",
      "Epoch 11, d_loss: 0.695909, g_loss: 0.718407\n",
      "Epoch 12, d_loss: 0.691980, g_loss: 0.740280\n",
      "Epoch 13, d_loss: 0.690894, g_loss: 0.728234\n",
      "Epoch 14, d_loss: 0.697552, g_loss: 0.737980\n",
      "Epoch 15, d_loss: 0.696810, g_loss: 0.743851\n",
      "Epoch 16, d_loss: 0.696895, g_loss: 0.744528\n",
      "Epoch 17, d_loss: 0.692848, g_loss: 0.752015\n",
      "Epoch 18, d_loss: 0.692207, g_loss: 0.742462\n",
      "Epoch 19, d_loss: 0.694538, g_loss: 0.752389\n",
      "Epoch 20, d_loss: 0.693867, g_loss: 0.750112\n",
      "Epoch 21, d_loss: 0.694884, g_loss: 0.752999\n",
      "Epoch 22, d_loss: 0.692237, g_loss: 0.770351\n",
      "Epoch 23, d_loss: 0.695486, g_loss: 0.756555\n",
      "Epoch 24, d_loss: 0.688960, g_loss: 0.754672\n",
      "Epoch 25, d_loss: 0.688728, g_loss: 0.766066\n",
      "Epoch 26, d_loss: 0.691731, g_loss: 0.759641\n",
      "Epoch 27, d_loss: 0.686142, g_loss: 0.766634\n",
      "Epoch 28, d_loss: 0.688730, g_loss: 0.761162\n",
      "Epoch 29, d_loss: 0.684539, g_loss: 0.772352\n",
      "Epoch 30, d_loss: 0.685379, g_loss: 0.774664\n",
      "Epoch 31, d_loss: 0.681511, g_loss: 0.783832\n",
      "Epoch 32, d_loss: 0.686062, g_loss: 0.779650\n",
      "Epoch 33, d_loss: 0.681795, g_loss: 0.766931\n",
      "Epoch 34, d_loss: 0.692061, g_loss: 0.768834\n",
      "Epoch 35, d_loss: 0.680606, g_loss: 0.767343\n",
      "Epoch 36, d_loss: 0.686619, g_loss: 0.756238\n",
      "Epoch 37, d_loss: 0.674939, g_loss: 0.761730\n",
      "Epoch 38, d_loss: 0.684751, g_loss: 0.787917\n",
      "Epoch 39, d_loss: 0.679828, g_loss: 0.771447\n",
      "Epoch 40, d_loss: 0.677802, g_loss: 0.771830\n",
      "Epoch 41, d_loss: 0.685461, g_loss: 0.775519\n",
      "Epoch 42, d_loss: 0.691844, g_loss: 0.731699\n",
      "Epoch 43, d_loss: 0.686308, g_loss: 0.776914\n",
      "Epoch 44, d_loss: 0.699143, g_loss: 0.739230\n",
      "Epoch 45, d_loss: 0.681452, g_loss: 0.767630\n",
      "Epoch 46, d_loss: 0.690284, g_loss: 0.760438\n",
      "Epoch 47, d_loss: 0.681624, g_loss: 0.781684\n",
      "Epoch 48, d_loss: 0.673383, g_loss: 0.791576\n",
      "Epoch 49, d_loss: 0.687741, g_loss: 0.737696\n",
      "Epoch 50, d_loss: 0.707160, g_loss: 0.740668\n",
      "Epoch 51, d_loss: 0.684220, g_loss: 0.750110\n",
      "Epoch 52, d_loss: 0.681319, g_loss: 0.761095\n",
      "Epoch 53, d_loss: 0.693721, g_loss: 0.755305\n",
      "Epoch 54, d_loss: 0.693254, g_loss: 0.724558\n",
      "Epoch 55, d_loss: 0.681684, g_loss: 0.765275\n",
      "Epoch 56, d_loss: 0.687115, g_loss: 0.745882\n",
      "Epoch 57, d_loss: 0.694063, g_loss: 0.789940\n",
      "Epoch 58, d_loss: 0.697393, g_loss: 0.761950\n",
      "Epoch 59, d_loss: 0.696790, g_loss: 0.748766\n",
      "Epoch 60, d_loss: 0.697547, g_loss: 0.772397\n",
      "Epoch 61, d_loss: 0.711768, g_loss: 0.728178\n",
      "Epoch 62, d_loss: 0.705201, g_loss: 0.760092\n",
      "Epoch 63, d_loss: 0.702816, g_loss: 0.773566\n",
      "Epoch 64, d_loss: 0.701009, g_loss: 0.725087\n",
      "Epoch 65, d_loss: 0.695540, g_loss: 0.772934\n",
      "Epoch 66, d_loss: 0.693202, g_loss: 0.724027\n",
      "Epoch 67, d_loss: 0.698846, g_loss: 0.739290\n",
      "Epoch 68, d_loss: 0.695240, g_loss: 0.729431\n",
      "Epoch 69, d_loss: 0.702649, g_loss: 0.766471\n",
      "Epoch 70, d_loss: 0.696030, g_loss: 0.747654\n",
      "Epoch 71, d_loss: 0.687822, g_loss: 0.753725\n",
      "Epoch 72, d_loss: 0.691916, g_loss: 0.736363\n",
      "Epoch 73, d_loss: 0.687814, g_loss: 0.720497\n",
      "Epoch 74, d_loss: 0.688863, g_loss: 0.758821\n",
      "Epoch 75, d_loss: 0.692815, g_loss: 0.733889\n",
      "Epoch 76, d_loss: 0.698374, g_loss: 0.760519\n",
      "Epoch 77, d_loss: 0.667180, g_loss: 0.768252\n",
      "Epoch 78, d_loss: 0.672019, g_loss: 0.751944\n",
      "Epoch 79, d_loss: 0.675967, g_loss: 0.751916\n",
      "Epoch 80, d_loss: 0.668058, g_loss: 0.762867\n",
      "Epoch 81, d_loss: 0.662676, g_loss: 0.757650\n",
      "Epoch 82, d_loss: 0.661020, g_loss: 0.761480\n",
      "Epoch 83, d_loss: 0.663564, g_loss: 0.722888\n",
      "Epoch 84, d_loss: 0.663061, g_loss: 0.774018\n",
      "Epoch 85, d_loss: 0.667262, g_loss: 0.734611\n",
      "Epoch 86, d_loss: 0.664785, g_loss: 0.769121\n",
      "Epoch 87, d_loss: 0.647121, g_loss: 0.763755\n",
      "Epoch 88, d_loss: 0.657847, g_loss: 0.775367\n",
      "Epoch 89, d_loss: 0.643667, g_loss: 0.729913\n",
      "Epoch 90, d_loss: 0.632213, g_loss: 0.764923\n",
      "Epoch 91, d_loss: 0.633496, g_loss: 0.756052\n",
      "Epoch 92, d_loss: 0.655742, g_loss: 0.763560\n",
      "Epoch 93, d_loss: 0.636566, g_loss: 0.776054\n",
      "Epoch 94, d_loss: 0.631374, g_loss: 0.803507\n",
      "Epoch 95, d_loss: 0.631960, g_loss: 0.723569\n",
      "Epoch 96, d_loss: 0.624132, g_loss: 0.770996\n",
      "Epoch 97, d_loss: 0.638542, g_loss: 0.762361\n",
      "Epoch 98, d_loss: 0.626700, g_loss: 0.765274\n",
      "Epoch 99, d_loss: 0.633913, g_loss: 0.780193\n",
      "Epoch 100, d_loss: 0.618253, g_loss: 0.772697\n",
      "Epoch 101, d_loss: 0.646236, g_loss: 0.786549\n",
      "Epoch 102, d_loss: 0.607706, g_loss: 0.813249\n",
      "Epoch 103, d_loss: 0.613360, g_loss: 0.757614\n",
      "Epoch 104, d_loss: 0.636366, g_loss: 0.781471\n",
      "Epoch 105, d_loss: 0.636245, g_loss: 0.724885\n",
      "Epoch 106, d_loss: 0.652428, g_loss: 0.817290\n",
      "Epoch 107, d_loss: 0.630055, g_loss: 0.763090\n",
      "Epoch 108, d_loss: 0.645701, g_loss: 0.819161\n",
      "Epoch 109, d_loss: 0.675165, g_loss: 0.845773\n",
      "Epoch 110, d_loss: 0.639117, g_loss: 0.815843\n",
      "Epoch 111, d_loss: 0.615299, g_loss: 0.757899\n",
      "Epoch 112, d_loss: 0.638241, g_loss: 0.787150\n",
      "Epoch 113, d_loss: 0.625814, g_loss: 0.716506\n",
      "Epoch 114, d_loss: 0.634428, g_loss: 0.809392\n",
      "Epoch 115, d_loss: 0.652174, g_loss: 0.801744\n",
      "Epoch 116, d_loss: 0.612560, g_loss: 0.730090\n",
      "Epoch 117, d_loss: 0.649298, g_loss: 0.797394\n",
      "Epoch 118, d_loss: 0.626797, g_loss: 0.703628\n",
      "Epoch 119, d_loss: 0.617302, g_loss: 0.665488\n",
      "Epoch 120, d_loss: 0.644223, g_loss: 0.733508\n",
      "Epoch 121, d_loss: 0.631036, g_loss: 0.829021\n",
      "Epoch 122, d_loss: 0.627733, g_loss: 0.707793\n",
      "Epoch 123, d_loss: 0.644470, g_loss: 0.568968\n",
      "Epoch 124, d_loss: 0.675603, g_loss: 0.739263\n",
      "Epoch 125, d_loss: 0.697273, g_loss: 0.637119\n",
      "Epoch 126, d_loss: 0.681434, g_loss: 0.652288\n",
      "Epoch 127, d_loss: 0.620984, g_loss: 0.763499\n",
      "Epoch 128, d_loss: 0.704485, g_loss: 0.623080\n",
      "Epoch 129, d_loss: 0.602431, g_loss: 0.687177\n",
      "Epoch 130, d_loss: 0.646956, g_loss: 0.794997\n",
      "Epoch 131, d_loss: 0.640811, g_loss: 0.769752\n",
      "Epoch 132, d_loss: 0.656933, g_loss: 0.724046\n",
      "Epoch 133, d_loss: 0.621666, g_loss: 0.670550\n",
      "Epoch 134, d_loss: 0.622401, g_loss: 0.689117\n",
      "Epoch 135, d_loss: 0.640361, g_loss: 0.746816\n",
      "Epoch 136, d_loss: 0.609556, g_loss: 0.774308\n",
      "Epoch 137, d_loss: 0.689462, g_loss: 0.744835\n",
      "Epoch 138, d_loss: 0.595328, g_loss: 0.599259\n",
      "Epoch 139, d_loss: 0.723617, g_loss: 0.750782\n",
      "Epoch 140, d_loss: 0.680201, g_loss: 0.684404\n",
      "Epoch 141, d_loss: 0.663551, g_loss: 0.649919\n",
      "Epoch 142, d_loss: 0.638772, g_loss: 0.707775\n",
      "Epoch 143, d_loss: 0.676237, g_loss: 0.758307\n",
      "Epoch 144, d_loss: 0.697320, g_loss: 0.645271\n",
      "Epoch 145, d_loss: 0.661144, g_loss: 0.716624\n",
      "Epoch 146, d_loss: 0.694816, g_loss: 0.682026\n",
      "Epoch 147, d_loss: 0.711996, g_loss: 0.730900\n",
      "Epoch 148, d_loss: 0.646356, g_loss: 0.772299\n",
      "Epoch 149, d_loss: 0.594921, g_loss: 0.763781\n",
      "Epoch 150, d_loss: 0.615967, g_loss: 0.619705\n",
      "Epoch 151, d_loss: 0.674083, g_loss: 0.655880\n",
      "Epoch 152, d_loss: 0.673172, g_loss: 0.657790\n",
      "Epoch 153, d_loss: 0.699615, g_loss: 0.753182\n",
      "Epoch 154, d_loss: 0.673773, g_loss: 0.627681\n",
      "Epoch 155, d_loss: 0.684656, g_loss: 0.710382\n",
      "Epoch 156, d_loss: 0.691833, g_loss: 0.788047\n",
      "Epoch 157, d_loss: 0.686061, g_loss: 0.747143\n",
      "Epoch 158, d_loss: 0.678950, g_loss: 0.682321\n",
      "Epoch 159, d_loss: 0.654736, g_loss: 0.695705\n",
      "Epoch 160, d_loss: 0.636563, g_loss: 0.692573\n",
      "Epoch 161, d_loss: 0.696049, g_loss: 0.667360\n",
      "Epoch 162, d_loss: 0.703852, g_loss: 0.674673\n",
      "Epoch 163, d_loss: 0.713463, g_loss: 0.618649\n",
      "Epoch 164, d_loss: 0.670199, g_loss: 0.767858\n",
      "Epoch 165, d_loss: 0.646411, g_loss: 0.674169\n",
      "Epoch 166, d_loss: 0.677543, g_loss: 0.680647\n",
      "Epoch 167, d_loss: 0.702558, g_loss: 0.632234\n",
      "Epoch 168, d_loss: 0.679698, g_loss: 0.627055\n",
      "Epoch 169, d_loss: 0.653723, g_loss: 0.674097\n",
      "Epoch 170, d_loss: 0.690218, g_loss: 0.700731\n",
      "Epoch 171, d_loss: 0.654330, g_loss: 0.678103\n",
      "Epoch 172, d_loss: 0.650519, g_loss: 0.741345\n",
      "Epoch 173, d_loss: 0.644680, g_loss: 0.636121\n",
      "Epoch 174, d_loss: 0.666717, g_loss: 0.698566\n",
      "Epoch 175, d_loss: 0.669593, g_loss: 0.673990\n",
      "Epoch 176, d_loss: 0.655716, g_loss: 0.677005\n",
      "Epoch 177, d_loss: 0.679886, g_loss: 0.718621\n",
      "Epoch 178, d_loss: 0.678165, g_loss: 0.710682\n",
      "Epoch 179, d_loss: 0.677564, g_loss: 0.662404\n",
      "Epoch 180, d_loss: 0.664447, g_loss: 0.681652\n",
      "Epoch 181, d_loss: 0.682448, g_loss: 0.699445\n",
      "Epoch 182, d_loss: 0.643276, g_loss: 0.665218\n",
      "Epoch 183, d_loss: 0.674279, g_loss: 0.682395\n",
      "Epoch 184, d_loss: 0.653265, g_loss: 0.697905\n",
      "Epoch 185, d_loss: 0.606796, g_loss: 0.665807\n",
      "Epoch 186, d_loss: 0.675566, g_loss: 0.713573\n",
      "Epoch 187, d_loss: 0.662329, g_loss: 0.711084\n",
      "Epoch 188, d_loss: 0.671763, g_loss: 0.746370\n",
      "Epoch 189, d_loss: 0.669229, g_loss: 0.755388\n",
      "Epoch 190, d_loss: 0.655757, g_loss: 0.722442\n",
      "Epoch 191, d_loss: 0.665505, g_loss: 0.750656\n",
      "Epoch 192, d_loss: 0.654864, g_loss: 0.697165\n",
      "Epoch 193, d_loss: 0.649265, g_loss: 0.682806\n",
      "Epoch 194, d_loss: 0.653635, g_loss: 0.669505\n",
      "Epoch 195, d_loss: 0.647051, g_loss: 0.712156\n",
      "Epoch 196, d_loss: 0.653058, g_loss: 0.695215\n",
      "Epoch 197, d_loss: 0.656556, g_loss: 0.716700\n",
      "Epoch 198, d_loss: 0.656736, g_loss: 0.692058\n",
      "Epoch 199, d_loss: 0.659898, g_loss: 0.710707\n"
     ]
    }
   ],
   "source": [
    "gan.train(X, nb_epoch=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
