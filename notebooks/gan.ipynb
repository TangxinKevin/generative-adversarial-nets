{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append('../../generative-adversarial-nets/')\n",
    "from ganetwork import GAN, CGAN\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds = datasets.load_iris()\n",
    "X, y = minmax_scale(ds.data), LabelBinarizer().fit_transform(ds.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 1.490799903869629, generator loss: 0.4140889048576355\n",
      "Epoch: 1, discriminator loss: 1.4364362955093384, generator loss: 0.49492472410202026\n",
      "Epoch: 2, discriminator loss: 1.404874324798584, generator loss: 0.5674110651016235\n",
      "Epoch: 3, discriminator loss: 1.391737461090088, generator loss: 0.6212331652641296\n",
      "Epoch: 4, discriminator loss: 1.386643648147583, generator loss: 0.6517943143844604\n",
      "Epoch: 5, discriminator loss: 1.375281572341919, generator loss: 0.6671280860900879\n",
      "Epoch: 6, discriminator loss: 1.3614658117294312, generator loss: 0.681520938873291\n",
      "Epoch: 7, discriminator loss: 1.3589646816253662, generator loss: 0.6202360987663269\n",
      "Epoch: 8, discriminator loss: 1.4632829427719116, generator loss: 0.6730211973190308\n",
      "Epoch: 9, discriminator loss: 1.4941837787628174, generator loss: 0.7115226984024048\n",
      "Epoch: 10, discriminator loss: 1.4735699892044067, generator loss: 0.626997709274292\n",
      "Epoch: 11, discriminator loss: 1.3734543323516846, generator loss: 0.6678651571273804\n",
      "Epoch: 12, discriminator loss: 1.4374909400939941, generator loss: 0.716650128364563\n",
      "Epoch: 13, discriminator loss: 1.3950132131576538, generator loss: 0.6866176128387451\n",
      "Epoch: 14, discriminator loss: 1.3933372497558594, generator loss: 0.684554934501648\n",
      "Epoch: 15, discriminator loss: 1.385643720626831, generator loss: 0.6944129467010498\n",
      "Epoch: 16, discriminator loss: 1.3742945194244385, generator loss: 0.697773814201355\n",
      "Epoch: 17, discriminator loss: 1.3603273630142212, generator loss: 0.683029055595398\n",
      "Epoch: 18, discriminator loss: 1.3546950817108154, generator loss: 0.7045916318893433\n",
      "Epoch: 19, discriminator loss: 1.3464479446411133, generator loss: 0.7038028240203857\n",
      "Epoch: 20, discriminator loss: 1.3610806465148926, generator loss: 0.7058974504470825\n",
      "Epoch: 21, discriminator loss: 1.3628873825073242, generator loss: 0.720647931098938\n",
      "Epoch: 22, discriminator loss: 1.363335371017456, generator loss: 0.718489408493042\n",
      "Epoch: 23, discriminator loss: 1.3686308860778809, generator loss: 0.6905803680419922\n",
      "Epoch: 24, discriminator loss: 1.375304937362671, generator loss: 0.6966537833213806\n",
      "Epoch: 25, discriminator loss: 1.3761274814605713, generator loss: 0.7028347253799438\n",
      "Epoch: 26, discriminator loss: 1.384096622467041, generator loss: 0.6949799060821533\n",
      "Epoch: 27, discriminator loss: 1.3844050168991089, generator loss: 0.6936373114585876\n",
      "Epoch: 28, discriminator loss: 1.386317491531372, generator loss: 0.6969408988952637\n",
      "Epoch: 29, discriminator loss: 1.3942673206329346, generator loss: 0.6925040483474731\n",
      "Epoch: 30, discriminator loss: 1.3999440670013428, generator loss: 0.6971018314361572\n",
      "Epoch: 31, discriminator loss: 1.403390645980835, generator loss: 0.6971076726913452\n",
      "Epoch: 32, discriminator loss: 1.4077706336975098, generator loss: 0.6919695138931274\n",
      "Epoch: 33, discriminator loss: 1.4029350280761719, generator loss: 0.6995797753334045\n",
      "Epoch: 34, discriminator loss: 1.3910424709320068, generator loss: 0.6910500526428223\n",
      "Epoch: 35, discriminator loss: 1.3896725177764893, generator loss: 0.691908597946167\n",
      "Epoch: 36, discriminator loss: 1.3956317901611328, generator loss: 0.6887077689170837\n",
      "Epoch: 37, discriminator loss: 1.389026165008545, generator loss: 0.6889187097549438\n",
      "Epoch: 38, discriminator loss: 1.375654935836792, generator loss: 0.6926994919776917\n",
      "Epoch: 39, discriminator loss: 1.3727238178253174, generator loss: 0.6882201433181763\n",
      "Epoch: 40, discriminator loss: 1.3779195547103882, generator loss: 0.6893314719200134\n",
      "Epoch: 41, discriminator loss: 1.3669005632400513, generator loss: 0.6879122257232666\n",
      "Epoch: 42, discriminator loss: 1.3813848495483398, generator loss: 0.6818720102310181\n",
      "Epoch: 43, discriminator loss: 1.3771557807922363, generator loss: 0.6916128396987915\n",
      "Epoch: 44, discriminator loss: 1.3741745948791504, generator loss: 0.6954315304756165\n",
      "Epoch: 45, discriminator loss: 1.3787438869476318, generator loss: 0.696926474571228\n",
      "Epoch: 46, discriminator loss: 1.381112813949585, generator loss: 0.6913379430770874\n",
      "Epoch: 47, discriminator loss: 1.38895583152771, generator loss: 0.693216860294342\n",
      "Epoch: 48, discriminator loss: 1.3899569511413574, generator loss: 0.686593770980835\n",
      "Epoch: 49, discriminator loss: 1.387427806854248, generator loss: 0.6942282319068909\n",
      "Epoch: 50, discriminator loss: 1.3913159370422363, generator loss: 0.690597414970398\n",
      "Epoch: 51, discriminator loss: 1.3896023035049438, generator loss: 0.6858314275741577\n",
      "Epoch: 52, discriminator loss: 1.3817503452301025, generator loss: 0.6884058713912964\n",
      "Epoch: 53, discriminator loss: 1.3889570236206055, generator loss: 0.6892064213752747\n",
      "Epoch: 54, discriminator loss: 1.382380723953247, generator loss: 0.6883216500282288\n",
      "Epoch: 55, discriminator loss: 1.3855929374694824, generator loss: 0.6924662590026855\n",
      "Epoch: 56, discriminator loss: 1.383821964263916, generator loss: 0.6910213232040405\n",
      "Epoch: 57, discriminator loss: 1.3841395378112793, generator loss: 0.6909242868423462\n",
      "Epoch: 58, discriminator loss: 1.3895230293273926, generator loss: 0.6943103075027466\n",
      "Epoch: 59, discriminator loss: 1.390281081199646, generator loss: 0.6899365186691284\n",
      "Epoch: 60, discriminator loss: 1.4088866710662842, generator loss: 0.6932727694511414\n",
      "Epoch: 61, discriminator loss: 1.3955237865447998, generator loss: 0.6888495683670044\n",
      "Epoch: 62, discriminator loss: 1.3959413766860962, generator loss: 0.6879485249519348\n",
      "Epoch: 63, discriminator loss: 1.3998818397521973, generator loss: 0.6788733601570129\n",
      "Epoch: 64, discriminator loss: 1.3945949077606201, generator loss: 0.6791952848434448\n",
      "Epoch: 65, discriminator loss: 1.3839309215545654, generator loss: 0.68951016664505\n",
      "Epoch: 66, discriminator loss: 1.4017581939697266, generator loss: 0.7009307146072388\n",
      "Epoch: 67, discriminator loss: 1.380357027053833, generator loss: 0.7000149488449097\n",
      "Epoch: 68, discriminator loss: 1.3802884817123413, generator loss: 0.6780972480773926\n",
      "Epoch: 69, discriminator loss: 1.3726155757904053, generator loss: 0.6893177628517151\n",
      "Epoch: 70, discriminator loss: 1.363135576248169, generator loss: 0.6908800601959229\n",
      "Epoch: 71, discriminator loss: 1.368739366531372, generator loss: 0.688947856426239\n",
      "Epoch: 72, discriminator loss: 1.3340144157409668, generator loss: 0.6943173408508301\n",
      "Epoch: 73, discriminator loss: 1.3484983444213867, generator loss: 0.6951379776000977\n",
      "Epoch: 74, discriminator loss: 1.3516913652420044, generator loss: 0.6836153864860535\n",
      "Epoch: 75, discriminator loss: 1.3589990139007568, generator loss: 0.6939131021499634\n",
      "Epoch: 76, discriminator loss: 1.3556408882141113, generator loss: 0.7015881538391113\n",
      "Epoch: 77, discriminator loss: 1.3755803108215332, generator loss: 0.7000489234924316\n",
      "Epoch: 78, discriminator loss: 1.3836477994918823, generator loss: 0.6956945657730103\n",
      "Epoch: 79, discriminator loss: 1.4001550674438477, generator loss: 0.6967183947563171\n",
      "Epoch: 80, discriminator loss: 1.4295861721038818, generator loss: 0.7194622159004211\n",
      "Epoch: 81, discriminator loss: 1.4132964611053467, generator loss: 0.691050112247467\n",
      "Epoch: 82, discriminator loss: 1.4052798748016357, generator loss: 0.6930345892906189\n",
      "Epoch: 83, discriminator loss: 1.421707034111023, generator loss: 0.6313127279281616\n",
      "Epoch: 84, discriminator loss: 1.395890712738037, generator loss: 0.6935349702835083\n",
      "Epoch: 85, discriminator loss: 1.3676917552947998, generator loss: 0.675118625164032\n",
      "Epoch: 86, discriminator loss: 1.37651526927948, generator loss: 0.6484878659248352\n",
      "Epoch: 87, discriminator loss: 1.322136402130127, generator loss: 0.7047893404960632\n",
      "Epoch: 88, discriminator loss: 1.3144943714141846, generator loss: 0.7135569453239441\n",
      "Epoch: 89, discriminator loss: 1.321117639541626, generator loss: 0.6731675863265991\n",
      "Epoch: 90, discriminator loss: 1.3320872783660889, generator loss: 0.6516598463058472\n",
      "Epoch: 91, discriminator loss: 1.3484129905700684, generator loss: 0.7069944143295288\n",
      "Epoch: 92, discriminator loss: 1.3560664653778076, generator loss: 0.687111496925354\n",
      "Epoch: 93, discriminator loss: 1.3635269403457642, generator loss: 0.6825025081634521\n",
      "Epoch: 94, discriminator loss: 1.3861281871795654, generator loss: 0.677905797958374\n",
      "Epoch: 95, discriminator loss: 1.3702545166015625, generator loss: 0.6973577737808228\n",
      "Epoch: 96, discriminator loss: 1.3719720840454102, generator loss: 0.6922942399978638\n",
      "Epoch: 97, discriminator loss: 1.3564121723175049, generator loss: 0.699274480342865\n",
      "Epoch: 98, discriminator loss: 1.3736236095428467, generator loss: 0.6895702481269836\n",
      "Epoch: 99, discriminator loss: 1.3889998197555542, generator loss: 0.6957886815071106\n",
      "Epoch: 100, discriminator loss: 1.4191713333129883, generator loss: 0.6912297010421753\n",
      "Epoch: 101, discriminator loss: 1.4396300315856934, generator loss: 0.7223790287971497\n",
      "Epoch: 102, discriminator loss: 1.4021730422973633, generator loss: 0.7096653580665588\n",
      "Epoch: 103, discriminator loss: 1.4362744092941284, generator loss: 0.6810749173164368\n",
      "Epoch: 104, discriminator loss: 1.419525384902954, generator loss: 0.7053825855255127\n",
      "Epoch: 105, discriminator loss: 1.4027540683746338, generator loss: 0.7090328931808472\n",
      "Epoch: 106, discriminator loss: 1.35464346408844, generator loss: 0.7168906331062317\n",
      "Epoch: 107, discriminator loss: 1.3008605241775513, generator loss: 0.7233883142471313\n",
      "Epoch: 108, discriminator loss: 1.2905397415161133, generator loss: 0.729286789894104\n",
      "Epoch: 109, discriminator loss: 1.2704319953918457, generator loss: 0.664126992225647\n",
      "Epoch: 110, discriminator loss: 1.3723433017730713, generator loss: 0.6905267834663391\n",
      "Epoch: 111, discriminator loss: 1.3399670124053955, generator loss: 0.733246922492981\n",
      "Epoch: 112, discriminator loss: 1.3373239040374756, generator loss: 0.7102208137512207\n",
      "Epoch: 113, discriminator loss: 1.3554258346557617, generator loss: 0.6932893991470337\n",
      "Epoch: 114, discriminator loss: 1.3522311449050903, generator loss: 0.6663233041763306\n",
      "Epoch: 115, discriminator loss: 1.3164033889770508, generator loss: 0.682376503944397\n",
      "Epoch: 116, discriminator loss: 1.3718128204345703, generator loss: 0.6838520169258118\n",
      "Epoch: 117, discriminator loss: 1.3090975284576416, generator loss: 0.6734066009521484\n",
      "Epoch: 118, discriminator loss: 1.350390911102295, generator loss: 0.693707287311554\n",
      "Epoch: 119, discriminator loss: 1.326322078704834, generator loss: 0.7196383476257324\n",
      "Epoch: 120, discriminator loss: 1.2804007530212402, generator loss: 0.6787043213844299\n",
      "Epoch: 121, discriminator loss: 1.3241568803787231, generator loss: 0.7421411275863647\n",
      "Epoch: 122, discriminator loss: 1.3280785083770752, generator loss: 0.6974438428878784\n",
      "Epoch: 123, discriminator loss: 1.2931193113327026, generator loss: 0.6877428293228149\n",
      "Epoch: 124, discriminator loss: 1.342235803604126, generator loss: 0.6858530044555664\n",
      "Epoch: 125, discriminator loss: 1.3264203071594238, generator loss: 0.7266881465911865\n",
      "Epoch: 126, discriminator loss: 1.3629233837127686, generator loss: 0.6889909505844116\n",
      "Epoch: 127, discriminator loss: 1.3462103605270386, generator loss: 0.7349642515182495\n",
      "Epoch: 128, discriminator loss: 1.3168926239013672, generator loss: 0.7065203785896301\n",
      "Epoch: 129, discriminator loss: 1.33342707157135, generator loss: 0.7173198461532593\n",
      "Epoch: 130, discriminator loss: 1.313802719116211, generator loss: 0.7268933057785034\n",
      "Epoch: 131, discriminator loss: 1.3012895584106445, generator loss: 0.7318233251571655\n",
      "Epoch: 132, discriminator loss: 1.2894299030303955, generator loss: 0.6776561141014099\n",
      "Epoch: 133, discriminator loss: 1.2665891647338867, generator loss: 0.7112345695495605\n",
      "Epoch: 134, discriminator loss: 1.2809052467346191, generator loss: 0.7257073521614075\n",
      "Epoch: 135, discriminator loss: 1.2920916080474854, generator loss: 0.6799942255020142\n",
      "Epoch: 136, discriminator loss: 1.3200569152832031, generator loss: 0.6888368129730225\n",
      "Epoch: 137, discriminator loss: 1.3265516757965088, generator loss: 0.7314842939376831\n",
      "Epoch: 138, discriminator loss: 1.2663443088531494, generator loss: 0.7535930871963501\n",
      "Epoch: 139, discriminator loss: 1.3515949249267578, generator loss: 0.7986224889755249\n",
      "Epoch: 140, discriminator loss: 1.4105384349822998, generator loss: 0.7222445011138916\n",
      "Epoch: 141, discriminator loss: 1.3829600811004639, generator loss: 0.708642303943634\n",
      "Epoch: 142, discriminator loss: 1.4037259817123413, generator loss: 0.6973925828933716\n",
      "Epoch: 143, discriminator loss: 1.364628791809082, generator loss: 0.7217892408370972\n",
      "Epoch: 144, discriminator loss: 1.2465605735778809, generator loss: 0.7949327230453491\n",
      "Epoch: 145, discriminator loss: 1.4255177974700928, generator loss: 0.6198031902313232\n",
      "Epoch: 146, discriminator loss: 1.242168664932251, generator loss: 0.6527799367904663\n",
      "Epoch: 147, discriminator loss: 1.381766676902771, generator loss: 0.6860297918319702\n",
      "Epoch: 148, discriminator loss: 1.3381330966949463, generator loss: 0.7552949786186218\n",
      "Epoch: 149, discriminator loss: 1.3318126201629639, generator loss: 0.6751946210861206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ganetwork.GAN at 0x112d7f6d8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_layers=[(4, None), (6, tf.nn.tanh), (3, tf.nn.tanh), (1, None)]\n",
    "generator_layers=[(6, None), (8, tf.nn.tanh), (4, None)]\n",
    "gan = GAN(discriminator_layers, generator_layers)\n",
    "gan.train(X, nb_epoch=150, batch_size=5, discriminator_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82286429,  0.06186615,  0.35310692,  0.99341476],\n",
       "       [ 0.03446291,  0.94318295,  0.12055588,  0.00606388],\n",
       "       [ 0.62049049,  0.19632798,  0.24209307,  0.9075613 ],\n",
       "       [ 0.05745903,  0.88128054,  0.11820747,  0.02301324],\n",
       "       [ 0.78784901,  0.0684895 ,  0.33140084,  0.991521  ],\n",
       "       [ 0.22671881,  0.37728301,  0.15340915,  0.4068011 ],\n",
       "       [ 0.09689891,  0.75855774,  0.14134948,  0.09562992],\n",
       "       [ 0.02882782,  0.88491029,  0.07493525,  0.00802684],\n",
       "       [ 0.45593026,  0.1402266 ,  0.24176201,  0.88480145],\n",
       "       [ 0.31504497,  0.19276431,  0.19334783,  0.76300633]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.generate_samples(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 1.6523098945617676, generator loss: 0.29970329999923706\n",
      "Epoch: 1, discriminator loss: 1.5994004011154175, generator loss: 0.3310699164867401\n",
      "Epoch: 2, discriminator loss: 1.550580382347107, generator loss: 0.3658149242401123\n",
      "Epoch: 3, discriminator loss: 1.5104293823242188, generator loss: 0.4001856744289398\n",
      "Epoch: 4, discriminator loss: 1.4795063734054565, generator loss: 0.4332950711250305\n",
      "Epoch: 5, discriminator loss: 1.4556725025177002, generator loss: 0.46100449562072754\n",
      "Epoch: 6, discriminator loss: 1.4411755800247192, generator loss: 0.48999032378196716\n",
      "Epoch: 7, discriminator loss: 1.426853895187378, generator loss: 0.5139530897140503\n",
      "Epoch: 8, discriminator loss: 1.416275978088379, generator loss: 0.5410186648368835\n",
      "Epoch: 9, discriminator loss: 1.409661889076233, generator loss: 0.5602079629898071\n",
      "Epoch: 10, discriminator loss: 1.4035042524337769, generator loss: 0.5811821222305298\n",
      "Epoch: 11, discriminator loss: 1.397782564163208, generator loss: 0.5997690558433533\n",
      "Epoch: 12, discriminator loss: 1.395369052886963, generator loss: 0.6126652359962463\n",
      "Epoch: 13, discriminator loss: 1.3983043432235718, generator loss: 0.6246310472488403\n",
      "Epoch: 14, discriminator loss: 1.3921220302581787, generator loss: 0.6360551714897156\n",
      "Epoch: 15, discriminator loss: 1.3906807899475098, generator loss: 0.6492523550987244\n",
      "Epoch: 16, discriminator loss: 1.392250895500183, generator loss: 0.659585177898407\n",
      "Epoch: 17, discriminator loss: 1.387995958328247, generator loss: 0.6678997278213501\n",
      "Epoch: 18, discriminator loss: 1.3891942501068115, generator loss: 0.6727092862129211\n",
      "Epoch: 19, discriminator loss: 1.389861822128296, generator loss: 0.6765953302383423\n",
      "Epoch: 20, discriminator loss: 1.3900985717773438, generator loss: 0.6844761371612549\n",
      "Epoch: 21, discriminator loss: 1.390001654624939, generator loss: 0.686721920967102\n",
      "Epoch: 22, discriminator loss: 1.3894028663635254, generator loss: 0.6909509897232056\n",
      "Epoch: 23, discriminator loss: 1.3871560096740723, generator loss: 0.6945205926895142\n",
      "Epoch: 24, discriminator loss: 1.3878626823425293, generator loss: 0.6977123618125916\n",
      "Epoch: 25, discriminator loss: 1.3872376680374146, generator loss: 0.6994732618331909\n",
      "Epoch: 26, discriminator loss: 1.3867058753967285, generator loss: 0.700609028339386\n",
      "Epoch: 27, discriminator loss: 1.3855431079864502, generator loss: 0.7008864283561707\n",
      "Epoch: 28, discriminator loss: 1.382447361946106, generator loss: 0.7008925676345825\n",
      "Epoch: 29, discriminator loss: 1.3785488605499268, generator loss: 0.7000928521156311\n",
      "Epoch: 30, discriminator loss: 1.36855149269104, generator loss: 0.6990602612495422\n",
      "Epoch: 31, discriminator loss: 1.3577150106430054, generator loss: 0.6931287050247192\n",
      "Epoch: 32, discriminator loss: 1.333642840385437, generator loss: 0.6848475337028503\n",
      "Epoch: 33, discriminator loss: 1.2621206045150757, generator loss: 0.628279983997345\n",
      "Epoch: 34, discriminator loss: 1.2774858474731445, generator loss: 0.6554681062698364\n",
      "Epoch: 35, discriminator loss: 1.2336312532424927, generator loss: 0.6283705830574036\n",
      "Epoch: 36, discriminator loss: 1.3393089771270752, generator loss: 0.6480792164802551\n",
      "Epoch: 37, discriminator loss: 1.2441115379333496, generator loss: 0.6885056495666504\n",
      "Epoch: 38, discriminator loss: 1.2523198127746582, generator loss: 0.7347790002822876\n",
      "Epoch: 39, discriminator loss: 1.2367792129516602, generator loss: 0.6307334303855896\n",
      "Epoch: 40, discriminator loss: 1.287537693977356, generator loss: 0.6156705617904663\n",
      "Epoch: 41, discriminator loss: 1.4132180213928223, generator loss: 0.5675250291824341\n",
      "Epoch: 42, discriminator loss: 1.4100770950317383, generator loss: 0.5983246564865112\n",
      "Epoch: 43, discriminator loss: 1.3171193599700928, generator loss: 0.6102129220962524\n",
      "Epoch: 44, discriminator loss: 1.409315824508667, generator loss: 0.6085470914840698\n",
      "Epoch: 45, discriminator loss: 1.3993557691574097, generator loss: 0.6489703059196472\n",
      "Epoch: 46, discriminator loss: 1.4328817129135132, generator loss: 0.688701868057251\n",
      "Epoch: 47, discriminator loss: 1.418809413909912, generator loss: 0.7392014861106873\n",
      "Epoch: 48, discriminator loss: 1.3845641613006592, generator loss: 0.732232391834259\n",
      "Epoch: 49, discriminator loss: 1.4129077196121216, generator loss: 0.7024371027946472\n",
      "Epoch: 50, discriminator loss: 1.3887736797332764, generator loss: 0.742207407951355\n",
      "Epoch: 51, discriminator loss: 1.3876327276229858, generator loss: 0.7100040316581726\n",
      "Epoch: 52, discriminator loss: 1.3976118564605713, generator loss: 0.7195478677749634\n",
      "Epoch: 53, discriminator loss: 1.3976397514343262, generator loss: 0.7265440821647644\n",
      "Epoch: 54, discriminator loss: 1.3967669010162354, generator loss: 0.7253939509391785\n",
      "Epoch: 55, discriminator loss: 1.3964378833770752, generator loss: 0.7372897863388062\n",
      "Epoch: 56, discriminator loss: 1.3955862522125244, generator loss: 0.7501655220985413\n",
      "Epoch: 57, discriminator loss: 1.3942477703094482, generator loss: 0.7605627775192261\n",
      "Epoch: 58, discriminator loss: 1.394527554512024, generator loss: 0.7632132768630981\n",
      "Epoch: 59, discriminator loss: 1.3929499387741089, generator loss: 0.7700314521789551\n",
      "Epoch: 60, discriminator loss: 1.3939611911773682, generator loss: 0.7725719809532166\n",
      "Epoch: 61, discriminator loss: 1.3976891040802002, generator loss: 0.7841720581054688\n",
      "Epoch: 62, discriminator loss: 1.3875749111175537, generator loss: 0.7635631561279297\n",
      "Epoch: 63, discriminator loss: 1.3960192203521729, generator loss: 0.7647026181221008\n",
      "Epoch: 64, discriminator loss: 1.3837472200393677, generator loss: 0.7595618367195129\n",
      "Epoch: 65, discriminator loss: 1.3848680257797241, generator loss: 0.7545846700668335\n",
      "Epoch: 66, discriminator loss: 1.391937494277954, generator loss: 0.7508066296577454\n",
      "Epoch: 67, discriminator loss: 1.379279375076294, generator loss: 0.7584288120269775\n",
      "Epoch: 68, discriminator loss: 1.3720329999923706, generator loss: 0.7557114362716675\n",
      "Epoch: 69, discriminator loss: 1.374072790145874, generator loss: 0.7687774896621704\n",
      "Epoch: 70, discriminator loss: 1.3577799797058105, generator loss: 0.7650707960128784\n",
      "Epoch: 71, discriminator loss: 1.3545645475387573, generator loss: 0.7639257907867432\n",
      "Epoch: 72, discriminator loss: 1.3619922399520874, generator loss: 0.7389940619468689\n",
      "Epoch: 73, discriminator loss: 1.3503490686416626, generator loss: 0.7322495579719543\n",
      "Epoch: 74, discriminator loss: 1.324047565460205, generator loss: 0.7306448221206665\n",
      "Epoch: 75, discriminator loss: 1.3496085405349731, generator loss: 0.733047604560852\n",
      "Epoch: 76, discriminator loss: 1.3293520212173462, generator loss: 0.7306981682777405\n",
      "Epoch: 77, discriminator loss: 1.2910144329071045, generator loss: 0.7128170728683472\n",
      "Epoch: 78, discriminator loss: 1.3163411617279053, generator loss: 0.7476099729537964\n",
      "Epoch: 79, discriminator loss: 1.343234658241272, generator loss: 0.7059667706489563\n",
      "Epoch: 80, discriminator loss: 1.3283360004425049, generator loss: 0.7589499354362488\n",
      "Epoch: 81, discriminator loss: 1.3295435905456543, generator loss: 0.7065678834915161\n",
      "Epoch: 82, discriminator loss: 1.3450361490249634, generator loss: 0.6606743931770325\n",
      "Epoch: 83, discriminator loss: 1.354115605354309, generator loss: 0.6533171534538269\n",
      "Epoch: 84, discriminator loss: 1.3128843307495117, generator loss: 0.6655248999595642\n",
      "Epoch: 85, discriminator loss: 1.3563028573989868, generator loss: 0.685954749584198\n",
      "Epoch: 86, discriminator loss: 1.3220221996307373, generator loss: 0.6621179580688477\n",
      "Epoch: 87, discriminator loss: 1.3922295570373535, generator loss: 0.729256272315979\n",
      "Epoch: 88, discriminator loss: 1.3361399173736572, generator loss: 0.6845211982727051\n",
      "Epoch: 89, discriminator loss: 1.3733302354812622, generator loss: 0.7171486616134644\n",
      "Epoch: 90, discriminator loss: 1.348359227180481, generator loss: 0.7182848453521729\n",
      "Epoch: 91, discriminator loss: 1.3455286026000977, generator loss: 0.7072812914848328\n",
      "Epoch: 92, discriminator loss: 1.357367753982544, generator loss: 0.7004262208938599\n",
      "Epoch: 93, discriminator loss: 1.3335978984832764, generator loss: 0.7377842664718628\n",
      "Epoch: 94, discriminator loss: 1.3344817161560059, generator loss: 0.6970369219779968\n",
      "Epoch: 95, discriminator loss: 1.3553904294967651, generator loss: 0.7182751893997192\n",
      "Epoch: 96, discriminator loss: 1.3896610736846924, generator loss: 0.7136102318763733\n",
      "Epoch: 97, discriminator loss: 1.3941380977630615, generator loss: 0.6852207779884338\n",
      "Epoch: 98, discriminator loss: 1.4005937576293945, generator loss: 0.714764416217804\n",
      "Epoch: 99, discriminator loss: 1.486990213394165, generator loss: 0.6665396094322205\n",
      "Epoch: 100, discriminator loss: 1.5134801864624023, generator loss: 0.6512399315834045\n",
      "Epoch: 101, discriminator loss: 1.5275084972381592, generator loss: 0.6659308671951294\n",
      "Epoch: 102, discriminator loss: 1.5201258659362793, generator loss: 0.6664636135101318\n",
      "Epoch: 103, discriminator loss: 1.4970638751983643, generator loss: 0.6702291369438171\n",
      "Epoch: 104, discriminator loss: 1.484879970550537, generator loss: 0.688183605670929\n",
      "Epoch: 105, discriminator loss: 1.4589693546295166, generator loss: 0.6892563104629517\n",
      "Epoch: 106, discriminator loss: 1.4256420135498047, generator loss: 0.699620246887207\n",
      "Epoch: 107, discriminator loss: 1.4232721328735352, generator loss: 0.7024293541908264\n",
      "Epoch: 108, discriminator loss: 1.4033656120300293, generator loss: 0.7051997184753418\n",
      "Epoch: 109, discriminator loss: 1.3938004970550537, generator loss: 0.7134165167808533\n",
      "Epoch: 110, discriminator loss: 1.380260944366455, generator loss: 0.7199515104293823\n",
      "Epoch: 111, discriminator loss: 1.3757869005203247, generator loss: 0.7287387251853943\n",
      "Epoch: 112, discriminator loss: 1.368109941482544, generator loss: 0.7395696640014648\n",
      "Epoch: 113, discriminator loss: 1.35677170753479, generator loss: 0.7502859234809875\n",
      "Epoch: 114, discriminator loss: 1.345476508140564, generator loss: 0.7634330987930298\n",
      "Epoch: 115, discriminator loss: 1.332054615020752, generator loss: 0.7748527526855469\n",
      "Epoch: 116, discriminator loss: 1.3189759254455566, generator loss: 0.7841890454292297\n",
      "Epoch: 117, discriminator loss: 1.3042335510253906, generator loss: 0.7939363121986389\n",
      "Epoch: 118, discriminator loss: 1.2862365245819092, generator loss: 0.7910207509994507\n",
      "Epoch: 119, discriminator loss: 1.2696545124053955, generator loss: 0.7876984477043152\n",
      "Epoch: 120, discriminator loss: 1.253589391708374, generator loss: 0.7817362546920776\n",
      "Epoch: 121, discriminator loss: 1.2478842735290527, generator loss: 0.7626349925994873\n",
      "Epoch: 122, discriminator loss: 1.2543904781341553, generator loss: 0.7379441261291504\n",
      "Epoch: 123, discriminator loss: 1.2481181621551514, generator loss: 0.7286657691001892\n",
      "Epoch: 124, discriminator loss: 1.2671089172363281, generator loss: 0.7270790338516235\n",
      "Epoch: 125, discriminator loss: 1.2670572996139526, generator loss: 0.7059668898582458\n",
      "Epoch: 126, discriminator loss: 1.2977797985076904, generator loss: 0.7010554075241089\n",
      "Epoch: 127, discriminator loss: 1.3217307329177856, generator loss: 0.6749886274337769\n",
      "Epoch: 128, discriminator loss: 1.338228464126587, generator loss: 0.6966831684112549\n",
      "Epoch: 129, discriminator loss: 1.3605362176895142, generator loss: 0.681768536567688\n",
      "Epoch: 130, discriminator loss: 1.3795056343078613, generator loss: 0.6755542755126953\n",
      "Epoch: 131, discriminator loss: 1.4226089715957642, generator loss: 0.6650599241256714\n",
      "Epoch: 132, discriminator loss: 1.4127216339111328, generator loss: 0.671716034412384\n",
      "Epoch: 133, discriminator loss: 1.4283266067504883, generator loss: 0.6756365299224854\n",
      "Epoch: 134, discriminator loss: 1.4262864589691162, generator loss: 0.6628050804138184\n",
      "Epoch: 135, discriminator loss: 1.4305756092071533, generator loss: 0.6435083150863647\n",
      "Epoch: 136, discriminator loss: 1.4264689683914185, generator loss: 0.6336906552314758\n",
      "Epoch: 137, discriminator loss: 1.4294711351394653, generator loss: 0.6597487330436707\n",
      "Epoch: 138, discriminator loss: 1.4141302108764648, generator loss: 0.6587647199630737\n",
      "Epoch: 139, discriminator loss: 1.3944092988967896, generator loss: 0.6624796986579895\n",
      "Epoch: 140, discriminator loss: 1.4000334739685059, generator loss: 0.672073245048523\n",
      "Epoch: 141, discriminator loss: 1.3973095417022705, generator loss: 0.6775027513504028\n",
      "Epoch: 142, discriminator loss: 1.3955159187316895, generator loss: 0.6782788038253784\n",
      "Epoch: 143, discriminator loss: 1.3897426128387451, generator loss: 0.6882513761520386\n",
      "Epoch: 144, discriminator loss: 1.3908097743988037, generator loss: 0.6869778633117676\n",
      "Epoch: 145, discriminator loss: 1.3941004276275635, generator loss: 0.684093177318573\n",
      "Epoch: 146, discriminator loss: 1.3846304416656494, generator loss: 0.6892178654670715\n",
      "Epoch: 147, discriminator loss: 1.3890535831451416, generator loss: 0.6869876980781555\n",
      "Epoch: 148, discriminator loss: 1.3893232345581055, generator loss: 0.6928846836090088\n",
      "Epoch: 149, discriminator loss: 1.3865113258361816, generator loss: 0.6883837580680847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ganetwork.CGAN at 0x10cbe63c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_layers=[(7, None), (6, tf.nn.tanh), (3, tf.nn.softmax), (1, None)]\n",
    "generator_layers=[(9, None), (5, tf.nn.tanh), (4, None)]\n",
    "cgan = CGAN(discriminator_layers, generator_layers)\n",
    "cgan.train(X, y, nb_epoch=150, batch_size=5, discriminator_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1427446 ,  0.25820407,  0.71241528,  0.80112904],\n",
       "       [ 0.58134753,  0.64160776,  0.79944354,  0.85646617],\n",
       "       [ 0.92438316,  0.83942538,  0.92529041,  0.93354577],\n",
       "       [ 0.0405555 ,  0.12971404,  0.54324424,  0.62391841],\n",
       "       [ 0.8086018 ,  0.80916679,  0.84699678,  0.89936841],\n",
       "       [ 0.07473692,  0.1681546 ,  0.6725744 ,  0.77329409],\n",
       "       [ 0.02196066,  0.11114164,  0.32455224,  0.36907181],\n",
       "       [ 0.12258787,  0.23161577,  0.6954993 ,  0.78482884],\n",
       "       [ 0.06398835,  0.14856528,  0.61575019,  0.70132172],\n",
       "       [ 0.09529524,  0.19102204,  0.65368778,  0.73630053]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgan.generate_samples(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75      ,  0.5       ,  0.62711864,  0.54166667],\n",
       "       [ 0.58333333,  0.5       ,  0.59322034,  0.58333333],\n",
       "       [ 0.72222222,  0.45833333,  0.66101695,  0.58333333],\n",
       "       [ 0.33333333,  0.125     ,  0.50847458,  0.5       ],\n",
       "       [ 0.61111111,  0.33333333,  0.61016949,  0.58333333],\n",
       "       [ 0.38888889,  0.33333333,  0.59322034,  0.5       ],\n",
       "       [ 0.55555556,  0.54166667,  0.62711864,  0.625     ],\n",
       "       [ 0.16666667,  0.16666667,  0.38983051,  0.375     ],\n",
       "       [ 0.63888889,  0.375     ,  0.61016949,  0.5       ],\n",
       "       [ 0.25      ,  0.29166667,  0.49152542,  0.54166667],\n",
       "       [ 0.19444444,  0.        ,  0.42372881,  0.375     ],\n",
       "       [ 0.44444444,  0.41666667,  0.54237288,  0.58333333],\n",
       "       [ 0.47222222,  0.08333333,  0.50847458,  0.375     ],\n",
       "       [ 0.5       ,  0.375     ,  0.62711864,  0.54166667],\n",
       "       [ 0.36111111,  0.375     ,  0.44067797,  0.5       ],\n",
       "       [ 0.66666667,  0.45833333,  0.57627119,  0.54166667],\n",
       "       [ 0.36111111,  0.41666667,  0.59322034,  0.58333333],\n",
       "       [ 0.41666667,  0.29166667,  0.52542373,  0.375     ],\n",
       "       [ 0.52777778,  0.08333333,  0.59322034,  0.58333333],\n",
       "       [ 0.36111111,  0.20833333,  0.49152542,  0.41666667],\n",
       "       [ 0.44444444,  0.5       ,  0.6440678 ,  0.70833333],\n",
       "       [ 0.5       ,  0.33333333,  0.50847458,  0.5       ],\n",
       "       [ 0.55555556,  0.20833333,  0.66101695,  0.58333333],\n",
       "       [ 0.5       ,  0.33333333,  0.62711864,  0.45833333],\n",
       "       [ 0.58333333,  0.375     ,  0.55932203,  0.5       ],\n",
       "       [ 0.63888889,  0.41666667,  0.57627119,  0.54166667],\n",
       "       [ 0.69444444,  0.33333333,  0.6440678 ,  0.54166667],\n",
       "       [ 0.66666667,  0.41666667,  0.6779661 ,  0.66666667],\n",
       "       [ 0.47222222,  0.375     ,  0.59322034,  0.58333333],\n",
       "       [ 0.38888889,  0.25      ,  0.42372881,  0.375     ],\n",
       "       [ 0.33333333,  0.16666667,  0.47457627,  0.41666667],\n",
       "       [ 0.33333333,  0.16666667,  0.45762712,  0.375     ],\n",
       "       [ 0.41666667,  0.29166667,  0.49152542,  0.45833333],\n",
       "       [ 0.47222222,  0.29166667,  0.69491525,  0.625     ],\n",
       "       [ 0.30555556,  0.41666667,  0.59322034,  0.58333333],\n",
       "       [ 0.47222222,  0.58333333,  0.59322034,  0.625     ],\n",
       "       [ 0.66666667,  0.45833333,  0.62711864,  0.58333333],\n",
       "       [ 0.55555556,  0.125     ,  0.57627119,  0.5       ],\n",
       "       [ 0.36111111,  0.41666667,  0.52542373,  0.5       ],\n",
       "       [ 0.33333333,  0.20833333,  0.50847458,  0.5       ],\n",
       "       [ 0.33333333,  0.25      ,  0.57627119,  0.45833333],\n",
       "       [ 0.5       ,  0.41666667,  0.61016949,  0.54166667],\n",
       "       [ 0.41666667,  0.25      ,  0.50847458,  0.45833333],\n",
       "       [ 0.19444444,  0.125     ,  0.38983051,  0.375     ],\n",
       "       [ 0.36111111,  0.29166667,  0.54237288,  0.5       ],\n",
       "       [ 0.38888889,  0.41666667,  0.54237288,  0.45833333],\n",
       "       [ 0.38888889,  0.375     ,  0.54237288,  0.5       ],\n",
       "       [ 0.52777778,  0.375     ,  0.55932203,  0.5       ],\n",
       "       [ 0.22222222,  0.20833333,  0.33898305,  0.41666667],\n",
       "       [ 0.38888889,  0.33333333,  0.52542373,  0.5       ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[ds.target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
