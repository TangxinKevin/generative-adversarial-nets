{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds = datasets.load_iris()\n",
    "X_train, y_train = minmax_scale(ds.data), LabelBinarizer().fit_transform(ds.target)\n",
    "training_data = np.concatenate([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_X_samples = X_train.shape[0]\n",
    "n_X_features = X_train.shape[1]\n",
    "n_classes = y_train.shape[1]\n",
    "n_Z_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_X_features], name='X')\n",
    "D_W1 = tf.Variable(tf.random_uniform([n_X_features + n_classes, 6]), name='D_W1')\n",
    "D_b1 = tf.Variable(tf.random_uniform([6]), name='D_b1')\n",
    "D_W2 = tf.Variable(tf.random_uniform([6, 1]), name='D_W2')\n",
    "D_b2 = tf.Variable(tf.random_uniform([1]), name='D_b2')\n",
    "D_parameters = [D_W1, D_W2, D_b1, D_b2]\n",
    "def D_logit(X, y):\n",
    "    inputs = tf.concat(axis=1, values=[X, y])\n",
    "    D_h1 = tf.nn.tanh(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    return tf.matmul(D_h1, D_W2) + D_b2\n",
    "\n",
    "Z = tf.placeholder(tf.float32, shape=[None, n_Z_features], name='Z')\n",
    "G_W1 = tf.Variable(tf.random_uniform([n_Z_features + n_classes, 6]), name='G_W1')\n",
    "G_b1 = tf.Variable(tf.random_uniform([6]), name='G_b1')\n",
    "G_W2 = tf.Variable(tf.random_uniform([6, n_X_features]), name='G_W2')\n",
    "G_b2 = tf.Variable(tf.random_uniform([n_X_features]), name='G_b2')\n",
    "G_parameters = [G_W1, G_W2, G_b1, G_b2]\n",
    "def G_logit(Z, y):\n",
    "    inputs = tf.concat(axis=1, values=[Z, y])\n",
    "    G_h1 = tf.nn.tanh(tf.matmul(inputs, G_W1) + G_b1)\n",
    "    return tf.matmul(G_h1, G_W2) + G_b2\n",
    "\n",
    "def sample_Z(n_samples, n_features):\n",
    "    return np.random.uniform(-1., 1., size=[n_samples, n_features]).astype(np.float32)\n",
    "\n",
    "def sample_y(n_samples, n_classes, class_label):\n",
    "    output = np.zeros(shape=[n_samples, n_classes]).astype(np.float32)\n",
    "    output[:, class_label] = 1.\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D_logit_data = D_logit(X, y)\n",
    "D_logit_generated = D_logit(tf.nn.sigmoid(G_logit(Z, y)), y)\n",
    "\n",
    "D_loss_data = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_data, labels=tf.ones_like(D_logit_data)))\n",
    "D_loss_generated = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_generated, labels=tf.zeros_like(D_logit_generated)))\n",
    "D_loss = D_loss_data + D_loss_generated\n",
    "\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_generated, labels=tf.ones_like(D_logit_generated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=D_parameters)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=G_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 4.202922344207764, generator loss: 0.01588446833193302\n",
      "Epoch: 1, discriminator loss: 3.9094738960266113, generator loss: 0.018823150545358658\n",
      "Epoch: 2, discriminator loss: 3.8059606552124023, generator loss: 0.022607285529375076\n",
      "Epoch: 3, discriminator loss: 3.639249801635742, generator loss: 0.027837589383125305\n",
      "Epoch: 4, discriminator loss: 3.427393674850464, generator loss: 0.03814699873328209\n",
      "Epoch: 5, discriminator loss: 3.221202850341797, generator loss: 0.04424634948372841\n",
      "Epoch: 6, discriminator loss: 2.9936392307281494, generator loss: 0.05537525936961174\n",
      "Epoch: 7, discriminator loss: 2.7353363037109375, generator loss: 0.0749804899096489\n",
      "Epoch: 8, discriminator loss: 2.517587661743164, generator loss: 0.09529682993888855\n",
      "Epoch: 9, discriminator loss: 2.1044423580169678, generator loss: 0.1592247188091278\n",
      "Epoch: 10, discriminator loss: 1.7798351049423218, generator loss: 0.24169805645942688\n",
      "Epoch: 11, discriminator loss: 1.6325829029083252, generator loss: 0.315296471118927\n",
      "Epoch: 12, discriminator loss: 1.5348623991012573, generator loss: 0.38792553544044495\n",
      "Epoch: 13, discriminator loss: 1.4212331771850586, generator loss: 0.5078692436218262\n",
      "Epoch: 14, discriminator loss: 1.4355086088180542, generator loss: 0.5261217951774597\n",
      "Epoch: 15, discriminator loss: 1.3665416240692139, generator loss: 0.5461797714233398\n",
      "Epoch: 16, discriminator loss: 1.2732176780700684, generator loss: 0.6625893712043762\n",
      "Epoch: 17, discriminator loss: 1.3802212476730347, generator loss: 0.6648489832878113\n",
      "Epoch: 18, discriminator loss: 1.3642346858978271, generator loss: 0.6409919857978821\n",
      "Epoch: 19, discriminator loss: 1.228463888168335, generator loss: 0.6963099241256714\n",
      "Epoch: 20, discriminator loss: 1.3438050746917725, generator loss: 0.7266582250595093\n",
      "Epoch: 21, discriminator loss: 1.4283268451690674, generator loss: 0.7170034646987915\n",
      "Epoch: 22, discriminator loss: 1.4499547481536865, generator loss: 0.6789897680282593\n",
      "Epoch: 23, discriminator loss: 1.462160348892212, generator loss: 0.6055659055709839\n",
      "Epoch: 24, discriminator loss: 1.3691391944885254, generator loss: 0.7068902850151062\n",
      "Epoch: 25, discriminator loss: 1.4239526987075806, generator loss: 0.6956659555435181\n",
      "Epoch: 26, discriminator loss: 1.496781826019287, generator loss: 0.6449837684631348\n",
      "Epoch: 27, discriminator loss: 1.3526653051376343, generator loss: 0.6622142791748047\n",
      "Epoch: 28, discriminator loss: 1.3101612329483032, generator loss: 0.6489969491958618\n",
      "Epoch: 29, discriminator loss: 1.331425666809082, generator loss: 0.6594663858413696\n",
      "Epoch: 30, discriminator loss: 1.3915290832519531, generator loss: 0.6727420091629028\n",
      "Epoch: 31, discriminator loss: 1.418010950088501, generator loss: 0.630914568901062\n",
      "Epoch: 32, discriminator loss: 1.3652136325836182, generator loss: 0.6955192685127258\n",
      "Epoch: 33, discriminator loss: 1.3788647651672363, generator loss: 0.6526936888694763\n",
      "Epoch: 34, discriminator loss: 1.4372916221618652, generator loss: 0.6506463289260864\n",
      "Epoch: 35, discriminator loss: 1.409557580947876, generator loss: 0.666553258895874\n",
      "Epoch: 36, discriminator loss: 1.3821005821228027, generator loss: 0.6772609949111938\n",
      "Epoch: 37, discriminator loss: 1.3694558143615723, generator loss: 0.6718285083770752\n",
      "Epoch: 38, discriminator loss: 1.3878438472747803, generator loss: 0.6702175140380859\n",
      "Epoch: 39, discriminator loss: 1.3765326738357544, generator loss: 0.668399453163147\n",
      "Epoch: 40, discriminator loss: 1.3904175758361816, generator loss: 0.6652821898460388\n",
      "Epoch: 41, discriminator loss: 1.3874659538269043, generator loss: 0.6619560718536377\n",
      "Epoch: 42, discriminator loss: 1.3627910614013672, generator loss: 0.6684814095497131\n",
      "Epoch: 43, discriminator loss: 1.3869611024856567, generator loss: 0.6695429086685181\n",
      "Epoch: 44, discriminator loss: 1.3840532302856445, generator loss: 0.6803034543991089\n",
      "Epoch: 45, discriminator loss: 1.3808388710021973, generator loss: 0.6841415166854858\n",
      "Epoch: 46, discriminator loss: 1.3754510879516602, generator loss: 0.7008556127548218\n",
      "Epoch: 47, discriminator loss: 1.3608161211013794, generator loss: 0.69922935962677\n",
      "Epoch: 48, discriminator loss: 1.3323040008544922, generator loss: 0.7237607836723328\n",
      "Epoch: 49, discriminator loss: 1.3327335119247437, generator loss: 0.7443414330482483\n",
      "Epoch: 50, discriminator loss: 1.3574018478393555, generator loss: 0.7105581760406494\n",
      "Epoch: 51, discriminator loss: 1.3123316764831543, generator loss: 0.7772446870803833\n",
      "Epoch: 52, discriminator loss: 1.3120909929275513, generator loss: 0.7554032206535339\n",
      "Epoch: 53, discriminator loss: 1.3126122951507568, generator loss: 0.7984857559204102\n",
      "Epoch: 54, discriminator loss: 1.2941862344741821, generator loss: 0.7895267605781555\n",
      "Epoch: 55, discriminator loss: 1.298844814300537, generator loss: 0.7478327751159668\n",
      "Epoch: 56, discriminator loss: 1.2846019268035889, generator loss: 0.7680114507675171\n",
      "Epoch: 57, discriminator loss: 1.2466483116149902, generator loss: 0.8150428533554077\n",
      "Epoch: 58, discriminator loss: 1.2658782005310059, generator loss: 0.770609974861145\n",
      "Epoch: 59, discriminator loss: 1.2186541557312012, generator loss: 0.7895898818969727\n",
      "Epoch: 60, discriminator loss: 1.2549781799316406, generator loss: 0.8690560460090637\n",
      "Epoch: 61, discriminator loss: 1.3018324375152588, generator loss: 0.7144734263420105\n",
      "Epoch: 62, discriminator loss: 1.3074538707733154, generator loss: 0.7139223217964172\n",
      "Epoch: 63, discriminator loss: 1.297070026397705, generator loss: 0.7248857617378235\n",
      "Epoch: 64, discriminator loss: 1.3598664999008179, generator loss: 0.7017334699630737\n",
      "Epoch: 65, discriminator loss: 1.3450145721435547, generator loss: 0.7000414133071899\n",
      "Epoch: 66, discriminator loss: 1.351062536239624, generator loss: 0.7120704054832458\n",
      "Epoch: 67, discriminator loss: 1.4218664169311523, generator loss: 0.7117371559143066\n",
      "Epoch: 68, discriminator loss: 1.4372315406799316, generator loss: 0.7155582904815674\n",
      "Epoch: 69, discriminator loss: 1.3705840110778809, generator loss: 0.7274554967880249\n",
      "Epoch: 70, discriminator loss: 1.1779720783233643, generator loss: 0.7559490203857422\n",
      "Epoch: 71, discriminator loss: 1.3452526330947876, generator loss: 0.7579233646392822\n",
      "Epoch: 72, discriminator loss: 1.3627562522888184, generator loss: 0.7456897497177124\n",
      "Epoch: 73, discriminator loss: 1.3404808044433594, generator loss: 0.7125307321548462\n",
      "Epoch: 74, discriminator loss: 1.3946349620819092, generator loss: 0.7242069244384766\n",
      "Epoch: 75, discriminator loss: 1.3542219400405884, generator loss: 0.7534375190734863\n",
      "Epoch: 76, discriminator loss: 1.3626155853271484, generator loss: 0.663673996925354\n",
      "Epoch: 77, discriminator loss: 1.3175365924835205, generator loss: 0.7601622343063354\n",
      "Epoch: 78, discriminator loss: 1.2611420154571533, generator loss: 0.6977008581161499\n",
      "Epoch: 79, discriminator loss: 1.3115230798721313, generator loss: 0.6847540736198425\n",
      "Epoch: 80, discriminator loss: 1.4036412239074707, generator loss: 0.7424631714820862\n",
      "Epoch: 81, discriminator loss: 1.4392943382263184, generator loss: 0.6667019724845886\n",
      "Epoch: 82, discriminator loss: 1.3748266696929932, generator loss: 0.659137487411499\n",
      "Epoch: 83, discriminator loss: 1.4089787006378174, generator loss: 0.68536376953125\n",
      "Epoch: 84, discriminator loss: 1.3836445808410645, generator loss: 0.6413727402687073\n",
      "Epoch: 85, discriminator loss: 1.402449369430542, generator loss: 0.6222037076950073\n",
      "Epoch: 86, discriminator loss: 1.4170501232147217, generator loss: 0.6758261919021606\n",
      "Epoch: 87, discriminator loss: 1.4373681545257568, generator loss: 0.6511567234992981\n",
      "Epoch: 88, discriminator loss: 1.4114019870758057, generator loss: 0.6627380847930908\n",
      "Epoch: 89, discriminator loss: 1.4400413036346436, generator loss: 0.6527659296989441\n",
      "Epoch: 90, discriminator loss: 1.4457354545593262, generator loss: 0.624308705329895\n",
      "Epoch: 91, discriminator loss: 1.3767954111099243, generator loss: 0.6880539655685425\n",
      "Epoch: 92, discriminator loss: 1.3924908638000488, generator loss: 0.6799269914627075\n",
      "Epoch: 93, discriminator loss: 1.4053435325622559, generator loss: 0.6577156782150269\n",
      "Epoch: 94, discriminator loss: 1.425269365310669, generator loss: 0.6655411720275879\n",
      "Epoch: 95, discriminator loss: 1.3792301416397095, generator loss: 0.6947084665298462\n",
      "Epoch: 96, discriminator loss: 1.4041531085968018, generator loss: 0.6682085990905762\n",
      "Epoch: 97, discriminator loss: 1.3902097940444946, generator loss: 0.6902291774749756\n",
      "Epoch: 98, discriminator loss: 1.3796641826629639, generator loss: 0.6884295344352722\n",
      "Epoch: 99, discriminator loss: 1.3936476707458496, generator loss: 0.6829811334609985\n",
      "Epoch: 100, discriminator loss: 1.39070725440979, generator loss: 0.6900309920310974\n",
      "Epoch: 101, discriminator loss: 1.4033499956130981, generator loss: 0.6834381818771362\n",
      "Epoch: 102, discriminator loss: 1.3979880809783936, generator loss: 0.695747971534729\n",
      "Epoch: 103, discriminator loss: 1.3917049169540405, generator loss: 0.6932418942451477\n",
      "Epoch: 104, discriminator loss: 1.4031109809875488, generator loss: 0.6730853319168091\n",
      "Epoch: 105, discriminator loss: 1.4104719161987305, generator loss: 0.6739152669906616\n",
      "Epoch: 106, discriminator loss: 1.395714521408081, generator loss: 0.6738502979278564\n",
      "Epoch: 107, discriminator loss: 1.3770508766174316, generator loss: 0.705246090888977\n",
      "Epoch: 108, discriminator loss: 1.3894751071929932, generator loss: 0.6628602743148804\n",
      "Epoch: 109, discriminator loss: 1.380817174911499, generator loss: 0.6937475204467773\n",
      "Epoch: 110, discriminator loss: 1.3696272373199463, generator loss: 0.6981382369995117\n",
      "Epoch: 111, discriminator loss: 1.3941991329193115, generator loss: 0.6748030185699463\n",
      "Epoch: 112, discriminator loss: 1.3924635648727417, generator loss: 0.6784687042236328\n",
      "Epoch: 113, discriminator loss: 1.3757739067077637, generator loss: 0.6757569313049316\n",
      "Epoch: 114, discriminator loss: 1.3997222185134888, generator loss: 0.7072230577468872\n",
      "Epoch: 115, discriminator loss: 1.3963747024536133, generator loss: 0.6632079482078552\n",
      "Epoch: 116, discriminator loss: 1.3671019077301025, generator loss: 0.714368999004364\n",
      "Epoch: 117, discriminator loss: 1.3988566398620605, generator loss: 0.6633802652359009\n",
      "Epoch: 118, discriminator loss: 1.3900260925292969, generator loss: 0.6708997488021851\n",
      "Epoch: 119, discriminator loss: 1.4082659482955933, generator loss: 0.6610026359558105\n",
      "Epoch: 120, discriminator loss: 1.3927686214447021, generator loss: 0.6956190466880798\n",
      "Epoch: 121, discriminator loss: 1.4076569080352783, generator loss: 0.6711755394935608\n",
      "Epoch: 122, discriminator loss: 1.3934361934661865, generator loss: 0.670335590839386\n",
      "Epoch: 123, discriminator loss: 1.3844865560531616, generator loss: 0.6923402547836304\n",
      "Epoch: 124, discriminator loss: 1.382340431213379, generator loss: 0.6847476959228516\n",
      "Epoch: 125, discriminator loss: 1.3920842409133911, generator loss: 0.6858192682266235\n",
      "Epoch: 126, discriminator loss: 1.3812310695648193, generator loss: 0.6930955648422241\n",
      "Epoch: 127, discriminator loss: 1.3776373863220215, generator loss: 0.6854084134101868\n",
      "Epoch: 128, discriminator loss: 1.3752028942108154, generator loss: 0.6896020174026489\n",
      "Epoch: 129, discriminator loss: 1.3784539699554443, generator loss: 0.6899276971817017\n",
      "Epoch: 130, discriminator loss: 1.3724849224090576, generator loss: 0.6875959038734436\n",
      "Epoch: 131, discriminator loss: 1.3765380382537842, generator loss: 0.6915679574012756\n",
      "Epoch: 132, discriminator loss: 1.3684091567993164, generator loss: 0.6933627128601074\n",
      "Epoch: 133, discriminator loss: 1.3705230951309204, generator loss: 0.6912443041801453\n",
      "Epoch: 134, discriminator loss: 1.359596610069275, generator loss: 0.7036329507827759\n",
      "Epoch: 135, discriminator loss: 1.355647325515747, generator loss: 0.7008458971977234\n",
      "Epoch: 136, discriminator loss: 1.3435355424880981, generator loss: 0.6963547468185425\n",
      "Epoch: 137, discriminator loss: 1.3656723499298096, generator loss: 0.695853590965271\n",
      "Epoch: 138, discriminator loss: 1.3850767612457275, generator loss: 0.7007230520248413\n",
      "Epoch: 139, discriminator loss: 1.37505042552948, generator loss: 0.7003534436225891\n",
      "Epoch: 140, discriminator loss: 1.4029161930084229, generator loss: 0.675503134727478\n",
      "Epoch: 141, discriminator loss: 1.3676228523254395, generator loss: 0.6883432865142822\n",
      "Epoch: 142, discriminator loss: 1.3996456861495972, generator loss: 0.6886562705039978\n",
      "Epoch: 143, discriminator loss: 1.4066425561904907, generator loss: 0.7104436755180359\n",
      "Epoch: 144, discriminator loss: 1.3950092792510986, generator loss: 0.6723673939704895\n",
      "Epoch: 145, discriminator loss: 1.405587911605835, generator loss: 0.6851547956466675\n",
      "Epoch: 146, discriminator loss: 1.3992555141448975, generator loss: 0.717070460319519\n",
      "Epoch: 147, discriminator loss: 1.3967560529708862, generator loss: 0.6944130063056946\n",
      "Epoch: 148, discriminator loss: 1.3711961507797241, generator loss: 0.7195470333099365\n",
      "Epoch: 149, discriminator loss: 1.3772424459457397, generator loss: 0.6844339370727539\n",
      "Epoch: 150, discriminator loss: 1.374993085861206, generator loss: 0.6805899143218994\n",
      "Epoch: 151, discriminator loss: 1.3582618236541748, generator loss: 0.7262907028198242\n",
      "Epoch: 152, discriminator loss: 1.3661038875579834, generator loss: 0.7553519010543823\n",
      "Epoch: 153, discriminator loss: 1.3452479839324951, generator loss: 0.7305413484573364\n",
      "Epoch: 154, discriminator loss: 1.40471351146698, generator loss: 0.6789771914482117\n",
      "Epoch: 155, discriminator loss: 1.4036558866500854, generator loss: 0.7072991728782654\n",
      "Epoch: 156, discriminator loss: 1.409366488456726, generator loss: 0.6948578953742981\n",
      "Epoch: 157, discriminator loss: 1.3936647176742554, generator loss: 0.7145553827285767\n",
      "Epoch: 158, discriminator loss: 1.3695719242095947, generator loss: 0.7132369875907898\n",
      "Epoch: 159, discriminator loss: 1.3819098472595215, generator loss: 0.7053175568580627\n",
      "Epoch: 160, discriminator loss: 1.3907395601272583, generator loss: 0.7204273343086243\n",
      "Epoch: 161, discriminator loss: 1.3773829936981201, generator loss: 0.720852255821228\n",
      "Epoch: 162, discriminator loss: 1.3176625967025757, generator loss: 0.7847359776496887\n",
      "Epoch: 163, discriminator loss: 1.3940443992614746, generator loss: 0.7138365507125854\n",
      "Epoch: 164, discriminator loss: 1.396346092224121, generator loss: 0.7098128199577332\n",
      "Epoch: 165, discriminator loss: 1.403273582458496, generator loss: 0.7054417133331299\n",
      "Epoch: 166, discriminator loss: 1.3898890018463135, generator loss: 0.6882864236831665\n",
      "Epoch: 167, discriminator loss: 1.4764724969863892, generator loss: 0.6608437299728394\n",
      "Epoch: 168, discriminator loss: 1.3827567100524902, generator loss: 0.6820051074028015\n",
      "Epoch: 169, discriminator loss: 1.4345512390136719, generator loss: 0.6563655734062195\n",
      "Epoch: 170, discriminator loss: 1.4151129722595215, generator loss: 0.6859308481216431\n",
      "Epoch: 171, discriminator loss: 1.3797588348388672, generator loss: 0.691684901714325\n",
      "Epoch: 172, discriminator loss: 1.376739740371704, generator loss: 0.6951494216918945\n",
      "Epoch: 173, discriminator loss: 1.391457200050354, generator loss: 0.6978228092193604\n",
      "Epoch: 174, discriminator loss: 1.3792566061019897, generator loss: 0.7036082744598389\n",
      "Epoch: 175, discriminator loss: 1.3712248802185059, generator loss: 0.7031639218330383\n",
      "Epoch: 176, discriminator loss: 1.3784770965576172, generator loss: 0.6952816843986511\n",
      "Epoch: 177, discriminator loss: 1.3847976922988892, generator loss: 0.6898439526557922\n",
      "Epoch: 178, discriminator loss: 1.4099178314208984, generator loss: 0.672346830368042\n",
      "Epoch: 179, discriminator loss: 1.4145088195800781, generator loss: 0.7020751237869263\n",
      "Epoch: 180, discriminator loss: 1.4357657432556152, generator loss: 0.6495422124862671\n",
      "Epoch: 181, discriminator loss: 1.40444016456604, generator loss: 0.6769472360610962\n",
      "Epoch: 182, discriminator loss: 1.3882675170898438, generator loss: 0.6836368441581726\n",
      "Epoch: 183, discriminator loss: 1.386223554611206, generator loss: 0.6975371241569519\n",
      "Epoch: 184, discriminator loss: 1.3893754482269287, generator loss: 0.6789331436157227\n",
      "Epoch: 185, discriminator loss: 1.3872394561767578, generator loss: 0.7016041874885559\n",
      "Epoch: 186, discriminator loss: 1.386124849319458, generator loss: 0.6887651085853577\n",
      "Epoch: 187, discriminator loss: 1.3746490478515625, generator loss: 0.6724003553390503\n",
      "Epoch: 188, discriminator loss: 1.3956332206726074, generator loss: 0.6931759119033813\n",
      "Epoch: 189, discriminator loss: 1.3956663608551025, generator loss: 0.7089153528213501\n",
      "Epoch: 190, discriminator loss: 1.3796815872192383, generator loss: 0.6896239519119263\n",
      "Epoch: 191, discriminator loss: 1.3863794803619385, generator loss: 0.7057158350944519\n",
      "Epoch: 192, discriminator loss: 1.3956599235534668, generator loss: 0.7042986154556274\n",
      "Epoch: 193, discriminator loss: 1.3780629634857178, generator loss: 0.7003409266471863\n",
      "Epoch: 194, discriminator loss: 1.363005518913269, generator loss: 0.6876612305641174\n",
      "Epoch: 195, discriminator loss: 1.3836393356323242, generator loss: 0.6711385250091553\n",
      "Epoch: 196, discriminator loss: 1.3966877460479736, generator loss: 0.6937177777290344\n",
      "Epoch: 197, discriminator loss: 1.3753812313079834, generator loss: 0.6863785982131958\n",
      "Epoch: 198, discriminator loss: 1.3716297149658203, generator loss: 0.711657702922821\n",
      "Epoch: 199, discriminator loss: 1.3540585041046143, generator loss: 0.7015060782432556\n",
      "Epoch: 200, discriminator loss: 1.3420360088348389, generator loss: 0.7131557464599609\n",
      "Epoch: 201, discriminator loss: 1.3877558708190918, generator loss: 0.714746356010437\n",
      "Epoch: 202, discriminator loss: 1.3715789318084717, generator loss: 0.7036600708961487\n",
      "Epoch: 203, discriminator loss: 1.3993315696716309, generator loss: 0.6841964721679688\n",
      "Epoch: 204, discriminator loss: 1.3672581911087036, generator loss: 0.6889910697937012\n",
      "Epoch: 205, discriminator loss: 1.3849437236785889, generator loss: 0.7135343551635742\n",
      "Epoch: 206, discriminator loss: 1.4046213626861572, generator loss: 0.6880584955215454\n",
      "Epoch: 207, discriminator loss: 1.3877613544464111, generator loss: 0.6970240473747253\n",
      "Epoch: 208, discriminator loss: 1.3779175281524658, generator loss: 0.7173476219177246\n",
      "Epoch: 209, discriminator loss: 1.3814406394958496, generator loss: 0.7001596093177795\n",
      "Epoch: 210, discriminator loss: 1.3792437314987183, generator loss: 0.6978394985198975\n",
      "Epoch: 211, discriminator loss: 1.3946044445037842, generator loss: 0.6934394240379333\n",
      "Epoch: 212, discriminator loss: 1.3991755247116089, generator loss: 0.6973933577537537\n",
      "Epoch: 213, discriminator loss: 1.3749020099639893, generator loss: 0.6904302835464478\n",
      "Epoch: 214, discriminator loss: 1.3880330324172974, generator loss: 0.6872357130050659\n",
      "Epoch: 215, discriminator loss: 1.4121487140655518, generator loss: 0.6940650343894958\n",
      "Epoch: 216, discriminator loss: 1.4186427593231201, generator loss: 0.6979092955589294\n",
      "Epoch: 217, discriminator loss: 1.4083151817321777, generator loss: 0.6824721097946167\n",
      "Epoch: 218, discriminator loss: 1.3935649394989014, generator loss: 0.6860513687133789\n",
      "Epoch: 219, discriminator loss: 1.3894875049591064, generator loss: 0.6831867694854736\n",
      "Epoch: 220, discriminator loss: 1.3885951042175293, generator loss: 0.7017160654067993\n",
      "Epoch: 221, discriminator loss: 1.384907603263855, generator loss: 0.68412184715271\n",
      "Epoch: 222, discriminator loss: 1.3678677082061768, generator loss: 0.6974004507064819\n",
      "Epoch: 223, discriminator loss: 1.3716998100280762, generator loss: 0.7173293232917786\n",
      "Epoch: 224, discriminator loss: 1.3662981986999512, generator loss: 0.7056457996368408\n",
      "Epoch: 225, discriminator loss: 1.3475711345672607, generator loss: 0.7256510257720947\n",
      "Epoch: 226, discriminator loss: 1.361264705657959, generator loss: 0.7026177644729614\n",
      "Epoch: 227, discriminator loss: 1.4096457958221436, generator loss: 0.6967728734016418\n",
      "Epoch: 228, discriminator loss: 1.4263858795166016, generator loss: 0.6842280626296997\n",
      "Epoch: 229, discriminator loss: 1.3917149305343628, generator loss: 0.697147011756897\n",
      "Epoch: 230, discriminator loss: 1.3915345668792725, generator loss: 0.7012821435928345\n",
      "Epoch: 231, discriminator loss: 1.3822107315063477, generator loss: 0.6938996315002441\n",
      "Epoch: 232, discriminator loss: 1.3715145587921143, generator loss: 0.7093353271484375\n",
      "Epoch: 233, discriminator loss: 1.3669003248214722, generator loss: 0.7069275975227356\n",
      "Epoch: 234, discriminator loss: 1.3684637546539307, generator loss: 0.7013573050498962\n",
      "Epoch: 235, discriminator loss: 1.370190978050232, generator loss: 0.7023341059684753\n",
      "Epoch: 236, discriminator loss: 1.3826924562454224, generator loss: 0.7088863253593445\n",
      "Epoch: 237, discriminator loss: 1.371410846710205, generator loss: 0.7052512764930725\n",
      "Epoch: 238, discriminator loss: 1.3374229669570923, generator loss: 0.6962993741035461\n",
      "Epoch: 239, discriminator loss: 1.3721132278442383, generator loss: 0.6925068497657776\n",
      "Epoch: 240, discriminator loss: 1.3866771459579468, generator loss: 0.6981069445610046\n",
      "Epoch: 241, discriminator loss: 1.4118647575378418, generator loss: 0.7185004353523254\n",
      "Epoch: 242, discriminator loss: 1.3869197368621826, generator loss: 0.6933761835098267\n",
      "Epoch: 243, discriminator loss: 1.41064453125, generator loss: 0.6808301210403442\n",
      "Epoch: 244, discriminator loss: 1.4215826988220215, generator loss: 0.6832630038261414\n",
      "Epoch: 245, discriminator loss: 1.4137248992919922, generator loss: 0.6837571859359741\n",
      "Epoch: 246, discriminator loss: 1.3828455209732056, generator loss: 0.6838939785957336\n",
      "Epoch: 247, discriminator loss: 1.4118740558624268, generator loss: 0.6857579946517944\n",
      "Epoch: 248, discriminator loss: 1.3820371627807617, generator loss: 0.7020577192306519\n",
      "Epoch: 249, discriminator loss: 1.3811745643615723, generator loss: 0.6847490668296814\n",
      "Epoch: 250, discriminator loss: 1.3878607749938965, generator loss: 0.707344651222229\n",
      "Epoch: 251, discriminator loss: 1.3875714540481567, generator loss: 0.6910868287086487\n",
      "Epoch: 252, discriminator loss: 1.4224036931991577, generator loss: 0.6879631280899048\n",
      "Epoch: 253, discriminator loss: 1.3771836757659912, generator loss: 0.6926183104515076\n",
      "Epoch: 254, discriminator loss: 1.3994476795196533, generator loss: 0.6738221049308777\n",
      "Epoch: 255, discriminator loss: 1.4100358486175537, generator loss: 0.6873542666435242\n",
      "Epoch: 256, discriminator loss: 1.389172911643982, generator loss: 0.6807798147201538\n",
      "Epoch: 257, discriminator loss: 1.400953769683838, generator loss: 0.6897131204605103\n",
      "Epoch: 258, discriminator loss: 1.3827378749847412, generator loss: 0.6936718821525574\n",
      "Epoch: 259, discriminator loss: 1.3915746212005615, generator loss: 0.6917036771774292\n",
      "Epoch: 260, discriminator loss: 1.3790805339813232, generator loss: 0.7019421458244324\n",
      "Epoch: 261, discriminator loss: 1.3756179809570312, generator loss: 0.6977930665016174\n",
      "Epoch: 262, discriminator loss: 1.3819172382354736, generator loss: 0.7068639993667603\n",
      "Epoch: 263, discriminator loss: 1.388514757156372, generator loss: 0.6954929828643799\n",
      "Epoch: 264, discriminator loss: 1.381716251373291, generator loss: 0.7011234760284424\n",
      "Epoch: 265, discriminator loss: 1.3835976123809814, generator loss: 0.6854652166366577\n",
      "Epoch: 266, discriminator loss: 1.3856520652770996, generator loss: 0.6987358331680298\n",
      "Epoch: 267, discriminator loss: 1.3653030395507812, generator loss: 0.6876089572906494\n",
      "Epoch: 268, discriminator loss: 1.3965880870819092, generator loss: 0.6962612271308899\n",
      "Epoch: 269, discriminator loss: 1.39829421043396, generator loss: 0.6929243206977844\n",
      "Epoch: 270, discriminator loss: 1.409503698348999, generator loss: 0.6872493624687195\n",
      "Epoch: 271, discriminator loss: 1.3895227909088135, generator loss: 0.6846386194229126\n",
      "Epoch: 272, discriminator loss: 1.3976291418075562, generator loss: 0.698795735836029\n",
      "Epoch: 273, discriminator loss: 1.3773260116577148, generator loss: 0.6844373941421509\n",
      "Epoch: 274, discriminator loss: 1.3850129842758179, generator loss: 0.6873900294303894\n",
      "Epoch: 275, discriminator loss: 1.3924633264541626, generator loss: 0.689093291759491\n",
      "Epoch: 276, discriminator loss: 1.385688304901123, generator loss: 0.6919512748718262\n",
      "Epoch: 277, discriminator loss: 1.3906452655792236, generator loss: 0.6906771659851074\n",
      "Epoch: 278, discriminator loss: 1.407732605934143, generator loss: 0.6924015283584595\n",
      "Epoch: 279, discriminator loss: 1.386397123336792, generator loss: 0.6954081654548645\n",
      "Epoch: 280, discriminator loss: 1.3886622190475464, generator loss: 0.6951079368591309\n",
      "Epoch: 281, discriminator loss: 1.3958673477172852, generator loss: 0.6956533193588257\n",
      "Epoch: 282, discriminator loss: 1.4077084064483643, generator loss: 0.686534583568573\n",
      "Epoch: 283, discriminator loss: 1.3896219730377197, generator loss: 0.6953538656234741\n",
      "Epoch: 284, discriminator loss: 1.3965106010437012, generator loss: 0.6969507932662964\n",
      "Epoch: 285, discriminator loss: 1.3905553817749023, generator loss: 0.7013848423957825\n",
      "Epoch: 286, discriminator loss: 1.3862650394439697, generator loss: 0.7045971751213074\n",
      "Epoch: 287, discriminator loss: 1.367544412612915, generator loss: 0.6981146335601807\n",
      "Epoch: 288, discriminator loss: 1.3790230751037598, generator loss: 0.6895986199378967\n",
      "Epoch: 289, discriminator loss: 1.3923403024673462, generator loss: 0.6938191652297974\n",
      "Epoch: 290, discriminator loss: 1.3965239524841309, generator loss: 0.6968751549720764\n",
      "Epoch: 291, discriminator loss: 1.396064281463623, generator loss: 0.6983777284622192\n",
      "Epoch: 292, discriminator loss: 1.3857381343841553, generator loss: 0.713356614112854\n",
      "Epoch: 293, discriminator loss: 1.3722383975982666, generator loss: 0.6870031952857971\n",
      "Epoch: 294, discriminator loss: 1.3568964004516602, generator loss: 0.7070566415786743\n",
      "Epoch: 295, discriminator loss: 1.3673129081726074, generator loss: 0.7112349271774292\n",
      "Epoch: 296, discriminator loss: 1.3535828590393066, generator loss: 0.7117942571640015\n",
      "Epoch: 297, discriminator loss: 1.3627004623413086, generator loss: 0.7123040556907654\n",
      "Epoch: 298, discriminator loss: 1.3928701877593994, generator loss: 0.6918995380401611\n",
      "Epoch: 299, discriminator loss: 1.3965623378753662, generator loss: 0.6882926225662231\n",
      "Epoch: 300, discriminator loss: 1.3807876110076904, generator loss: 0.7168043851852417\n",
      "Epoch: 301, discriminator loss: 1.4063525199890137, generator loss: 0.6877621412277222\n",
      "Epoch: 302, discriminator loss: 1.3880596160888672, generator loss: 0.7080516815185547\n",
      "Epoch: 303, discriminator loss: 1.3904025554656982, generator loss: 0.6925922632217407\n",
      "Epoch: 304, discriminator loss: 1.3699183464050293, generator loss: 0.7107590436935425\n",
      "Epoch: 305, discriminator loss: 1.3611984252929688, generator loss: 0.7041329145431519\n",
      "Epoch: 306, discriminator loss: 1.3853394985198975, generator loss: 0.7141398191452026\n",
      "Epoch: 307, discriminator loss: 1.4098942279815674, generator loss: 0.6933555603027344\n",
      "Epoch: 308, discriminator loss: 1.3894548416137695, generator loss: 0.682539701461792\n",
      "Epoch: 309, discriminator loss: 1.3795230388641357, generator loss: 0.6952673196792603\n",
      "Epoch: 310, discriminator loss: 1.3844246864318848, generator loss: 0.680365264415741\n",
      "Epoch: 311, discriminator loss: 1.387355089187622, generator loss: 0.6820449233055115\n",
      "Epoch: 312, discriminator loss: 1.4131369590759277, generator loss: 0.6855940222740173\n",
      "Epoch: 313, discriminator loss: 1.4014812707901, generator loss: 0.6967498660087585\n",
      "Epoch: 314, discriminator loss: 1.4010753631591797, generator loss: 0.6845564842224121\n",
      "Epoch: 315, discriminator loss: 1.3895865678787231, generator loss: 0.6954725980758667\n",
      "Epoch: 316, discriminator loss: 1.394644021987915, generator loss: 0.6904163956642151\n",
      "Epoch: 317, discriminator loss: 1.3780193328857422, generator loss: 0.6967588663101196\n",
      "Epoch: 318, discriminator loss: 1.386854887008667, generator loss: 0.6973118185997009\n",
      "Epoch: 319, discriminator loss: 1.3958569765090942, generator loss: 0.697328507900238\n",
      "Epoch: 320, discriminator loss: 1.3859326839447021, generator loss: 0.697135865688324\n",
      "Epoch: 321, discriminator loss: 1.3778276443481445, generator loss: 0.6735252737998962\n",
      "Epoch: 322, discriminator loss: 1.3803662061691284, generator loss: 0.6697328686714172\n",
      "Epoch: 323, discriminator loss: 1.3774755001068115, generator loss: 0.6791512966156006\n",
      "Epoch: 324, discriminator loss: 1.363600254058838, generator loss: 0.6965336203575134\n",
      "Epoch: 325, discriminator loss: 1.3530532121658325, generator loss: 0.6981762647628784\n",
      "Epoch: 326, discriminator loss: 1.3544566631317139, generator loss: 0.717443585395813\n",
      "Epoch: 327, discriminator loss: 1.3721482753753662, generator loss: 0.7056154012680054\n",
      "Epoch: 328, discriminator loss: 1.3583729267120361, generator loss: 0.7257960438728333\n",
      "Epoch: 329, discriminator loss: 1.3576745986938477, generator loss: 0.7100853323936462\n",
      "Epoch: 330, discriminator loss: 1.3788104057312012, generator loss: 0.6610831022262573\n",
      "Epoch: 331, discriminator loss: 1.3825082778930664, generator loss: 0.7051565647125244\n",
      "Epoch: 332, discriminator loss: 1.3889998197555542, generator loss: 0.6808100938796997\n",
      "Epoch: 333, discriminator loss: 1.4050631523132324, generator loss: 0.6955252885818481\n",
      "Epoch: 334, discriminator loss: 1.405592679977417, generator loss: 0.6869215965270996\n",
      "Epoch: 335, discriminator loss: 1.3998098373413086, generator loss: 0.6994367241859436\n",
      "Epoch: 336, discriminator loss: 1.3697677850723267, generator loss: 0.7090974450111389\n",
      "Epoch: 337, discriminator loss: 1.3757219314575195, generator loss: 0.714270830154419\n",
      "Epoch: 338, discriminator loss: 1.393276572227478, generator loss: 0.6986107230186462\n",
      "Epoch: 339, discriminator loss: 1.4388080835342407, generator loss: 0.6856034398078918\n",
      "Epoch: 340, discriminator loss: 1.3772392272949219, generator loss: 0.6760746240615845\n",
      "Epoch: 341, discriminator loss: 1.4448847770690918, generator loss: 0.6803339123725891\n",
      "Epoch: 342, discriminator loss: 1.3932989835739136, generator loss: 0.7001772522926331\n",
      "Epoch: 343, discriminator loss: 1.3898184299468994, generator loss: 0.7041878700256348\n",
      "Epoch: 344, discriminator loss: 1.37704336643219, generator loss: 0.7017830014228821\n",
      "Epoch: 345, discriminator loss: 1.3750282526016235, generator loss: 0.7074620127677917\n",
      "Epoch: 346, discriminator loss: 1.3822914361953735, generator loss: 0.708483099937439\n",
      "Epoch: 347, discriminator loss: 1.3227983713150024, generator loss: 0.7068096399307251\n",
      "Epoch: 348, discriminator loss: 1.4118821620941162, generator loss: 0.7220288515090942\n",
      "Epoch: 349, discriminator loss: 1.3769985437393188, generator loss: 0.701262354850769\n",
      "Epoch: 350, discriminator loss: 1.281101107597351, generator loss: 0.6566004753112793\n",
      "Epoch: 351, discriminator loss: 1.4343390464782715, generator loss: 0.6613543033599854\n",
      "Epoch: 352, discriminator loss: 1.35599946975708, generator loss: 0.6583613753318787\n",
      "Epoch: 353, discriminator loss: 1.431364893913269, generator loss: 0.674461305141449\n",
      "Epoch: 354, discriminator loss: 1.4093520641326904, generator loss: 0.6844831705093384\n",
      "Epoch: 355, discriminator loss: 1.3691365718841553, generator loss: 0.6708244681358337\n",
      "Epoch: 356, discriminator loss: 1.3828907012939453, generator loss: 0.6882811784744263\n",
      "Epoch: 357, discriminator loss: 1.3918848037719727, generator loss: 0.6843300461769104\n",
      "Epoch: 358, discriminator loss: 1.3222451210021973, generator loss: 0.6863628029823303\n",
      "Epoch: 359, discriminator loss: 1.3219823837280273, generator loss: 0.731232762336731\n",
      "Epoch: 360, discriminator loss: 1.4043869972229004, generator loss: 0.7147523760795593\n",
      "Epoch: 361, discriminator loss: 1.3779230117797852, generator loss: 0.6815728545188904\n",
      "Epoch: 362, discriminator loss: 1.2961170673370361, generator loss: 0.6958667635917664\n",
      "Epoch: 363, discriminator loss: 1.393366813659668, generator loss: 0.690722644329071\n",
      "Epoch: 364, discriminator loss: 1.4162747859954834, generator loss: 0.6955631971359253\n",
      "Epoch: 365, discriminator loss: 1.3764357566833496, generator loss: 0.6920454502105713\n",
      "Epoch: 366, discriminator loss: 1.3462555408477783, generator loss: 0.6784259676933289\n",
      "Epoch: 367, discriminator loss: 1.4488232135772705, generator loss: 0.7303876280784607\n",
      "Epoch: 368, discriminator loss: 1.4275190830230713, generator loss: 0.6789637804031372\n",
      "Epoch: 369, discriminator loss: 1.4157013893127441, generator loss: 0.6652684807777405\n",
      "Epoch: 370, discriminator loss: 1.4077551364898682, generator loss: 0.6613748669624329\n",
      "Epoch: 371, discriminator loss: 1.4445674419403076, generator loss: 0.6690398454666138\n",
      "Epoch: 372, discriminator loss: 1.4291998147964478, generator loss: 0.6815902590751648\n",
      "Epoch: 373, discriminator loss: 1.4308803081512451, generator loss: 0.6720600128173828\n",
      "Epoch: 374, discriminator loss: 1.4235081672668457, generator loss: 0.6707213521003723\n",
      "Epoch: 375, discriminator loss: 1.409381628036499, generator loss: 0.6688773036003113\n",
      "Epoch: 376, discriminator loss: 1.3947659730911255, generator loss: 0.6815495491027832\n",
      "Epoch: 377, discriminator loss: 1.3904621601104736, generator loss: 0.6696575284004211\n",
      "Epoch: 378, discriminator loss: 1.3935126066207886, generator loss: 0.6843430399894714\n",
      "Epoch: 379, discriminator loss: 1.388545036315918, generator loss: 0.6858197450637817\n",
      "Epoch: 380, discriminator loss: 1.3812143802642822, generator loss: 0.6937209963798523\n",
      "Epoch: 381, discriminator loss: 1.378831148147583, generator loss: 0.6886371970176697\n",
      "Epoch: 382, discriminator loss: 1.3866363763809204, generator loss: 0.6914602518081665\n",
      "Epoch: 383, discriminator loss: 1.3571840524673462, generator loss: 0.6892696619033813\n",
      "Epoch: 384, discriminator loss: 1.3554811477661133, generator loss: 0.6992830038070679\n",
      "Epoch: 385, discriminator loss: 1.367907166481018, generator loss: 0.6970998048782349\n",
      "Epoch: 386, discriminator loss: 1.3649089336395264, generator loss: 0.7063683271408081\n",
      "Epoch: 387, discriminator loss: 1.3838648796081543, generator loss: 0.7096912264823914\n",
      "Epoch: 388, discriminator loss: 1.3484182357788086, generator loss: 0.6998063325881958\n",
      "Epoch: 389, discriminator loss: 1.37343168258667, generator loss: 0.700792670249939\n",
      "Epoch: 390, discriminator loss: 1.378875494003296, generator loss: 0.7106595039367676\n",
      "Epoch: 391, discriminator loss: 1.3198626041412354, generator loss: 0.6314722299575806\n",
      "Epoch: 392, discriminator loss: 1.3902618885040283, generator loss: 0.712319016456604\n",
      "Epoch: 393, discriminator loss: 1.4045162200927734, generator loss: 0.6622235178947449\n",
      "Epoch: 394, discriminator loss: 1.4313255548477173, generator loss: 0.7007499933242798\n",
      "Epoch: 395, discriminator loss: 1.4339303970336914, generator loss: 0.7007709741592407\n",
      "Epoch: 396, discriminator loss: 1.4114420413970947, generator loss: 0.6821540594100952\n",
      "Epoch: 397, discriminator loss: 1.4202039241790771, generator loss: 0.6921302676200867\n",
      "Epoch: 398, discriminator loss: 1.4143359661102295, generator loss: 0.6907411813735962\n",
      "Epoch: 399, discriminator loss: 1.3947699069976807, generator loss: 0.7137578129768372\n",
      "Epoch: 400, discriminator loss: 1.3817789554595947, generator loss: 0.7137578725814819\n",
      "Epoch: 401, discriminator loss: 1.3429478406906128, generator loss: 0.738237738609314\n",
      "Epoch: 402, discriminator loss: 1.301072359085083, generator loss: 0.7494914531707764\n",
      "Epoch: 403, discriminator loss: 1.339399814605713, generator loss: 0.8010557889938354\n",
      "Epoch: 404, discriminator loss: 1.3583195209503174, generator loss: 0.6734618544578552\n",
      "Epoch: 405, discriminator loss: 1.2775466442108154, generator loss: 0.7607842087745667\n",
      "Epoch: 406, discriminator loss: 1.2671387195587158, generator loss: 0.7269062995910645\n",
      "Epoch: 407, discriminator loss: 1.3786613941192627, generator loss: 0.6190311312675476\n",
      "Epoch: 408, discriminator loss: 1.4584760665893555, generator loss: 0.6493711471557617\n",
      "Epoch: 409, discriminator loss: 1.4826639890670776, generator loss: 0.6547937989234924\n",
      "Epoch: 410, discriminator loss: 1.4331698417663574, generator loss: 0.6359776854515076\n",
      "Epoch: 411, discriminator loss: 1.4156211614608765, generator loss: 0.6251322031021118\n",
      "Epoch: 412, discriminator loss: 1.402176022529602, generator loss: 0.6946778893470764\n",
      "Epoch: 413, discriminator loss: 1.430835485458374, generator loss: 0.6728147268295288\n",
      "Epoch: 414, discriminator loss: 1.3818089962005615, generator loss: 0.6918236017227173\n",
      "Epoch: 415, discriminator loss: 1.3974721431732178, generator loss: 0.6991395354270935\n",
      "Epoch: 416, discriminator loss: 1.3825738430023193, generator loss: 0.691301703453064\n",
      "Epoch: 417, discriminator loss: 1.3516539335250854, generator loss: 0.6913321614265442\n",
      "Epoch: 418, discriminator loss: 1.3587627410888672, generator loss: 0.6970598697662354\n",
      "Epoch: 419, discriminator loss: 1.3520159721374512, generator loss: 0.6973579525947571\n",
      "Epoch: 420, discriminator loss: 1.395399570465088, generator loss: 0.6837887167930603\n",
      "Epoch: 421, discriminator loss: 1.3304715156555176, generator loss: 0.7298783659934998\n",
      "Epoch: 422, discriminator loss: 1.309763789176941, generator loss: 0.7338945269584656\n",
      "Epoch: 423, discriminator loss: 1.3401436805725098, generator loss: 0.7256898283958435\n",
      "Epoch: 424, discriminator loss: 1.3488022089004517, generator loss: 0.705487847328186\n",
      "Epoch: 425, discriminator loss: 1.385479211807251, generator loss: 0.7118229269981384\n",
      "Epoch: 426, discriminator loss: 1.4183149337768555, generator loss: 0.6718770861625671\n",
      "Epoch: 427, discriminator loss: 1.398903250694275, generator loss: 0.6992937326431274\n",
      "Epoch: 428, discriminator loss: 1.3369494676589966, generator loss: 0.6975582242012024\n",
      "Epoch: 429, discriminator loss: 1.3659331798553467, generator loss: 0.7197734713554382\n",
      "Epoch: 430, discriminator loss: 1.4745984077453613, generator loss: 0.6552241444587708\n",
      "Epoch: 431, discriminator loss: 1.3590108156204224, generator loss: 0.7221237421035767\n",
      "Epoch: 432, discriminator loss: 1.4698070287704468, generator loss: 0.6916927695274353\n",
      "Epoch: 433, discriminator loss: 1.3418831825256348, generator loss: 0.7172261476516724\n",
      "Epoch: 434, discriminator loss: 1.4233531951904297, generator loss: 0.6684048175811768\n",
      "Epoch: 435, discriminator loss: 1.390155553817749, generator loss: 0.6884188055992126\n",
      "Epoch: 436, discriminator loss: 1.3852338790893555, generator loss: 0.7147111296653748\n",
      "Epoch: 437, discriminator loss: 1.3569667339324951, generator loss: 0.6927677392959595\n",
      "Epoch: 438, discriminator loss: 1.3991215229034424, generator loss: 0.6877404451370239\n",
      "Epoch: 439, discriminator loss: 1.4033613204956055, generator loss: 0.6894699335098267\n",
      "Epoch: 440, discriminator loss: 1.3836703300476074, generator loss: 0.7042359709739685\n",
      "Epoch: 441, discriminator loss: 1.3826674222946167, generator loss: 0.7159051895141602\n",
      "Epoch: 442, discriminator loss: 1.3776850700378418, generator loss: 0.6869341731071472\n",
      "Epoch: 443, discriminator loss: 1.4416639804840088, generator loss: 0.6541796326637268\n",
      "Epoch: 444, discriminator loss: 1.3636083602905273, generator loss: 0.7376588582992554\n",
      "Epoch: 445, discriminator loss: 1.4313749074935913, generator loss: 0.7240765690803528\n",
      "Epoch: 446, discriminator loss: 1.3839623928070068, generator loss: 0.7230826616287231\n",
      "Epoch: 447, discriminator loss: 1.389993667602539, generator loss: 0.7336915731430054\n",
      "Epoch: 448, discriminator loss: 1.4039161205291748, generator loss: 0.7124971151351929\n",
      "Epoch: 449, discriminator loss: 1.360330581665039, generator loss: 0.7099683284759521\n",
      "Epoch: 450, discriminator loss: 1.3680012226104736, generator loss: 0.7304348945617676\n",
      "Epoch: 451, discriminator loss: 1.3926959037780762, generator loss: 0.7111093997955322\n",
      "Epoch: 452, discriminator loss: 1.3368124961853027, generator loss: 0.6931957006454468\n",
      "Epoch: 453, discriminator loss: 1.34742271900177, generator loss: 0.7164729833602905\n",
      "Epoch: 454, discriminator loss: 1.3342363834381104, generator loss: 0.7027899622917175\n",
      "Epoch: 455, discriminator loss: 1.3900996446609497, generator loss: 0.6977207660675049\n",
      "Epoch: 456, discriminator loss: 1.388556718826294, generator loss: 0.6816234588623047\n",
      "Epoch: 457, discriminator loss: 1.4108227491378784, generator loss: 0.6731564402580261\n",
      "Epoch: 458, discriminator loss: 1.402517557144165, generator loss: 0.6692181825637817\n",
      "Epoch: 459, discriminator loss: 1.3863978385925293, generator loss: 0.6832195520401001\n",
      "Epoch: 460, discriminator loss: 1.4287102222442627, generator loss: 0.689792811870575\n",
      "Epoch: 461, discriminator loss: 1.38429856300354, generator loss: 0.6922789216041565\n",
      "Epoch: 462, discriminator loss: 1.4071526527404785, generator loss: 0.6871386766433716\n",
      "Epoch: 463, discriminator loss: 1.3746566772460938, generator loss: 0.6783145666122437\n",
      "Epoch: 464, discriminator loss: 1.3719998598098755, generator loss: 0.7003428936004639\n",
      "Epoch: 465, discriminator loss: 1.353805661201477, generator loss: 0.7154531478881836\n",
      "Epoch: 466, discriminator loss: 1.4306004047393799, generator loss: 0.6821972727775574\n",
      "Epoch: 467, discriminator loss: 1.4030184745788574, generator loss: 0.7064713835716248\n",
      "Epoch: 468, discriminator loss: 1.373049259185791, generator loss: 0.6765304803848267\n",
      "Epoch: 469, discriminator loss: 1.3969848155975342, generator loss: 0.6642974615097046\n",
      "Epoch: 470, discriminator loss: 1.4125193357467651, generator loss: 0.6756545305252075\n",
      "Epoch: 471, discriminator loss: 1.395449161529541, generator loss: 0.6985102891921997\n",
      "Epoch: 472, discriminator loss: 1.406179428100586, generator loss: 0.6634512543678284\n",
      "Epoch: 473, discriminator loss: 1.4026579856872559, generator loss: 0.6748620271682739\n",
      "Epoch: 474, discriminator loss: 1.386483073234558, generator loss: 0.6845178008079529\n",
      "Epoch: 475, discriminator loss: 1.3785674571990967, generator loss: 0.682508111000061\n",
      "Epoch: 476, discriminator loss: 1.381335735321045, generator loss: 0.6861585378646851\n",
      "Epoch: 477, discriminator loss: 1.3584219217300415, generator loss: 0.6802890300750732\n",
      "Epoch: 478, discriminator loss: 1.3753721714019775, generator loss: 0.7021981477737427\n",
      "Epoch: 479, discriminator loss: 1.3821141719818115, generator loss: 0.6826478242874146\n",
      "Epoch: 480, discriminator loss: 1.3689570426940918, generator loss: 0.687006950378418\n",
      "Epoch: 481, discriminator loss: 1.4212956428527832, generator loss: 0.6918722987174988\n",
      "Epoch: 482, discriminator loss: 1.3521909713745117, generator loss: 0.7100523710250854\n",
      "Epoch: 483, discriminator loss: 1.3820061683654785, generator loss: 0.6890662908554077\n",
      "Epoch: 484, discriminator loss: 1.384932518005371, generator loss: 0.6983362436294556\n",
      "Epoch: 485, discriminator loss: 1.3931818008422852, generator loss: 0.6871366500854492\n",
      "Epoch: 486, discriminator loss: 1.3704237937927246, generator loss: 0.7075241208076477\n",
      "Epoch: 487, discriminator loss: 1.3664956092834473, generator loss: 0.6999432444572449\n",
      "Epoch: 488, discriminator loss: 1.3715436458587646, generator loss: 0.6948717832565308\n",
      "Epoch: 489, discriminator loss: 1.3903065919876099, generator loss: 0.7213193774223328\n",
      "Epoch: 490, discriminator loss: 1.3708465099334717, generator loss: 0.7064158320426941\n",
      "Epoch: 491, discriminator loss: 1.3621699810028076, generator loss: 0.7182551622390747\n",
      "Epoch: 492, discriminator loss: 1.3403534889221191, generator loss: 0.7152615189552307\n",
      "Epoch: 493, discriminator loss: 1.335950255393982, generator loss: 0.7228752970695496\n",
      "Epoch: 494, discriminator loss: 1.3666224479675293, generator loss: 0.698586106300354\n",
      "Epoch: 495, discriminator loss: 1.3614723682403564, generator loss: 0.6891611218452454\n",
      "Epoch: 496, discriminator loss: 1.4266653060913086, generator loss: 0.6848810911178589\n",
      "Epoch: 497, discriminator loss: 1.3900630474090576, generator loss: 0.667820394039154\n",
      "Epoch: 498, discriminator loss: 1.4115350246429443, generator loss: 0.6849721074104309\n",
      "Epoch: 499, discriminator loss: 1.44123375415802, generator loss: 0.6805860996246338\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 5\n",
    "n_batches = int(n_X_samples / batch_size)\n",
    "for epoch in range(500):\n",
    "    epoch_permuted_indices = np.random.permutation(range(n_X_samples))\n",
    "    X_epoch = X_train[epoch_permuted_indices]\n",
    "    y_epoch = y_train[epoch_permuted_indices]\n",
    "    for batch_index in range(n_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        X_batch = X_epoch[start_index:end_index]\n",
    "        y_batch = y_epoch[start_index:end_index]\n",
    "        _, D_loss_value = sess.run([D_solver, D_loss], feed_dict={X: X_batch, Z: sample_Z(batch_size, n_Z_features), y: y_batch})\n",
    "        _, G_loss_value = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(batch_size, n_Z_features), y: y_batch})\n",
    "    print('Epoch: {}, discriminator loss: {}, generator loss: {}'.format(epoch, D_loss_value, G_loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_generated = tf.nn.sigmoid(G_logit(sample_Z(10, n_Z_features), sample_y(10, n_classes, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40602136,  0.27141324,  0.8307209 ,  0.57854921],\n",
       "       [ 0.46065405,  0.30945   ,  0.78602254,  0.65364873],\n",
       "       [ 0.44015408,  0.277385  ,  0.80347764,  0.60472214],\n",
       "       [ 0.38755029,  0.28218868,  0.82850897,  0.5852614 ],\n",
       "       [ 0.4099665 ,  0.25503406,  0.8052249 ,  0.59090215],\n",
       "       [ 0.31517851,  0.22329536,  0.83608657,  0.50601941],\n",
       "       [ 0.46828321,  0.30253586,  0.78813523,  0.65890127],\n",
       "       [ 0.51689166,  0.41220194,  0.83162063,  0.72102773],\n",
       "       [ 0.67201138,  0.53954577,  0.79447925,  0.80900848],\n",
       "       [ 0.33292016,  0.24067263,  0.85144645,  0.53288835]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(X_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.55555556,  0.54166667,  0.84745763,  1.        ],\n",
       "       [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "       [ 0.77777778,  0.41666667,  0.83050847,  0.83333333],\n",
       "       [ 0.55555556,  0.375     ,  0.77966102,  0.70833333],\n",
       "       [ 0.61111111,  0.41666667,  0.81355932,  0.875     ],\n",
       "       [ 0.91666667,  0.41666667,  0.94915254,  0.83333333],\n",
       "       [ 0.16666667,  0.20833333,  0.59322034,  0.66666667],\n",
       "       [ 0.83333333,  0.375     ,  0.89830508,  0.70833333],\n",
       "       [ 0.66666667,  0.20833333,  0.81355932,  0.70833333],\n",
       "       [ 0.80555556,  0.66666667,  0.86440678,  1.        ],\n",
       "       [ 0.61111111,  0.5       ,  0.69491525,  0.79166667],\n",
       "       [ 0.58333333,  0.29166667,  0.72881356,  0.75      ],\n",
       "       [ 0.69444444,  0.41666667,  0.76271186,  0.83333333],\n",
       "       [ 0.38888889,  0.20833333,  0.6779661 ,  0.79166667],\n",
       "       [ 0.41666667,  0.33333333,  0.69491525,  0.95833333],\n",
       "       [ 0.58333333,  0.5       ,  0.72881356,  0.91666667],\n",
       "       [ 0.61111111,  0.41666667,  0.76271186,  0.70833333],\n",
       "       [ 0.94444444,  0.75      ,  0.96610169,  0.875     ],\n",
       "       [ 0.94444444,  0.25      ,  1.        ,  0.91666667],\n",
       "       [ 0.47222222,  0.08333333,  0.6779661 ,  0.58333333],\n",
       "       [ 0.72222222,  0.5       ,  0.79661017,  0.91666667],\n",
       "       [ 0.36111111,  0.33333333,  0.66101695,  0.79166667],\n",
       "       [ 0.94444444,  0.33333333,  0.96610169,  0.79166667],\n",
       "       [ 0.55555556,  0.29166667,  0.66101695,  0.70833333],\n",
       "       [ 0.66666667,  0.54166667,  0.79661017,  0.83333333],\n",
       "       [ 0.80555556,  0.5       ,  0.84745763,  0.70833333],\n",
       "       [ 0.52777778,  0.33333333,  0.6440678 ,  0.70833333],\n",
       "       [ 0.5       ,  0.41666667,  0.66101695,  0.70833333],\n",
       "       [ 0.58333333,  0.33333333,  0.77966102,  0.83333333],\n",
       "       [ 0.80555556,  0.41666667,  0.81355932,  0.625     ],\n",
       "       [ 0.86111111,  0.33333333,  0.86440678,  0.75      ],\n",
       "       [ 1.        ,  0.75      ,  0.91525424,  0.79166667],\n",
       "       [ 0.58333333,  0.33333333,  0.77966102,  0.875     ],\n",
       "       [ 0.55555556,  0.33333333,  0.69491525,  0.58333333],\n",
       "       [ 0.5       ,  0.25      ,  0.77966102,  0.54166667],\n",
       "       [ 0.94444444,  0.41666667,  0.86440678,  0.91666667],\n",
       "       [ 0.55555556,  0.58333333,  0.77966102,  0.95833333],\n",
       "       [ 0.58333333,  0.45833333,  0.76271186,  0.70833333],\n",
       "       [ 0.47222222,  0.41666667,  0.6440678 ,  0.70833333],\n",
       "       [ 0.72222222,  0.45833333,  0.74576271,  0.83333333],\n",
       "       [ 0.66666667,  0.45833333,  0.77966102,  0.95833333],\n",
       "       [ 0.72222222,  0.45833333,  0.69491525,  0.91666667],\n",
       "       [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "       [ 0.69444444,  0.5       ,  0.83050847,  0.91666667],\n",
       "       [ 0.66666667,  0.54166667,  0.79661017,  1.        ],\n",
       "       [ 0.66666667,  0.41666667,  0.71186441,  0.91666667],\n",
       "       [ 0.55555556,  0.20833333,  0.6779661 ,  0.75      ],\n",
       "       [ 0.61111111,  0.41666667,  0.71186441,  0.79166667],\n",
       "       [ 0.52777778,  0.58333333,  0.74576271,  0.91666667],\n",
       "       [ 0.44444444,  0.41666667,  0.69491525,  0.70833333]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[ds.target == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
