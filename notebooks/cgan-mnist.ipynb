{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append('../../generative-adversarial-nets/')\n",
    "from ganetwork import GAN, CGAN\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import minmax_scale, LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choices\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from imblearn.datasets import make_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home=\".\")\n",
    "keep_indices = (mnist.target == 1) | (mnist.target == 7)   \n",
    "X, y = minmax_scale(mnist.data.astype(np.float32))[keep_indices], mnist.target[keep_indices]\n",
    "X, y = make_imbalance(X, y, ratio=0.01, random_state=0)\n",
    "y = LabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "discriminator_layers=[(X.shape[1] + y.shape[1], None), (150, tf.nn.tanh), (1, None)]\n",
    "generator_layers=[(100 + y.shape[1], None), (150, tf.nn.tanh), (X.shape[1], None)]\n",
    "cgan = CGAN(discriminator_layers, generator_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 0.0017298910534009337, generator loss: 14.272872924804688\n",
      "Epoch: 1, discriminator loss: 0.0007518412894569337, generator loss: 14.251837730407715\n",
      "Epoch: 2, discriminator loss: 0.0002260994806420058, generator loss: 13.241905212402344\n",
      "Epoch: 3, discriminator loss: 0.000799640896730125, generator loss: 8.753179550170898\n",
      "Epoch: 4, discriminator loss: 0.0005654217675328255, generator loss: 8.116411209106445\n",
      "Epoch: 5, discriminator loss: 0.00056139484513551, generator loss: 8.895748138427734\n",
      "Epoch: 6, discriminator loss: 0.0005146056064404547, generator loss: 7.125438213348389\n",
      "Epoch: 7, discriminator loss: 0.0009390073246322572, generator loss: 7.236150741577148\n",
      "Epoch: 8, discriminator loss: 0.0013366274069994688, generator loss: 7.750124931335449\n",
      "Epoch: 9, discriminator loss: 0.0012763781705871224, generator loss: 6.274715423583984\n",
      "Epoch: 10, discriminator loss: 0.0008186969207599759, generator loss: 5.032691955566406\n",
      "Epoch: 11, discriminator loss: 0.0005381441442295909, generator loss: 4.546682357788086\n",
      "Epoch: 12, discriminator loss: 0.0005724816583096981, generator loss: 5.018233776092529\n",
      "Epoch: 13, discriminator loss: 0.0005730224656872451, generator loss: 3.12109112739563\n",
      "Epoch: 14, discriminator loss: 0.0005791057483293116, generator loss: 5.414599418640137\n",
      "Epoch: 15, discriminator loss: 0.0011665401980280876, generator loss: 2.9061949253082275\n",
      "Epoch: 16, discriminator loss: 0.00043178373016417027, generator loss: 5.29583740234375\n",
      "Epoch: 17, discriminator loss: 0.000735966139473021, generator loss: 5.293888092041016\n",
      "Epoch: 18, discriminator loss: 0.00094697525491938, generator loss: 3.33086895942688\n",
      "Epoch: 19, discriminator loss: 0.0006982143968343735, generator loss: 5.75272798538208\n",
      "Epoch: 20, discriminator loss: 0.0006207654369063675, generator loss: 3.85312557220459\n",
      "Epoch: 21, discriminator loss: 0.0003392196667846292, generator loss: 5.811054706573486\n",
      "Epoch: 22, discriminator loss: 0.00029785724473185837, generator loss: 0.9356979131698608\n",
      "Epoch: 23, discriminator loss: 1.7986581951845437e-05, generator loss: 14.39001178741455\n",
      "Epoch: 24, discriminator loss: 1.1464578165032435e-05, generator loss: 9.02241039276123\n",
      "Epoch: 25, discriminator loss: 0.00013290037168189883, generator loss: 8.084071159362793\n",
      "Epoch: 26, discriminator loss: 0.00020368682453408837, generator loss: 8.109063148498535\n",
      "Epoch: 27, discriminator loss: 0.00012265713303349912, generator loss: 5.248507022857666\n",
      "Epoch: 28, discriminator loss: 4.352314863353968e-05, generator loss: 5.430305480957031\n",
      "Epoch: 29, discriminator loss: 7.083555829012766e-05, generator loss: 8.53059196472168\n",
      "Epoch: 30, discriminator loss: 5.765744936070405e-05, generator loss: 7.934792995452881\n",
      "Epoch: 31, discriminator loss: 7.705243478994817e-05, generator loss: 7.823896884918213\n",
      "Epoch: 32, discriminator loss: 9.721047536004335e-05, generator loss: 8.47513484954834\n",
      "Epoch: 33, discriminator loss: 7.187729352153838e-05, generator loss: 7.6193928718566895\n",
      "Epoch: 34, discriminator loss: 2.8403435862855986e-05, generator loss: 7.5643815994262695\n",
      "Epoch: 35, discriminator loss: 4.330458614276722e-05, generator loss: 6.171582221984863\n",
      "Epoch: 36, discriminator loss: 2.010704884014558e-05, generator loss: 7.813292026519775\n",
      "Epoch: 37, discriminator loss: 2.283905996591784e-05, generator loss: 6.306241512298584\n",
      "Epoch: 38, discriminator loss: 3.0169958336045966e-05, generator loss: 8.013191223144531\n",
      "Epoch: 39, discriminator loss: 3.70679481420666e-05, generator loss: 7.715449333190918\n",
      "Epoch: 40, discriminator loss: 2.105364910676144e-05, generator loss: 7.56007194519043\n",
      "Epoch: 41, discriminator loss: 1.813623748603277e-05, generator loss: 5.978294372558594\n",
      "Epoch: 42, discriminator loss: 1.0134390322491527e-05, generator loss: 8.176534652709961\n",
      "Epoch: 43, discriminator loss: 3.0765273550059646e-05, generator loss: 7.936335563659668\n",
      "Epoch: 44, discriminator loss: 1.395149047311861e-05, generator loss: 7.357997894287109\n",
      "Epoch: 45, discriminator loss: 1.9800503650913015e-05, generator loss: 4.4367170333862305\n",
      "Epoch: 46, discriminator loss: 6.173027486511273e-06, generator loss: 11.9408540725708\n",
      "Epoch: 47, discriminator loss: 8.712415365152992e-06, generator loss: 2.590825080871582\n",
      "Epoch: 48, discriminator loss: 7.898784133431036e-06, generator loss: 17.457698822021484\n",
      "Epoch: 49, discriminator loss: 3.5054470117756864e-06, generator loss: 15.574475288391113\n",
      "Epoch: 50, discriminator loss: 2.921333134509041e-06, generator loss: 8.101081848144531\n",
      "Epoch: 51, discriminator loss: 6.066812602512073e-06, generator loss: 6.855193138122559\n",
      "Epoch: 52, discriminator loss: 6.993776878516655e-06, generator loss: 3.499791145324707\n",
      "Epoch: 53, discriminator loss: 8.827969395497348e-06, generator loss: 10.095470428466797\n",
      "Epoch: 54, discriminator loss: 1.2533802873804234e-05, generator loss: 2.970344066619873\n",
      "Epoch: 55, discriminator loss: 6.0726815718226135e-06, generator loss: 14.877166748046875\n",
      "Epoch: 56, discriminator loss: 3.211344392184401e-06, generator loss: 10.34836483001709\n",
      "Epoch: 57, discriminator loss: 8.999749297800008e-06, generator loss: 6.399226188659668\n",
      "Epoch: 58, discriminator loss: 7.031900167930871e-06, generator loss: 9.781963348388672\n",
      "Epoch: 59, discriminator loss: 1.1246494977967814e-05, generator loss: 9.886002540588379\n",
      "Epoch: 60, discriminator loss: 7.982753231772222e-06, generator loss: 0.3860381245613098\n",
      "Epoch: 61, discriminator loss: 1.944121521546549e-07, generator loss: 21.965003967285156\n",
      "Epoch: 62, discriminator loss: 1.4137154380478023e-07, generator loss: 13.178091049194336\n",
      "Epoch: 63, discriminator loss: 3.3456187793490244e-06, generator loss: 9.131780624389648\n",
      "Epoch: 64, discriminator loss: 5.15404281031806e-06, generator loss: 4.524813175201416\n",
      "Epoch: 65, discriminator loss: 2.0899781816297036e-07, generator loss: 14.946352005004883\n",
      "Epoch: 66, discriminator loss: 4.6497888206431526e-07, generator loss: 13.457759857177734\n",
      "Epoch: 67, discriminator loss: 1.4414296174436458e-06, generator loss: 11.00255012512207\n",
      "Epoch: 68, discriminator loss: 6.580800800293218e-06, generator loss: 8.099632263183594\n",
      "Epoch: 69, discriminator loss: 4.715242084785132e-06, generator loss: 7.82606840133667\n",
      "Epoch: 70, discriminator loss: 3.6684291444544215e-06, generator loss: 11.263513565063477\n",
      "Epoch: 71, discriminator loss: 3.7198753943812335e-06, generator loss: 9.643131256103516\n",
      "Epoch: 72, discriminator loss: 5.324483026925009e-06, generator loss: 8.096891403198242\n",
      "Epoch: 73, discriminator loss: 5.547382443182869e-06, generator loss: 8.221506118774414\n",
      "Epoch: 74, discriminator loss: 7.386224183392187e-07, generator loss: 9.306266784667969\n",
      "Epoch: 75, discriminator loss: 1.0626589528328623e-06, generator loss: 9.107234954833984\n",
      "Epoch: 76, discriminator loss: 2.210427737736609e-06, generator loss: 11.456789016723633\n",
      "Epoch: 77, discriminator loss: 2.2489371076517273e-06, generator loss: 2.1559906005859375\n",
      "Epoch: 78, discriminator loss: 2.2952190192881972e-07, generator loss: 21.751773834228516\n",
      "Epoch: 79, discriminator loss: 1.4531717340560135e-07, generator loss: 17.764612197875977\n",
      "Epoch: 80, discriminator loss: 1.477020816764707e-07, generator loss: 14.19766902923584\n",
      "Epoch: 81, discriminator loss: 6.418352995751775e-07, generator loss: 10.070782661437988\n",
      "Epoch: 82, discriminator loss: 7.368963679255103e-07, generator loss: 12.759660720825195\n",
      "Epoch: 83, discriminator loss: 7.945455422486702e-07, generator loss: 9.057867050170898\n",
      "Epoch: 84, discriminator loss: 4.501444550442102e-07, generator loss: 11.462471961975098\n",
      "Epoch: 85, discriminator loss: 6.869556727906456e-07, generator loss: 8.80947494506836\n",
      "Epoch: 86, discriminator loss: 4.769357246914296e-07, generator loss: 11.867064476013184\n",
      "Epoch: 87, discriminator loss: 5.76551656195079e-07, generator loss: 10.821420669555664\n",
      "Epoch: 88, discriminator loss: 6.789416602259735e-07, generator loss: 8.941429138183594\n",
      "Epoch: 89, discriminator loss: 5.497997221937112e-07, generator loss: 10.188576698303223\n",
      "Epoch: 90, discriminator loss: 9.804897445064853e-07, generator loss: 12.785019874572754\n",
      "Epoch: 91, discriminator loss: 9.58455643740308e-07, generator loss: 9.252659797668457\n",
      "Epoch: 92, discriminator loss: 1.0621048431858071e-06, generator loss: 10.130536079406738\n",
      "Epoch: 93, discriminator loss: 3.479601957678824e-07, generator loss: 11.37124252319336\n",
      "Epoch: 94, discriminator loss: 3.5923338259635784e-07, generator loss: 9.346864700317383\n",
      "Epoch: 95, discriminator loss: 2.3884771849225217e-07, generator loss: 10.80043888092041\n",
      "Epoch: 96, discriminator loss: 3.6091137189941946e-07, generator loss: 12.804841995239258\n",
      "Epoch: 97, discriminator loss: 3.279662053046195e-07, generator loss: 13.386772155761719\n",
      "Epoch: 98, discriminator loss: 3.784471687140467e-07, generator loss: 10.10771369934082\n",
      "Epoch: 99, discriminator loss: 1.9717596444479568e-07, generator loss: 14.715744018554688\n",
      "Epoch: 100, discriminator loss: 1.8348714547755662e-07, generator loss: 11.086715698242188\n",
      "Epoch: 101, discriminator loss: 1.9544862084330816e-07, generator loss: 13.31618881225586\n",
      "Epoch: 102, discriminator loss: 2.143132178389351e-07, generator loss: 11.74380874633789\n",
      "Epoch: 103, discriminator loss: 2.2001546540195704e-07, generator loss: 10.14150619506836\n",
      "Epoch: 104, discriminator loss: 1.8086551278884144e-07, generator loss: 10.469240188598633\n",
      "Epoch: 105, discriminator loss: 2.3113017277864856e-07, generator loss: 12.29189395904541\n",
      "Epoch: 106, discriminator loss: 2.3382800407034665e-07, generator loss: 13.21110725402832\n",
      "Epoch: 107, discriminator loss: 4.068239150001318e-07, generator loss: 9.913856506347656\n",
      "Epoch: 108, discriminator loss: 2.0144084089679382e-07, generator loss: 10.321309089660645\n",
      "Epoch: 109, discriminator loss: 3.8405565305765776e-07, generator loss: 14.133232116699219\n",
      "Epoch: 110, discriminator loss: 4.2911420905511477e-07, generator loss: 11.69917106628418\n",
      "Epoch: 111, discriminator loss: 4.504436788010935e-07, generator loss: 9.067741394042969\n",
      "Epoch: 112, discriminator loss: 1.6088976906303287e-07, generator loss: 15.100712776184082\n",
      "Epoch: 113, discriminator loss: 2.96381585940253e-07, generator loss: 12.587752342224121\n",
      "Epoch: 114, discriminator loss: 3.6523866242532677e-07, generator loss: 13.345577239990234\n",
      "Epoch: 115, discriminator loss: 2.298850603210667e-07, generator loss: 8.686946868896484\n",
      "Epoch: 116, discriminator loss: 6.843099242814787e-08, generator loss: 15.826400756835938\n",
      "Epoch: 117, discriminator loss: 1.3218647154644714e-07, generator loss: 11.810080528259277\n",
      "Epoch: 118, discriminator loss: 2.8794488571293186e-07, generator loss: 10.751667976379395\n",
      "Epoch: 119, discriminator loss: 2.129919920434986e-07, generator loss: 12.887519836425781\n",
      "Epoch: 120, discriminator loss: 1.770163322589724e-07, generator loss: 14.130623817443848\n",
      "Epoch: 121, discriminator loss: 1.2299234697366046e-07, generator loss: 11.812780380249023\n",
      "Epoch: 122, discriminator loss: 5.875097386365269e-08, generator loss: 11.9998140335083\n",
      "Epoch: 123, discriminator loss: 1.000487088731461e-07, generator loss: 12.981325149536133\n",
      "Epoch: 124, discriminator loss: 1.2945397998009867e-07, generator loss: 11.329305648803711\n",
      "Epoch: 125, discriminator loss: 5.5718125224757387e-08, generator loss: 12.352985382080078\n",
      "Epoch: 126, discriminator loss: 5.7905289452264697e-08, generator loss: 10.494803428649902\n",
      "Epoch: 127, discriminator loss: 2.6935390806670512e-08, generator loss: 14.408143997192383\n",
      "Epoch: 128, discriminator loss: 1.1929896004403417e-07, generator loss: 12.605467796325684\n",
      "Epoch: 129, discriminator loss: 1.1092512153254575e-07, generator loss: 15.319395065307617\n",
      "Epoch: 130, discriminator loss: 1.2942359717271756e-07, generator loss: 9.930179595947266\n",
      "Epoch: 131, discriminator loss: 3.775802426275732e-08, generator loss: 11.925649642944336\n",
      "Epoch: 132, discriminator loss: 5.0142478613679486e-08, generator loss: 10.896084785461426\n",
      "Epoch: 133, discriminator loss: 7.84167113465628e-08, generator loss: 14.551076889038086\n",
      "Epoch: 134, discriminator loss: 6.666969909474574e-08, generator loss: 9.260091781616211\n",
      "Epoch: 135, discriminator loss: 4.709999501528728e-08, generator loss: 17.993915557861328\n",
      "Epoch: 136, discriminator loss: 5.037998107582098e-08, generator loss: 12.67996883392334\n",
      "Epoch: 137, discriminator loss: 1.0985610998659467e-07, generator loss: 12.357029914855957\n",
      "Epoch: 138, discriminator loss: 5.690211679620916e-08, generator loss: 13.703483581542969\n",
      "Epoch: 139, discriminator loss: 5.487743237608811e-08, generator loss: 16.060441970825195\n",
      "Epoch: 140, discriminator loss: 4.4304062640776465e-08, generator loss: 13.224305152893066\n",
      "Epoch: 141, discriminator loss: 9.373424347813852e-08, generator loss: 7.901981353759766\n",
      "Epoch: 142, discriminator loss: 9.420338287213781e-09, generator loss: 25.61526107788086\n",
      "Epoch: 143, discriminator loss: 6.96527813204284e-09, generator loss: 20.87258529663086\n",
      "Epoch: 144, discriminator loss: 6.959720355581567e-09, generator loss: 15.893677711486816\n",
      "Epoch: 145, discriminator loss: 6.813088759827224e-08, generator loss: 14.212552070617676\n",
      "Epoch: 146, discriminator loss: 2.7537430113966366e-08, generator loss: 14.572209358215332\n",
      "Epoch: 147, discriminator loss: 4.8479886771701786e-08, generator loss: 15.848905563354492\n",
      "Epoch: 148, discriminator loss: 4.797792385602406e-08, generator loss: 16.35563087463379\n",
      "Epoch: 149, discriminator loss: 2.922237563041108e-08, generator loss: 10.355663299560547\n",
      "Epoch: 150, discriminator loss: 7.2477650547853045e-09, generator loss: 15.36866569519043\n",
      "Epoch: 151, discriminator loss: 1.9875376011668777e-08, generator loss: 11.977703094482422\n",
      "Epoch: 152, discriminator loss: 1.1919153664052828e-08, generator loss: 10.737443923950195\n",
      "Epoch: 153, discriminator loss: 6.03310201796603e-09, generator loss: 14.896086692810059\n",
      "Epoch: 154, discriminator loss: 3.557346417437657e-08, generator loss: 16.32005500793457\n",
      "Epoch: 155, discriminator loss: 2.5307119955186863e-08, generator loss: 7.777243614196777\n",
      "Epoch: 156, discriminator loss: 3.852607832754984e-08, generator loss: 24.04031753540039\n",
      "Epoch: 157, discriminator loss: 1.5136741637888917e-08, generator loss: 13.907482147216797\n",
      "Epoch: 158, discriminator loss: 4.780252638170168e-08, generator loss: 13.375635147094727\n",
      "Epoch: 159, discriminator loss: 3.882092158846717e-08, generator loss: 11.942010879516602\n",
      "Epoch: 160, discriminator loss: 1.2525575243671483e-08, generator loss: 19.04869842529297\n",
      "Epoch: 161, discriminator loss: 1.2188109188571161e-08, generator loss: 18.68746566772461\n",
      "Epoch: 162, discriminator loss: 1.4327707020811431e-08, generator loss: 5.770759582519531\n",
      "Epoch: 163, discriminator loss: 1.6962840021506054e-09, generator loss: 26.127399444580078\n",
      "Epoch: 164, discriminator loss: 1.2429443030370635e-09, generator loss: 19.248361587524414\n",
      "Epoch: 165, discriminator loss: 5.35792299416471e-09, generator loss: 15.109089851379395\n",
      "Epoch: 166, discriminator loss: 6.916927919320415e-09, generator loss: 10.567689895629883\n",
      "Epoch: 167, discriminator loss: 1.3444160229525437e-09, generator loss: 19.717514038085938\n",
      "Epoch: 168, discriminator loss: 3.914370605428985e-09, generator loss: 16.493621826171875\n",
      "Epoch: 169, discriminator loss: 1.2960384765392519e-08, generator loss: 10.784845352172852\n",
      "Epoch: 170, discriminator loss: 4.101827766334054e-09, generator loss: 19.134910583496094\n",
      "Epoch: 171, discriminator loss: 5.752428755556593e-09, generator loss: 6.612768650054932\n",
      "Epoch: 172, discriminator loss: 1.336943666885304e-09, generator loss: 30.477909088134766\n",
      "Epoch: 173, discriminator loss: 8.087419622881953e-10, generator loss: 24.385116577148438\n",
      "Epoch: 174, discriminator loss: 6.479883296606204e-10, generator loss: 23.230175018310547\n",
      "Epoch: 175, discriminator loss: 6.240117311762106e-10, generator loss: 15.444833755493164\n",
      "Epoch: 176, discriminator loss: 4.898232042194195e-09, generator loss: 16.662128448486328\n",
      "Epoch: 177, discriminator loss: 5.29282262462516e-09, generator loss: 15.135513305664062\n",
      "Epoch: 178, discriminator loss: 3.489564637249032e-09, generator loss: 12.739707946777344\n",
      "Epoch: 179, discriminator loss: 1.1698229940293459e-08, generator loss: 14.371112823486328\n",
      "Epoch: 180, discriminator loss: 9.811171430840204e-09, generator loss: 16.77010154724121\n",
      "Epoch: 181, discriminator loss: 5.062375851849765e-09, generator loss: 16.988101959228516\n",
      "Epoch: 182, discriminator loss: 8.960501673982435e-09, generator loss: 18.09514808654785\n",
      "Epoch: 183, discriminator loss: 5.30152899358427e-09, generator loss: 12.430848121643066\n",
      "Epoch: 184, discriminator loss: 1.7166361665488239e-09, generator loss: 17.161388397216797\n",
      "Epoch: 185, discriminator loss: 5.717331053034513e-09, generator loss: 17.414287567138672\n",
      "Epoch: 186, discriminator loss: 5.5964850531609045e-09, generator loss: 10.025815963745117\n",
      "Epoch: 187, discriminator loss: 9.718765792143813e-10, generator loss: 23.07598304748535\n",
      "Epoch: 188, discriminator loss: 8.216362590296455e-10, generator loss: 15.174072265625\n",
      "Epoch: 189, discriminator loss: 6.4643694841493016e-09, generator loss: 10.008655548095703\n",
      "Epoch: 190, discriminator loss: 7.669044288505233e-10, generator loss: 22.04262351989746\n",
      "Epoch: 191, discriminator loss: 9.57545154278705e-10, generator loss: 18.951522827148438\n",
      "Epoch: 192, discriminator loss: 7.63965868344485e-09, generator loss: 16.774625778198242\n",
      "Epoch: 193, discriminator loss: 7.881909347418059e-09, generator loss: 7.1722636222839355\n",
      "Epoch: 194, discriminator loss: 1.124927040407897e-09, generator loss: 32.53730010986328\n",
      "Epoch: 195, discriminator loss: 3.906949763710088e-10, generator loss: 31.03226089477539\n",
      "Epoch: 196, discriminator loss: 3.11806441777307e-10, generator loss: 28.74051856994629\n",
      "Epoch: 197, discriminator loss: 2.5864110853035527e-10, generator loss: 20.75039291381836\n",
      "Epoch: 198, discriminator loss: 9.54823331511534e-10, generator loss: 15.89933967590332\n",
      "Epoch: 199, discriminator loss: 1.730528054189051e-09, generator loss: 5.874396800994873\n",
      "Epoch: 200, discriminator loss: 4.662789043763382e-10, generator loss: 29.108070373535156\n",
      "Epoch: 201, discriminator loss: 2.1651201664862896e-10, generator loss: 22.27509880065918\n",
      "Epoch: 202, discriminator loss: 3.993653185929702e-10, generator loss: 19.822965621948242\n",
      "Epoch: 203, discriminator loss: 2.557796419111469e-09, generator loss: 15.377632141113281\n",
      "Epoch: 204, discriminator loss: 1.4562091088521356e-08, generator loss: 17.117660522460938\n",
      "Epoch: 205, discriminator loss: 6.140006281185606e-09, generator loss: 17.922191619873047\n",
      "Epoch: 206, discriminator loss: 6.50853504424731e-09, generator loss: 18.84482765197754\n",
      "Epoch: 207, discriminator loss: 2.830349510318797e-09, generator loss: 18.379398345947266\n",
      "Epoch: 208, discriminator loss: 5.977403461088215e-09, generator loss: 15.350410461425781\n",
      "Epoch: 209, discriminator loss: 4.316818014160617e-09, generator loss: 11.779092788696289\n",
      "Epoch: 210, discriminator loss: 4.617805693385435e-09, generator loss: 14.273815155029297\n",
      "Epoch: 211, discriminator loss: 1.3130175169351332e-08, generator loss: 11.9777193069458\n",
      "Epoch: 212, discriminator loss: 3.6514231638307137e-09, generator loss: 16.837543487548828\n",
      "Epoch: 213, discriminator loss: 1.0806630257320649e-08, generator loss: 17.114978790283203\n",
      "Epoch: 214, discriminator loss: 4.34713864905234e-09, generator loss: 14.931785583496094\n",
      "Epoch: 215, discriminator loss: 1.7613585034936818e-09, generator loss: 13.24193000793457\n",
      "Epoch: 216, discriminator loss: 6.091527726681534e-09, generator loss: 14.311878204345703\n",
      "Epoch: 217, discriminator loss: 1.1512040209993302e-09, generator loss: 13.570606231689453\n",
      "Epoch: 218, discriminator loss: 3.2804514660256245e-10, generator loss: 11.019021987915039\n",
      "Epoch: 219, discriminator loss: 1.0126612881578012e-09, generator loss: 13.401515007019043\n",
      "Epoch: 220, discriminator loss: 2.0269748102208496e-09, generator loss: 8.354318618774414\n",
      "Epoch: 221, discriminator loss: 2.842996726926117e-09, generator loss: 28.30956268310547\n",
      "Epoch: 222, discriminator loss: 8.220086833432561e-10, generator loss: 21.176311492919922\n",
      "Epoch: 223, discriminator loss: 1.2708142316242288e-09, generator loss: 14.831015586853027\n",
      "Epoch: 224, discriminator loss: 4.941641318367829e-09, generator loss: 16.10491943359375\n",
      "Epoch: 225, discriminator loss: 3.004478443813241e-09, generator loss: 10.546188354492188\n",
      "Epoch: 226, discriminator loss: 1.350775580277741e-08, generator loss: 16.96444320678711\n",
      "Epoch: 227, discriminator loss: 1.139733374344587e-08, generator loss: 5.52111291885376\n",
      "Epoch: 228, discriminator loss: 4.941910880518208e-09, generator loss: 33.47985076904297\n",
      "Epoch: 229, discriminator loss: 3.4119302938506735e-09, generator loss: 23.99496078491211\n",
      "Epoch: 230, discriminator loss: 2.950759636632938e-09, generator loss: 23.905607223510742\n",
      "Epoch: 231, discriminator loss: 2.5835773520554994e-09, generator loss: 23.041656494140625\n",
      "Epoch: 232, discriminator loss: 2.3486448341714095e-09, generator loss: 20.94872283935547\n",
      "Epoch: 233, discriminator loss: 2.4312298840811764e-09, generator loss: 18.629844665527344\n",
      "Epoch: 234, discriminator loss: 3.3329112802960026e-09, generator loss: 8.350119590759277\n",
      "Epoch: 235, discriminator loss: 2.238225960127238e-08, generator loss: 17.723491668701172\n",
      "Epoch: 236, discriminator loss: 2.255514530702385e-08, generator loss: 11.366293907165527\n",
      "Epoch: 237, discriminator loss: 1.7332228097188818e-08, generator loss: 16.168954849243164\n",
      "Epoch: 238, discriminator loss: 1.6572728966934847e-08, generator loss: 14.373357772827148\n",
      "Epoch: 239, discriminator loss: 1.4471726927922646e-08, generator loss: 6.702444553375244\n",
      "Epoch: 240, discriminator loss: 2.3982725139148897e-08, generator loss: 22.9575138092041\n",
      "Epoch: 241, discriminator loss: 1.4619169874663385e-08, generator loss: 19.151016235351562\n",
      "Epoch: 242, discriminator loss: 1.3910698370978025e-08, generator loss: 12.514532089233398\n",
      "Epoch: 243, discriminator loss: 5.524688262426025e-08, generator loss: 17.6644287109375\n",
      "Epoch: 244, discriminator loss: 3.524667491205946e-08, generator loss: 14.299962997436523\n",
      "Epoch: 245, discriminator loss: 3.1056796245820806e-08, generator loss: 16.293285369873047\n",
      "Epoch: 246, discriminator loss: 2.4229724004953823e-08, generator loss: 17.428741455078125\n",
      "Epoch: 247, discriminator loss: 2.649422903289178e-08, generator loss: 14.690261840820312\n",
      "Epoch: 248, discriminator loss: 1.6638276534308716e-08, generator loss: 17.136249542236328\n",
      "Epoch: 249, discriminator loss: 1.6656018786420645e-08, generator loss: 14.285362243652344\n",
      "Epoch: 250, discriminator loss: 4.973717082634721e-08, generator loss: 15.032485961914062\n",
      "Epoch: 251, discriminator loss: 1.6724408524737555e-08, generator loss: 15.598365783691406\n",
      "Epoch: 252, discriminator loss: 1.814681560574627e-08, generator loss: 10.611391067504883\n",
      "Epoch: 253, discriminator loss: 6.641682404051608e-08, generator loss: 17.432214736938477\n",
      "Epoch: 254, discriminator loss: 3.449057928150978e-08, generator loss: 14.140828132629395\n",
      "Epoch: 255, discriminator loss: 2.7427070392604946e-08, generator loss: 11.18740463256836\n",
      "Epoch: 256, discriminator loss: 1.1648604214542502e-07, generator loss: 20.639196395874023\n",
      "Epoch: 257, discriminator loss: 3.4148801120181815e-08, generator loss: 17.491802215576172\n",
      "Epoch: 258, discriminator loss: 2.6227239047216244e-08, generator loss: 10.029536247253418\n",
      "Epoch: 259, discriminator loss: 5.431690652812904e-08, generator loss: 19.813678741455078\n",
      "Epoch: 260, discriminator loss: 2.867807680217993e-08, generator loss: 14.591716766357422\n",
      "Epoch: 261, discriminator loss: 3.5168682188668754e-08, generator loss: 12.688692092895508\n",
      "Epoch: 262, discriminator loss: 3.3154517353750634e-08, generator loss: 14.960620880126953\n",
      "Epoch: 263, discriminator loss: 2.340095228703376e-08, generator loss: 13.299379348754883\n",
      "Epoch: 264, discriminator loss: 1.957506334804293e-08, generator loss: 15.084136962890625\n",
      "Epoch: 265, discriminator loss: 2.3006105465128712e-08, generator loss: 17.269500732421875\n",
      "Epoch: 266, discriminator loss: 1.6149254378206024e-08, generator loss: 10.531818389892578\n",
      "Epoch: 267, discriminator loss: 6.584205181070502e-08, generator loss: 29.469900131225586\n",
      "Epoch: 268, discriminator loss: 2.9476863616650917e-08, generator loss: 18.704124450683594\n",
      "Epoch: 269, discriminator loss: 2.5133816805578135e-08, generator loss: 14.49605941772461\n",
      "Epoch: 270, discriminator loss: 2.26815295434335e-08, generator loss: 16.67340850830078\n",
      "Epoch: 271, discriminator loss: 1.9998157796408123e-08, generator loss: 13.87342643737793\n",
      "Epoch: 272, discriminator loss: 2.280672006804707e-08, generator loss: 14.084689140319824\n",
      "Epoch: 273, discriminator loss: 1.9954223162699236e-08, generator loss: 15.627235412597656\n",
      "Epoch: 274, discriminator loss: 1.9890457281235285e-08, generator loss: 14.458673477172852\n",
      "Epoch: 275, discriminator loss: 2.0728984750917334e-08, generator loss: 11.405981063842773\n",
      "Epoch: 276, discriminator loss: 2.1765115931771106e-08, generator loss: 11.079693794250488\n",
      "Epoch: 277, discriminator loss: 4.0609975826555456e-08, generator loss: 18.924028396606445\n",
      "Epoch: 278, discriminator loss: 2.5442123074981282e-08, generator loss: 17.598012924194336\n",
      "Epoch: 279, discriminator loss: 2.249347375027355e-08, generator loss: 15.436949729919434\n",
      "Epoch: 280, discriminator loss: 2.4426356048934394e-08, generator loss: 16.26971435546875\n",
      "Epoch: 281, discriminator loss: 1.4201810394354197e-08, generator loss: 15.030509948730469\n",
      "Epoch: 282, discriminator loss: 1.1738904071023626e-08, generator loss: 13.829549789428711\n",
      "Epoch: 283, discriminator loss: 2.4614482896367917e-08, generator loss: 13.130966186523438\n",
      "Epoch: 284, discriminator loss: 2.024073886275346e-08, generator loss: 19.557750701904297\n",
      "Epoch: 285, discriminator loss: 1.4195084219181808e-08, generator loss: 10.772356033325195\n",
      "Epoch: 286, discriminator loss: 8.358686898191081e-08, generator loss: 16.56206512451172\n",
      "Epoch: 287, discriminator loss: 3.8072780483844326e-08, generator loss: 14.258727073669434\n",
      "Epoch: 288, discriminator loss: 3.0592826050224176e-08, generator loss: 11.049985885620117\n",
      "Epoch: 289, discriminator loss: 8.982980403970942e-08, generator loss: 17.171463012695312\n",
      "Epoch: 290, discriminator loss: 2.5452601803976904e-08, generator loss: 16.48015022277832\n",
      "Epoch: 291, discriminator loss: 1.767087276505208e-08, generator loss: 15.740118026733398\n",
      "Epoch: 292, discriminator loss: 3.956678185090823e-08, generator loss: 13.228693008422852\n",
      "Epoch: 293, discriminator loss: 4.666623354410149e-08, generator loss: 16.19304847717285\n",
      "Epoch: 294, discriminator loss: 2.2285018275169932e-08, generator loss: 7.528524398803711\n",
      "Epoch: 295, discriminator loss: 2.683460031960294e-08, generator loss: 26.450382232666016\n",
      "Epoch: 296, discriminator loss: 1.703426022459098e-08, generator loss: 22.551475524902344\n",
      "Epoch: 297, discriminator loss: 1.3696238809757233e-08, generator loss: 20.980449676513672\n",
      "Epoch: 298, discriminator loss: 1.2063989807131748e-08, generator loss: 20.314443588256836\n",
      "Epoch: 299, discriminator loss: 1.0911988646000736e-08, generator loss: 10.077666282653809\n",
      "Epoch: 300, discriminator loss: 4.762308662975556e-07, generator loss: 27.750568389892578\n",
      "Epoch: 301, discriminator loss: 2.9916549237896106e-08, generator loss: 7.81205415725708\n",
      "Epoch: 302, discriminator loss: 1.521140688964806e-07, generator loss: 31.186115264892578\n",
      "Epoch: 303, discriminator loss: 3.88124874461937e-08, generator loss: 19.783824920654297\n",
      "Epoch: 304, discriminator loss: 2.9044912253084476e-08, generator loss: 12.856792449951172\n",
      "Epoch: 305, discriminator loss: 2.8355989556416716e-08, generator loss: 13.624544143676758\n",
      "Epoch: 306, discriminator loss: 3.425472527851525e-08, generator loss: 13.435186386108398\n",
      "Epoch: 307, discriminator loss: 2.5854822283122303e-08, generator loss: 14.65614128112793\n",
      "Epoch: 308, discriminator loss: 2.2475299843449648e-08, generator loss: 5.852413177490234\n",
      "Epoch: 309, discriminator loss: 1.21732464108959e-08, generator loss: 28.250904083251953\n",
      "Epoch: 310, discriminator loss: 4.513351470336602e-09, generator loss: 20.457542419433594\n",
      "Epoch: 311, discriminator loss: 5.293891547353269e-09, generator loss: 11.821407318115234\n",
      "Epoch: 312, discriminator loss: 5.7107141238077475e-09, generator loss: 15.02673625946045\n",
      "Epoch: 313, discriminator loss: 1.479950029192878e-08, generator loss: 8.62460708618164\n",
      "Epoch: 314, discriminator loss: 1.043562924962771e-08, generator loss: 22.443147659301758\n",
      "Epoch: 315, discriminator loss: 7.250005040759788e-09, generator loss: 18.131078720092773\n",
      "Epoch: 316, discriminator loss: 1.4592037800298385e-08, generator loss: 10.37518310546875\n",
      "Epoch: 317, discriminator loss: 5.8323266216575576e-09, generator loss: 14.124618530273438\n",
      "Epoch: 318, discriminator loss: 1.726563603199338e-08, generator loss: 15.892756462097168\n",
      "Epoch: 319, discriminator loss: 2.56326302405796e-08, generator loss: 9.394183158874512\n",
      "Epoch: 320, discriminator loss: 3.0296385400419013e-09, generator loss: 15.822309494018555\n",
      "Epoch: 321, discriminator loss: 3.4778015134406814e-08, generator loss: 15.727130889892578\n",
      "Epoch: 322, discriminator loss: 6.543642516732007e-09, generator loss: 17.57383155822754\n",
      "Epoch: 323, discriminator loss: 1.0846508580186764e-08, generator loss: 16.039722442626953\n",
      "Epoch: 324, discriminator loss: 4.226807792662157e-09, generator loss: 15.873943328857422\n",
      "Epoch: 325, discriminator loss: 1.2945916338935604e-08, generator loss: 17.083168029785156\n",
      "Epoch: 326, discriminator loss: 8.317398325630165e-09, generator loss: 14.313401222229004\n",
      "Epoch: 327, discriminator loss: 3.825616268215981e-09, generator loss: 13.986330032348633\n",
      "Epoch: 328, discriminator loss: 7.307719318561112e-09, generator loss: 12.891195297241211\n",
      "Epoch: 329, discriminator loss: 2.9764193332226796e-09, generator loss: 15.502543449401855\n",
      "Epoch: 330, discriminator loss: 3.989518493341393e-09, generator loss: 10.212396621704102\n",
      "Epoch: 331, discriminator loss: 3.2310545350355824e-09, generator loss: 21.66897964477539\n",
      "Epoch: 332, discriminator loss: 1.852586972717063e-09, generator loss: 19.028074264526367\n",
      "Epoch: 333, discriminator loss: 4.206197612433016e-09, generator loss: 4.472532749176025\n",
      "Epoch: 334, discriminator loss: 1.716651543137715e-10, generator loss: 26.07192611694336\n",
      "Epoch: 335, discriminator loss: 1.220363948783998e-10, generator loss: 21.246131896972656\n",
      "Epoch: 336, discriminator loss: 7.431945059366285e-10, generator loss: 17.25855255126953\n",
      "Epoch: 337, discriminator loss: 7.581583361115918e-09, generator loss: 15.65030288696289\n",
      "Epoch: 338, discriminator loss: 2.23912999253173e-09, generator loss: 13.386207580566406\n",
      "Epoch: 339, discriminator loss: 7.258030843004804e-10, generator loss: 15.138263702392578\n",
      "Epoch: 340, discriminator loss: 1.5998277147488693e-09, generator loss: 17.784465789794922\n",
      "Epoch: 341, discriminator loss: 8.083411273673846e-09, generator loss: 15.654718399047852\n",
      "Epoch: 342, discriminator loss: 9.182745674962689e-10, generator loss: 14.44426155090332\n",
      "Epoch: 343, discriminator loss: 1.5130268149476933e-09, generator loss: 13.29848575592041\n",
      "Epoch: 344, discriminator loss: 7.017700309752684e-10, generator loss: 13.70072078704834\n",
      "Epoch: 345, discriminator loss: 3.120701030923101e-09, generator loss: 19.148757934570312\n",
      "Epoch: 346, discriminator loss: 3.205450793686282e-09, generator loss: 14.884994506835938\n",
      "Epoch: 347, discriminator loss: 1.296597718081216e-09, generator loss: 10.236692428588867\n",
      "Epoch: 348, discriminator loss: 2.2841208091595178e-10, generator loss: 20.386066436767578\n",
      "Epoch: 349, discriminator loss: 1.252520087646758e-09, generator loss: 15.940322875976562\n",
      "Epoch: 350, discriminator loss: 1.22314736117346e-09, generator loss: 8.829363822937012\n",
      "Epoch: 351, discriminator loss: 2.6839738764827814e-10, generator loss: 33.94599914550781\n",
      "Epoch: 352, discriminator loss: 9.373100906540088e-11, generator loss: 22.59905242919922\n",
      "Epoch: 353, discriminator loss: 2.4542387566661716e-10, generator loss: 13.923673629760742\n",
      "Epoch: 354, discriminator loss: 1.1092196050555003e-09, generator loss: 18.05050277709961\n",
      "Epoch: 355, discriminator loss: 2.718911096266652e-09, generator loss: 11.005084991455078\n",
      "Epoch: 356, discriminator loss: 1.1693357393482984e-09, generator loss: 19.768049240112305\n",
      "Epoch: 357, discriminator loss: 2.0056676319768485e-09, generator loss: 17.73639678955078\n",
      "Epoch: 358, discriminator loss: 6.3949001649632464e-09, generator loss: 9.98557186126709\n",
      "Epoch: 359, discriminator loss: 3.794804193102408e-10, generator loss: 13.2906494140625\n",
      "Epoch: 360, discriminator loss: 3.281261040655181e-09, generator loss: 12.890708923339844\n",
      "Epoch: 361, discriminator loss: 2.9147520508310265e-10, generator loss: 16.923141479492188\n",
      "Epoch: 362, discriminator loss: 1.6811165792773863e-09, generator loss: 12.820449829101562\n",
      "Epoch: 363, discriminator loss: 4.2811423850430685e-10, generator loss: 15.451930046081543\n",
      "Epoch: 364, discriminator loss: 1.48581025261052e-09, generator loss: 17.689043045043945\n",
      "Epoch: 365, discriminator loss: 2.359584527766856e-09, generator loss: 14.140205383300781\n",
      "Epoch: 366, discriminator loss: 8.918049632100633e-10, generator loss: 15.725090980529785\n",
      "Epoch: 367, discriminator loss: 1.7458223755539848e-09, generator loss: 12.770063400268555\n",
      "Epoch: 368, discriminator loss: 3.0021377050992726e-10, generator loss: 21.93568992614746\n"
     ]
    }
   ],
   "source": [
    "cgan.train(X, y, nb_epoch=1000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_generated = cgan.generate_samples(50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "fig, ax = plt.subplots(1, 20)\n",
    "img_dim = int(sqrt(X.shape[1]))\n",
    "X_img = X_generated.reshape(X_generated.shape[0], img_dim, -1)\n",
    "for ind in range(20):    \n",
    "    ax[ind].imshow(X_img[ind], cmap='gray_r')\n",
    "    ax[ind].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
