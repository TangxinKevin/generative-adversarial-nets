{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale, LabelBinarizer\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds = datasets.load_iris()\n",
    "X_train, y_train = minmax_scale(ds.data), LabelBinarizer().fit_transform(ds.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_X_samples = X_train.shape[0]\n",
    "n_X_features = X_train.shape[1]\n",
    "n_Z_features = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, n_X_features], name='X')\n",
    "D_W1 = tf.Variable(tf.random_uniform([n_X_features, 6]), name='D_W1')\n",
    "D_b1 = tf.Variable(tf.random_uniform([6]), name='D_b1')\n",
    "D_W2 = tf.Variable(tf.random_uniform([6, 1]), name='D_W2')\n",
    "D_b2 = tf.Variable(tf.random_uniform([1]), name='D_b2')\n",
    "D_parameters = [D_W1, D_W2, D_b1, D_b2]\n",
    "def D_logit(X):\n",
    "    D_h1 = tf.nn.tanh(tf.matmul(X, D_W1) + D_b1)\n",
    "    return tf.matmul(D_h1, D_W2) + D_b2\n",
    "\n",
    "Z = tf.placeholder(tf.float32, shape=[None, n_Z_features], name='Z')\n",
    "G_W1 = tf.Variable(tf.random_uniform([n_Z_features, 6]), name='G_W1')\n",
    "G_b1 = tf.Variable(tf.random_uniform([6]), name='G_b1')\n",
    "G_W2 = tf.Variable(tf.random_uniform([6, n_X_features]), name='G_W2')\n",
    "G_b2 = tf.Variable(tf.random_uniform([n_X_features]), name='G_b2')\n",
    "G_parameters = [G_W1, G_W2, G_b1, G_b2]\n",
    "def G_logit(Z):\n",
    "    G_h1 = tf.nn.tanh(tf.matmul(Z, G_W1) + G_b1)\n",
    "    return tf.matmul(G_h1, G_W2) + G_b2\n",
    "\n",
    "def sample_Z(n_samples, n_features):\n",
    "    return np.random.uniform(-1., 1., size=[n_samples, n_features]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D_logit_data = D_logit(X)\n",
    "D_logit_generated = D_logit(tf.nn.sigmoid(G_logit(Z)))\n",
    "\n",
    "D_loss_data = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_data, labels=tf.ones_like(D_logit_data)))\n",
    "D_loss_generated = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_generated, labels=tf.zeros_like(D_logit_generated)))\n",
    "D_loss = D_loss_data + D_loss_generated\n",
    "\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_generated, labels=tf.ones_like(D_logit_generated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=D_parameters)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=G_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 2.6091184616088867, generator loss: 0.07768820226192474\n",
      "Epoch: 1, discriminator loss: 2.5885040760040283, generator loss: 0.09816193580627441\n",
      "Epoch: 2, discriminator loss: 2.534332275390625, generator loss: 0.09133169800043106\n",
      "Epoch: 3, discriminator loss: 2.477931261062622, generator loss: 0.0961957573890686\n",
      "Epoch: 4, discriminator loss: 2.406693696975708, generator loss: 0.11907561868429184\n",
      "Epoch: 5, discriminator loss: 2.318744659423828, generator loss: 0.11431384086608887\n",
      "Epoch: 6, discriminator loss: 2.238431453704834, generator loss: 0.13139823079109192\n",
      "Epoch: 7, discriminator loss: 2.1927709579467773, generator loss: 0.14901892840862274\n",
      "Epoch: 8, discriminator loss: 2.1741034984588623, generator loss: 0.16706955432891846\n",
      "Epoch: 9, discriminator loss: 2.073620080947876, generator loss: 0.18236283957958221\n",
      "Epoch: 10, discriminator loss: 2.0146782398223877, generator loss: 0.18602879345417023\n",
      "Epoch: 11, discriminator loss: 1.974812626838684, generator loss: 0.19926448166370392\n",
      "Epoch: 12, discriminator loss: 1.942793846130371, generator loss: 0.225232794880867\n",
      "Epoch: 13, discriminator loss: 1.8334487676620483, generator loss: 0.23857946693897247\n",
      "Epoch: 14, discriminator loss: 1.8063366413116455, generator loss: 0.2600788176059723\n",
      "Epoch: 15, discriminator loss: 1.8124077320098877, generator loss: 0.2779454290866852\n",
      "Epoch: 16, discriminator loss: 1.730167269706726, generator loss: 0.29939502477645874\n",
      "Epoch: 17, discriminator loss: 1.7206896543502808, generator loss: 0.33102133870124817\n",
      "Epoch: 18, discriminator loss: 1.6692683696746826, generator loss: 0.35478726029396057\n",
      "Epoch: 19, discriminator loss: 1.6252208948135376, generator loss: 0.3741839528083801\n",
      "Epoch: 20, discriminator loss: 1.5545754432678223, generator loss: 0.39495426416397095\n",
      "Epoch: 21, discriminator loss: 1.5407143831253052, generator loss: 0.4234359860420227\n",
      "Epoch: 22, discriminator loss: 1.5114688873291016, generator loss: 0.45212286710739136\n",
      "Epoch: 23, discriminator loss: 1.5202040672302246, generator loss: 0.4787239134311676\n",
      "Epoch: 24, discriminator loss: 1.4657344818115234, generator loss: 0.5102699995040894\n",
      "Epoch: 25, discriminator loss: 1.4514474868774414, generator loss: 0.5333994626998901\n",
      "Epoch: 26, discriminator loss: 1.4240069389343262, generator loss: 0.558142364025116\n",
      "Epoch: 27, discriminator loss: 1.4062175750732422, generator loss: 0.5795953869819641\n",
      "Epoch: 28, discriminator loss: 1.394258737564087, generator loss: 0.5998722314834595\n",
      "Epoch: 29, discriminator loss: 1.37532377243042, generator loss: 0.620590090751648\n",
      "Epoch: 30, discriminator loss: 1.3680025339126587, generator loss: 0.6357539296150208\n",
      "Epoch: 31, discriminator loss: 1.351824164390564, generator loss: 0.6526536345481873\n",
      "Epoch: 32, discriminator loss: 1.3369593620300293, generator loss: 0.6611200571060181\n",
      "Epoch: 33, discriminator loss: 1.3533397912979126, generator loss: 0.6760028600692749\n",
      "Epoch: 34, discriminator loss: 1.3343193531036377, generator loss: 0.6869794726371765\n",
      "Epoch: 35, discriminator loss: 1.313124656677246, generator loss: 0.6973946690559387\n",
      "Epoch: 36, discriminator loss: 1.3352630138397217, generator loss: 0.7022836804389954\n",
      "Epoch: 37, discriminator loss: 1.3129444122314453, generator loss: 0.7076970934867859\n",
      "Epoch: 38, discriminator loss: 1.3263232707977295, generator loss: 0.7123392820358276\n",
      "Epoch: 39, discriminator loss: 1.3294827938079834, generator loss: 0.7154017686843872\n",
      "Epoch: 40, discriminator loss: 1.3073749542236328, generator loss: 0.7206844091415405\n",
      "Epoch: 41, discriminator loss: 1.254747748374939, generator loss: 0.7223941683769226\n",
      "Epoch: 42, discriminator loss: 1.2622320652008057, generator loss: 0.7362881898880005\n",
      "Epoch: 43, discriminator loss: 1.3150246143341064, generator loss: 0.728842556476593\n",
      "Epoch: 44, discriminator loss: 1.279557466506958, generator loss: 0.7429813146591187\n",
      "Epoch: 45, discriminator loss: 1.2777934074401855, generator loss: 0.7358533143997192\n",
      "Epoch: 46, discriminator loss: 1.2469902038574219, generator loss: 0.7220865488052368\n",
      "Epoch: 47, discriminator loss: 1.2511740922927856, generator loss: 0.721783459186554\n",
      "Epoch: 48, discriminator loss: 1.3065602779388428, generator loss: 0.7384710311889648\n",
      "Epoch: 49, discriminator loss: 1.3148999214172363, generator loss: 0.7179352045059204\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 10\n",
    "n_batches = int(n_X_samples / batch_size)\n",
    "for epoch in range(50):\n",
    "    X_epoch = X_train[np.random.permutation(range(n_X_samples))]\n",
    "    for batch_index in range(n_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        X_batch = X_epoch[start_index:end_index]\n",
    "        _, D_loss_value = sess.run([D_solver, D_loss], feed_dict={X: X_batch, Z: sample_Z(batch_size, n_Z_features)})\n",
    "        _, G_loss_value = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(batch_size, n_Z_features)})\n",
    "    print('Epoch: {}, discriminator loss: {}, generator loss: {}'.format(epoch, D_loss_value, G_loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_generated = tf.nn.sigmoid(G_logit(sample_Z(10, n_Z_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24513245,  0.54048389,  0.26786584,  0.87239295],\n",
       "       [ 0.28050452,  0.74936378,  0.51870602,  0.90157622],\n",
       "       [ 0.23966016,  0.62389594,  0.3239021 ,  0.92718315],\n",
       "       [ 0.29626796,  0.70880497,  0.40506876,  0.96753514],\n",
       "       [ 0.40586182,  0.64257467,  0.41495639,  0.89226812],\n",
       "       [ 0.27027369,  0.68068832,  0.3591398 ,  0.96063471],\n",
       "       [ 0.24787085,  0.78308898,  0.44295961,  0.98795205],\n",
       "       [ 0.37847656,  0.65923154,  0.40360287,  0.92068249],\n",
       "       [ 0.50756919,  0.46224296,  0.33950633,  0.23162611],\n",
       "       [ 0.31925187,  0.72746146,  0.43038481,  0.96071488]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(X_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
