{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds = datasets.load_iris()\n",
    "X_train, y_train = minmax_scale(ds.data), LabelBinarizer().fit_transform(ds.target)\n",
    "training_data = np.concatenate([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_X_samples = X_train.shape[0]\n",
    "n_X_features = X_train.shape[1]\n",
    "n_classes = y_train.shape[1]\n",
    "n_Z_features = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, n_X_features], name='X')\n",
    "D_W = tf.Variable(tf.random_uniform([n_X_features, 1]), name='D_W')\n",
    "D_b = tf.Variable(tf.random_uniform([1]), name='D_b')\n",
    "D_parameters = [D_W, D_b]\n",
    "def D_logit(X):\n",
    "    return tf.matmul(X, D_W) + D_b\n",
    "\n",
    "Z = tf.placeholder(tf.float32, shape=[None, n_Z_features], name='Z')\n",
    "G_W = tf.Variable(tf.random_uniform([n_Z_features, n_X_features]), name='G_W')\n",
    "G_b = tf.Variable(tf.random_uniform([n_X_features]), name='G_b')\n",
    "G_parameters = [G_W, G_b]\n",
    "def G_logit(Z):\n",
    "    return tf.matmul(Z, G_W) + G_b\n",
    "\n",
    "def sample_Z(n_samples, n_features):\n",
    "    return np.random.uniform(-1., 1., size=[n_samples, n_features]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D_logit_data = D_logit(X)\n",
    "D_logit_generated = D_logit(tf.nn.sigmoid(G_logit(Z)))\n",
    "\n",
    "D_loss_data = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_data, labels=tf.ones_like(D_logit_data)))\n",
    "D_loss_generated = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_generated, labels=tf.zeros_like(D_logit_generated)))\n",
    "D_loss = D_loss_data + D_loss_generated\n",
    "\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_generated, labels=tf.ones_like(D_logit_generated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=D_parameters)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=G_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, discriminator loss: 2.3044686317443848, generator loss: 0.13100770115852356\n",
      "Epoch: 1, discriminator loss: 2.1159284114837646, generator loss: 0.14579716324806213\n",
      "Epoch: 2, discriminator loss: 2.2519259452819824, generator loss: 0.13755899667739868\n",
      "Epoch: 3, discriminator loss: 2.256204605102539, generator loss: 0.14657092094421387\n",
      "Epoch: 4, discriminator loss: 2.1598048210144043, generator loss: 0.17542780935764313\n",
      "Epoch: 5, discriminator loss: 2.2429144382476807, generator loss: 0.150535449385643\n",
      "Epoch: 6, discriminator loss: 2.1370797157287598, generator loss: 0.1514035165309906\n",
      "Epoch: 7, discriminator loss: 2.2357523441314697, generator loss: 0.16957883536815643\n",
      "Epoch: 8, discriminator loss: 2.0795035362243652, generator loss: 0.17474763095378876\n",
      "Epoch: 9, discriminator loss: 2.0290422439575195, generator loss: 0.18798455595970154\n",
      "Epoch: 10, discriminator loss: 1.9893221855163574, generator loss: 0.20700402557849884\n",
      "Epoch: 11, discriminator loss: 1.92893648147583, generator loss: 0.18551981449127197\n",
      "Epoch: 12, discriminator loss: 2.0149364471435547, generator loss: 0.22437843680381775\n",
      "Epoch: 13, discriminator loss: 1.9059399366378784, generator loss: 0.20573274791240692\n",
      "Epoch: 14, discriminator loss: 1.8381462097167969, generator loss: 0.2310812920331955\n",
      "Epoch: 15, discriminator loss: 1.8598181009292603, generator loss: 0.2432716339826584\n",
      "Epoch: 16, discriminator loss: 1.8478033542633057, generator loss: 0.25877851247787476\n",
      "Epoch: 17, discriminator loss: 1.8144111633300781, generator loss: 0.2455275058746338\n",
      "Epoch: 18, discriminator loss: 1.7608551979064941, generator loss: 0.2501831352710724\n",
      "Epoch: 19, discriminator loss: 1.8045365810394287, generator loss: 0.26168397068977356\n",
      "Epoch: 20, discriminator loss: 1.7158989906311035, generator loss: 0.2774236798286438\n",
      "Epoch: 21, discriminator loss: 1.679551601409912, generator loss: 0.3025859296321869\n",
      "Epoch: 22, discriminator loss: 1.6529184579849243, generator loss: 0.3071346879005432\n",
      "Epoch: 23, discriminator loss: 1.70737624168396, generator loss: 0.3095566928386688\n",
      "Epoch: 24, discriminator loss: 1.6585131883621216, generator loss: 0.3209574520587921\n",
      "Epoch: 25, discriminator loss: 1.6811013221740723, generator loss: 0.33908921480178833\n",
      "Epoch: 26, discriminator loss: 1.6289727687835693, generator loss: 0.33773401379585266\n",
      "Epoch: 27, discriminator loss: 1.5929312705993652, generator loss: 0.36088627576828003\n",
      "Epoch: 28, discriminator loss: 1.5902984142303467, generator loss: 0.36668115854263306\n",
      "Epoch: 29, discriminator loss: 1.599543571472168, generator loss: 0.37435925006866455\n",
      "Epoch: 30, discriminator loss: 1.5738978385925293, generator loss: 0.3915384113788605\n",
      "Epoch: 31, discriminator loss: 1.5669912099838257, generator loss: 0.39927762746810913\n",
      "Epoch: 32, discriminator loss: 1.5650832653045654, generator loss: 0.4049098491668701\n",
      "Epoch: 33, discriminator loss: 1.522551417350769, generator loss: 0.42275339365005493\n",
      "Epoch: 34, discriminator loss: 1.4947885274887085, generator loss: 0.4276368021965027\n",
      "Epoch: 35, discriminator loss: 1.554760456085205, generator loss: 0.4333796501159668\n",
      "Epoch: 36, discriminator loss: 1.5478850603103638, generator loss: 0.44777965545654297\n",
      "Epoch: 37, discriminator loss: 1.5060503482818604, generator loss: 0.46417489647865295\n",
      "Epoch: 38, discriminator loss: 1.5170143842697144, generator loss: 0.46202945709228516\n",
      "Epoch: 39, discriminator loss: 1.4524693489074707, generator loss: 0.47231221199035645\n",
      "Epoch: 40, discriminator loss: 1.4868645668029785, generator loss: 0.48740559816360474\n",
      "Epoch: 41, discriminator loss: 1.4758682250976562, generator loss: 0.5029996633529663\n",
      "Epoch: 42, discriminator loss: 1.5073440074920654, generator loss: 0.49268651008605957\n",
      "Epoch: 43, discriminator loss: 1.515519380569458, generator loss: 0.5176230669021606\n",
      "Epoch: 44, discriminator loss: 1.4373202323913574, generator loss: 0.5146378874778748\n",
      "Epoch: 45, discriminator loss: 1.5025430917739868, generator loss: 0.5230966806411743\n",
      "Epoch: 46, discriminator loss: 1.4784893989562988, generator loss: 0.5457531213760376\n",
      "Epoch: 47, discriminator loss: 1.4764553308486938, generator loss: 0.5439123511314392\n",
      "Epoch: 48, discriminator loss: 1.4650015830993652, generator loss: 0.5629674792289734\n",
      "Epoch: 49, discriminator loss: 1.4580968618392944, generator loss: 0.5588710308074951\n",
      "Epoch: 50, discriminator loss: 1.4632418155670166, generator loss: 0.5785492062568665\n",
      "Epoch: 51, discriminator loss: 1.481947660446167, generator loss: 0.5862833857536316\n",
      "Epoch: 52, discriminator loss: 1.4346463680267334, generator loss: 0.5766512751579285\n",
      "Epoch: 53, discriminator loss: 1.4114940166473389, generator loss: 0.5917894840240479\n",
      "Epoch: 54, discriminator loss: 1.418344497680664, generator loss: 0.6101582646369934\n",
      "Epoch: 55, discriminator loss: 1.452908992767334, generator loss: 0.5922545194625854\n",
      "Epoch: 56, discriminator loss: 1.4476218223571777, generator loss: 0.6192256808280945\n",
      "Epoch: 57, discriminator loss: 1.4213426113128662, generator loss: 0.605256199836731\n",
      "Epoch: 58, discriminator loss: 1.4263601303100586, generator loss: 0.6055752635002136\n",
      "Epoch: 59, discriminator loss: 1.4505741596221924, generator loss: 0.6115005016326904\n",
      "Epoch: 60, discriminator loss: 1.4100382328033447, generator loss: 0.6139177083969116\n",
      "Epoch: 61, discriminator loss: 1.3979220390319824, generator loss: 0.6307311058044434\n",
      "Epoch: 62, discriminator loss: 1.4624874591827393, generator loss: 0.615784764289856\n",
      "Epoch: 63, discriminator loss: 1.4025459289550781, generator loss: 0.6231950521469116\n",
      "Epoch: 64, discriminator loss: 1.3393704891204834, generator loss: 0.626026451587677\n",
      "Epoch: 65, discriminator loss: 1.4101855754852295, generator loss: 0.6253389120101929\n",
      "Epoch: 66, discriminator loss: 1.3875527381896973, generator loss: 0.6578277349472046\n",
      "Epoch: 67, discriminator loss: 1.4473226070404053, generator loss: 0.6519193649291992\n",
      "Epoch: 68, discriminator loss: 1.4129040241241455, generator loss: 0.6750662922859192\n",
      "Epoch: 69, discriminator loss: 1.5036022663116455, generator loss: 0.6760160326957703\n",
      "Epoch: 70, discriminator loss: 1.3995506763458252, generator loss: 0.6249194145202637\n",
      "Epoch: 71, discriminator loss: 1.4372844696044922, generator loss: 0.6768718957901001\n",
      "Epoch: 72, discriminator loss: 1.4721159934997559, generator loss: 0.6584949493408203\n",
      "Epoch: 73, discriminator loss: 1.4446572065353394, generator loss: 0.691710352897644\n",
      "Epoch: 74, discriminator loss: 1.4721004962921143, generator loss: 0.6744721531867981\n",
      "Epoch: 75, discriminator loss: 1.3895461559295654, generator loss: 0.7089335322380066\n",
      "Epoch: 76, discriminator loss: 1.4518531560897827, generator loss: 0.680191159248352\n",
      "Epoch: 77, discriminator loss: 1.4292943477630615, generator loss: 0.6794909238815308\n",
      "Epoch: 78, discriminator loss: 1.3850059509277344, generator loss: 0.6998074650764465\n",
      "Epoch: 79, discriminator loss: 1.4173152446746826, generator loss: 0.6781576871871948\n",
      "Epoch: 80, discriminator loss: 1.40519118309021, generator loss: 0.688888430595398\n",
      "Epoch: 81, discriminator loss: 1.4464905261993408, generator loss: 0.6896004676818848\n",
      "Epoch: 82, discriminator loss: 1.4457283020019531, generator loss: 0.7026740908622742\n",
      "Epoch: 83, discriminator loss: 1.4602603912353516, generator loss: 0.7016737461090088\n",
      "Epoch: 84, discriminator loss: 1.3642823696136475, generator loss: 0.6948084831237793\n",
      "Epoch: 85, discriminator loss: 1.415700912475586, generator loss: 0.7098312973976135\n",
      "Epoch: 86, discriminator loss: 1.3950755596160889, generator loss: 0.692418098449707\n",
      "Epoch: 87, discriminator loss: 1.361990213394165, generator loss: 0.6902023553848267\n",
      "Epoch: 88, discriminator loss: 1.3720107078552246, generator loss: 0.7043420076370239\n",
      "Epoch: 89, discriminator loss: 1.419201374053955, generator loss: 0.7052411437034607\n",
      "Epoch: 90, discriminator loss: 1.381977915763855, generator loss: 0.6905244588851929\n",
      "Epoch: 91, discriminator loss: 1.3524454832077026, generator loss: 0.7185121774673462\n",
      "Epoch: 92, discriminator loss: 1.4087222814559937, generator loss: 0.7032486796379089\n",
      "Epoch: 93, discriminator loss: 1.4090684652328491, generator loss: 0.7010429501533508\n",
      "Epoch: 94, discriminator loss: 1.411273717880249, generator loss: 0.7051642537117004\n",
      "Epoch: 95, discriminator loss: 1.359839677810669, generator loss: 0.7205362915992737\n",
      "Epoch: 96, discriminator loss: 1.3748633861541748, generator loss: 0.7069864869117737\n",
      "Epoch: 97, discriminator loss: 1.402261734008789, generator loss: 0.7034174203872681\n",
      "Epoch: 98, discriminator loss: 1.3629647493362427, generator loss: 0.7023152112960815\n",
      "Epoch: 99, discriminator loss: 1.3494350910186768, generator loss: 0.7058718800544739\n",
      "Epoch: 100, discriminator loss: 1.3712821006774902, generator loss: 0.7055190801620483\n",
      "Epoch: 101, discriminator loss: 1.378981351852417, generator loss: 0.727802574634552\n",
      "Epoch: 102, discriminator loss: 1.3442198038101196, generator loss: 0.6965903043746948\n",
      "Epoch: 103, discriminator loss: 1.3784115314483643, generator loss: 0.7281922698020935\n",
      "Epoch: 104, discriminator loss: 1.3646591901779175, generator loss: 0.7265135645866394\n",
      "Epoch: 105, discriminator loss: 1.3684165477752686, generator loss: 0.7277860045433044\n",
      "Epoch: 106, discriminator loss: 1.3471171855926514, generator loss: 0.7115228772163391\n",
      "Epoch: 107, discriminator loss: 1.3267292976379395, generator loss: 0.7225782871246338\n",
      "Epoch: 108, discriminator loss: 1.3285983800888062, generator loss: 0.7115856409072876\n",
      "Epoch: 109, discriminator loss: 1.3725639581680298, generator loss: 0.7361922860145569\n",
      "Epoch: 110, discriminator loss: 1.3483905792236328, generator loss: 0.7115992307662964\n",
      "Epoch: 111, discriminator loss: 1.3434574604034424, generator loss: 0.710500955581665\n",
      "Epoch: 112, discriminator loss: 1.3176097869873047, generator loss: 0.7219136357307434\n",
      "Epoch: 113, discriminator loss: 1.3334335088729858, generator loss: 0.7248303890228271\n",
      "Epoch: 114, discriminator loss: 1.3541593551635742, generator loss: 0.7226428985595703\n",
      "Epoch: 115, discriminator loss: 1.3405320644378662, generator loss: 0.7413989305496216\n",
      "Epoch: 116, discriminator loss: 1.3311716318130493, generator loss: 0.7074260115623474\n",
      "Epoch: 117, discriminator loss: 1.3185513019561768, generator loss: 0.7308403253555298\n",
      "Epoch: 118, discriminator loss: 1.3294916152954102, generator loss: 0.7039207220077515\n",
      "Epoch: 119, discriminator loss: 1.3117215633392334, generator loss: 0.7342667579650879\n",
      "Epoch: 120, discriminator loss: 1.3200695514678955, generator loss: 0.7138192653656006\n",
      "Epoch: 121, discriminator loss: 1.3437104225158691, generator loss: 0.7287429571151733\n",
      "Epoch: 122, discriminator loss: 1.309136152267456, generator loss: 0.7396409511566162\n",
      "Epoch: 123, discriminator loss: 1.299867868423462, generator loss: 0.7155165076255798\n",
      "Epoch: 124, discriminator loss: 1.291407585144043, generator loss: 0.7210838198661804\n",
      "Epoch: 125, discriminator loss: 1.3224351406097412, generator loss: 0.7189292311668396\n",
      "Epoch: 126, discriminator loss: 1.3275396823883057, generator loss: 0.7151895761489868\n",
      "Epoch: 127, discriminator loss: 1.313765287399292, generator loss: 0.7194008827209473\n",
      "Epoch: 128, discriminator loss: 1.3066456317901611, generator loss: 0.7240037322044373\n",
      "Epoch: 129, discriminator loss: 1.3129040002822876, generator loss: 0.7208378911018372\n",
      "Epoch: 130, discriminator loss: 1.3180192708969116, generator loss: 0.6987388730049133\n",
      "Epoch: 131, discriminator loss: 1.3078749179840088, generator loss: 0.7015145421028137\n",
      "Epoch: 132, discriminator loss: 1.3180755376815796, generator loss: 0.7289682626724243\n",
      "Epoch: 133, discriminator loss: 1.3296427726745605, generator loss: 0.707105278968811\n",
      "Epoch: 134, discriminator loss: 1.336890459060669, generator loss: 0.7027795910835266\n",
      "Epoch: 135, discriminator loss: 1.317134976387024, generator loss: 0.7226629257202148\n",
      "Epoch: 136, discriminator loss: 1.305704116821289, generator loss: 0.7199459671974182\n",
      "Epoch: 137, discriminator loss: 1.327260136604309, generator loss: 0.7156910300254822\n",
      "Epoch: 138, discriminator loss: 1.3417527675628662, generator loss: 0.7146111726760864\n",
      "Epoch: 139, discriminator loss: 1.3138105869293213, generator loss: 0.7041773796081543\n",
      "Epoch: 140, discriminator loss: 1.3417234420776367, generator loss: 0.7078900337219238\n",
      "Epoch: 141, discriminator loss: 1.3178353309631348, generator loss: 0.6908189058303833\n",
      "Epoch: 142, discriminator loss: 1.3362390995025635, generator loss: 0.7071617245674133\n",
      "Epoch: 143, discriminator loss: 1.3075642585754395, generator loss: 0.6924521327018738\n",
      "Epoch: 144, discriminator loss: 1.3271572589874268, generator loss: 0.6944560408592224\n",
      "Epoch: 145, discriminator loss: 1.3480637073516846, generator loss: 0.687614917755127\n",
      "Epoch: 146, discriminator loss: 1.3598374128341675, generator loss: 0.6889452934265137\n",
      "Epoch: 147, discriminator loss: 1.3281837701797485, generator loss: 0.6893072128295898\n",
      "Epoch: 148, discriminator loss: 1.3481013774871826, generator loss: 0.6792572140693665\n",
      "Epoch: 149, discriminator loss: 1.3227903842926025, generator loss: 0.6955102682113647\n",
      "Epoch: 150, discriminator loss: 1.33359694480896, generator loss: 0.6780434846878052\n",
      "Epoch: 151, discriminator loss: 1.3649022579193115, generator loss: 0.7062973976135254\n",
      "Epoch: 152, discriminator loss: 1.3029495477676392, generator loss: 0.6684118509292603\n",
      "Epoch: 153, discriminator loss: 1.3653368949890137, generator loss: 0.6879264712333679\n",
      "Epoch: 154, discriminator loss: 1.3730905055999756, generator loss: 0.6743460893630981\n",
      "Epoch: 155, discriminator loss: 1.3442294597625732, generator loss: 0.6568059325218201\n",
      "Epoch: 156, discriminator loss: 1.3662601709365845, generator loss: 0.6791808605194092\n",
      "Epoch: 157, discriminator loss: 1.400309681892395, generator loss: 0.6818151473999023\n",
      "Epoch: 158, discriminator loss: 1.3436462879180908, generator loss: 0.6508342623710632\n",
      "Epoch: 159, discriminator loss: 1.369542121887207, generator loss: 0.682108998298645\n",
      "Epoch: 160, discriminator loss: 1.348253846168518, generator loss: 0.6754357218742371\n",
      "Epoch: 161, discriminator loss: 1.3400804996490479, generator loss: 0.6659565567970276\n",
      "Epoch: 162, discriminator loss: 1.3775031566619873, generator loss: 0.6581484079360962\n",
      "Epoch: 163, discriminator loss: 1.390740156173706, generator loss: 0.683643639087677\n",
      "Epoch: 164, discriminator loss: 1.4138164520263672, generator loss: 0.6605164408683777\n",
      "Epoch: 165, discriminator loss: 1.4017547369003296, generator loss: 0.6774609088897705\n",
      "Epoch: 166, discriminator loss: 1.379183053970337, generator loss: 0.6809480786323547\n",
      "Epoch: 167, discriminator loss: 1.4398210048675537, generator loss: 0.6806643009185791\n",
      "Epoch: 168, discriminator loss: 1.3221981525421143, generator loss: 0.6710912585258484\n",
      "Epoch: 169, discriminator loss: 1.3980216979980469, generator loss: 0.6711276173591614\n",
      "Epoch: 170, discriminator loss: 1.446479082107544, generator loss: 0.6692193746566772\n",
      "Epoch: 171, discriminator loss: 1.3836501836776733, generator loss: 0.6651128530502319\n",
      "Epoch: 172, discriminator loss: 1.417763113975525, generator loss: 0.6658865213394165\n",
      "Epoch: 173, discriminator loss: 1.3538634777069092, generator loss: 0.6522077322006226\n",
      "Epoch: 174, discriminator loss: 1.3998804092407227, generator loss: 0.6692800521850586\n",
      "Epoch: 175, discriminator loss: 1.4227101802825928, generator loss: 0.6825124025344849\n",
      "Epoch: 176, discriminator loss: 1.3865430355072021, generator loss: 0.6693021059036255\n",
      "Epoch: 177, discriminator loss: 1.438129186630249, generator loss: 0.6657996773719788\n",
      "Epoch: 178, discriminator loss: 1.4636454582214355, generator loss: 0.6728521585464478\n",
      "Epoch: 179, discriminator loss: 1.4221584796905518, generator loss: 0.6727285385131836\n",
      "Epoch: 180, discriminator loss: 1.3847589492797852, generator loss: 0.6585782766342163\n",
      "Epoch: 181, discriminator loss: 1.418531894683838, generator loss: 0.6745244264602661\n",
      "Epoch: 182, discriminator loss: 1.4078375101089478, generator loss: 0.6577509045600891\n",
      "Epoch: 183, discriminator loss: 1.5012874603271484, generator loss: 0.6720534563064575\n",
      "Epoch: 184, discriminator loss: 1.4180173873901367, generator loss: 0.6706358790397644\n",
      "Epoch: 185, discriminator loss: 1.4059383869171143, generator loss: 0.6676884889602661\n",
      "Epoch: 186, discriminator loss: 1.4037821292877197, generator loss: 0.6771291494369507\n",
      "Epoch: 187, discriminator loss: 1.4097707271575928, generator loss: 0.681429386138916\n",
      "Epoch: 188, discriminator loss: 1.383278727531433, generator loss: 0.6713245511054993\n",
      "Epoch: 189, discriminator loss: 1.3876333236694336, generator loss: 0.6788166165351868\n",
      "Epoch: 190, discriminator loss: 1.4339864253997803, generator loss: 0.6812301874160767\n",
      "Epoch: 191, discriminator loss: 1.3790920972824097, generator loss: 0.6816951036453247\n",
      "Epoch: 192, discriminator loss: 1.40370512008667, generator loss: 0.6645283699035645\n",
      "Epoch: 193, discriminator loss: 1.4274818897247314, generator loss: 0.6743795871734619\n",
      "Epoch: 194, discriminator loss: 1.4194133281707764, generator loss: 0.6741856932640076\n",
      "Epoch: 195, discriminator loss: 1.4040858745574951, generator loss: 0.6898361444473267\n",
      "Epoch: 196, discriminator loss: 1.4091987609863281, generator loss: 0.6688463687896729\n",
      "Epoch: 197, discriminator loss: 1.3960094451904297, generator loss: 0.6768373250961304\n",
      "Epoch: 198, discriminator loss: 1.426295518875122, generator loss: 0.7012215852737427\n",
      "Epoch: 199, discriminator loss: 1.3482398986816406, generator loss: 0.6698499917984009\n",
      "Epoch: 200, discriminator loss: 1.3930569887161255, generator loss: 0.6693893074989319\n",
      "Epoch: 201, discriminator loss: 1.4649279117584229, generator loss: 0.6930155754089355\n",
      "Epoch: 202, discriminator loss: 1.4558491706848145, generator loss: 0.6916383504867554\n",
      "Epoch: 203, discriminator loss: 1.4126633405685425, generator loss: 0.6890358924865723\n",
      "Epoch: 204, discriminator loss: 1.4148261547088623, generator loss: 0.6845923662185669\n",
      "Epoch: 205, discriminator loss: 1.436476230621338, generator loss: 0.7041780352592468\n",
      "Epoch: 206, discriminator loss: 1.3751444816589355, generator loss: 0.6871823668479919\n",
      "Epoch: 207, discriminator loss: 1.4106589555740356, generator loss: 0.6917328238487244\n",
      "Epoch: 208, discriminator loss: 1.4401025772094727, generator loss: 0.6876130104064941\n",
      "Epoch: 209, discriminator loss: 1.4104201793670654, generator loss: 0.6864697933197021\n",
      "Epoch: 210, discriminator loss: 1.3840807676315308, generator loss: 0.6912333369255066\n",
      "Epoch: 211, discriminator loss: 1.3974486589431763, generator loss: 0.7072864174842834\n",
      "Epoch: 212, discriminator loss: 1.4501515626907349, generator loss: 0.6963774561882019\n",
      "Epoch: 213, discriminator loss: 1.4244353771209717, generator loss: 0.679046630859375\n",
      "Epoch: 214, discriminator loss: 1.4330363273620605, generator loss: 0.6878906488418579\n",
      "Epoch: 215, discriminator loss: 1.3823875188827515, generator loss: 0.6869548559188843\n",
      "Epoch: 216, discriminator loss: 1.4046202898025513, generator loss: 0.6905328035354614\n",
      "Epoch: 217, discriminator loss: 1.4110053777694702, generator loss: 0.686322033405304\n",
      "Epoch: 218, discriminator loss: 1.4145435094833374, generator loss: 0.6859253644943237\n",
      "Epoch: 219, discriminator loss: 1.3985795974731445, generator loss: 0.6818895936012268\n",
      "Epoch: 220, discriminator loss: 1.3676660060882568, generator loss: 0.6856998205184937\n",
      "Epoch: 221, discriminator loss: 1.4064757823944092, generator loss: 0.6921220421791077\n",
      "Epoch: 222, discriminator loss: 1.4100323915481567, generator loss: 0.6957814693450928\n",
      "Epoch: 223, discriminator loss: 1.371731162071228, generator loss: 0.6916360855102539\n",
      "Epoch: 224, discriminator loss: 1.397796630859375, generator loss: 0.6925536394119263\n",
      "Epoch: 225, discriminator loss: 1.4056026935577393, generator loss: 0.6807352304458618\n",
      "Epoch: 226, discriminator loss: 1.4446868896484375, generator loss: 0.7027538418769836\n",
      "Epoch: 227, discriminator loss: 1.4025483131408691, generator loss: 0.6801351308822632\n",
      "Epoch: 228, discriminator loss: 1.4002190828323364, generator loss: 0.6869848966598511\n",
      "Epoch: 229, discriminator loss: 1.4117923974990845, generator loss: 0.6875678300857544\n",
      "Epoch: 230, discriminator loss: 1.410585641860962, generator loss: 0.6990437507629395\n",
      "Epoch: 231, discriminator loss: 1.4195280075073242, generator loss: 0.6739227175712585\n",
      "Epoch: 232, discriminator loss: 1.3700071573257446, generator loss: 0.6833730936050415\n",
      "Epoch: 233, discriminator loss: 1.4369982481002808, generator loss: 0.6782625317573547\n",
      "Epoch: 234, discriminator loss: 1.3959743976593018, generator loss: 0.6945363283157349\n",
      "Epoch: 235, discriminator loss: 1.415550947189331, generator loss: 0.680433452129364\n",
      "Epoch: 236, discriminator loss: 1.3953967094421387, generator loss: 0.6709729433059692\n",
      "Epoch: 237, discriminator loss: 1.4283521175384521, generator loss: 0.6716551780700684\n",
      "Epoch: 238, discriminator loss: 1.4162538051605225, generator loss: 0.6856268048286438\n",
      "Epoch: 239, discriminator loss: 1.4040889739990234, generator loss: 0.6666837930679321\n",
      "Epoch: 240, discriminator loss: 1.3961628675460815, generator loss: 0.667923092842102\n",
      "Epoch: 241, discriminator loss: 1.4250409603118896, generator loss: 0.6770065426826477\n",
      "Epoch: 242, discriminator loss: 1.4192973375320435, generator loss: 0.6720706224441528\n",
      "Epoch: 243, discriminator loss: 1.4093372821807861, generator loss: 0.6782231330871582\n",
      "Epoch: 244, discriminator loss: 1.4011523723602295, generator loss: 0.6767216920852661\n",
      "Epoch: 245, discriminator loss: 1.4157172441482544, generator loss: 0.671484649181366\n",
      "Epoch: 246, discriminator loss: 1.4214515686035156, generator loss: 0.6783637404441833\n",
      "Epoch: 247, discriminator loss: 1.407752275466919, generator loss: 0.6746836304664612\n",
      "Epoch: 248, discriminator loss: 1.4170255661010742, generator loss: 0.6848762631416321\n",
      "Epoch: 249, discriminator loss: 1.3978122472763062, generator loss: 0.6636289358139038\n",
      "Epoch: 250, discriminator loss: 1.4092319011688232, generator loss: 0.6757792830467224\n",
      "Epoch: 251, discriminator loss: 1.4286525249481201, generator loss: 0.6762613654136658\n",
      "Epoch: 252, discriminator loss: 1.419101595878601, generator loss: 0.6683265566825867\n",
      "Epoch: 253, discriminator loss: 1.3915200233459473, generator loss: 0.6745679974555969\n",
      "Epoch: 254, discriminator loss: 1.4283024072647095, generator loss: 0.6700183153152466\n",
      "Epoch: 255, discriminator loss: 1.4130812883377075, generator loss: 0.6769596338272095\n",
      "Epoch: 256, discriminator loss: 1.4087677001953125, generator loss: 0.6722819805145264\n",
      "Epoch: 257, discriminator loss: 1.4159867763519287, generator loss: 0.6675677299499512\n",
      "Epoch: 258, discriminator loss: 1.40444016456604, generator loss: 0.6669914126396179\n",
      "Epoch: 259, discriminator loss: 1.3862464427947998, generator loss: 0.6767621040344238\n",
      "Epoch: 260, discriminator loss: 1.4212632179260254, generator loss: 0.6684656143188477\n",
      "Epoch: 261, discriminator loss: 1.4078274965286255, generator loss: 0.6667917966842651\n",
      "Epoch: 262, discriminator loss: 1.3906197547912598, generator loss: 0.6611617207527161\n",
      "Epoch: 263, discriminator loss: 1.4111477136611938, generator loss: 0.668242335319519\n",
      "Epoch: 264, discriminator loss: 1.399865984916687, generator loss: 0.6676037311553955\n",
      "Epoch: 265, discriminator loss: 1.3932409286499023, generator loss: 0.667751669883728\n",
      "Epoch: 266, discriminator loss: 1.4077117443084717, generator loss: 0.6705418229103088\n",
      "Epoch: 267, discriminator loss: 1.3849047422409058, generator loss: 0.6692758798599243\n",
      "Epoch: 268, discriminator loss: 1.3831286430358887, generator loss: 0.6729379296302795\n",
      "Epoch: 269, discriminator loss: 1.3813042640686035, generator loss: 0.6739718317985535\n",
      "Epoch: 270, discriminator loss: 1.4035624265670776, generator loss: 0.6719176173210144\n",
      "Epoch: 271, discriminator loss: 1.3837776184082031, generator loss: 0.6751771569252014\n",
      "Epoch: 272, discriminator loss: 1.3632018566131592, generator loss: 0.6755858659744263\n",
      "Epoch: 273, discriminator loss: 1.3792747259140015, generator loss: 0.6788914799690247\n",
      "Epoch: 274, discriminator loss: 1.3690348863601685, generator loss: 0.6783909797668457\n",
      "Epoch: 275, discriminator loss: 1.3656196594238281, generator loss: 0.6804324984550476\n",
      "Epoch: 276, discriminator loss: 1.3735785484313965, generator loss: 0.6785939931869507\n",
      "Epoch: 277, discriminator loss: 1.3735005855560303, generator loss: 0.6806637644767761\n",
      "Epoch: 278, discriminator loss: 1.3734667301177979, generator loss: 0.6846094727516174\n",
      "Epoch: 279, discriminator loss: 1.3764349222183228, generator loss: 0.6799719929695129\n",
      "Epoch: 280, discriminator loss: 1.35811448097229, generator loss: 0.6844337582588196\n",
      "Epoch: 281, discriminator loss: 1.366481065750122, generator loss: 0.6847962737083435\n",
      "Epoch: 282, discriminator loss: 1.363572597503662, generator loss: 0.6885783076286316\n",
      "Epoch: 283, discriminator loss: 1.336050033569336, generator loss: 0.6854631900787354\n",
      "Epoch: 284, discriminator loss: 1.3535375595092773, generator loss: 0.6894415616989136\n",
      "Epoch: 285, discriminator loss: 1.3539819717407227, generator loss: 0.6844993829727173\n",
      "Epoch: 286, discriminator loss: 1.3412795066833496, generator loss: 0.6935745477676392\n",
      "Epoch: 287, discriminator loss: 1.3455066680908203, generator loss: 0.6911042928695679\n",
      "Epoch: 288, discriminator loss: 1.3583735227584839, generator loss: 0.685343861579895\n",
      "Epoch: 289, discriminator loss: 1.3619470596313477, generator loss: 0.6948457956314087\n",
      "Epoch: 290, discriminator loss: 1.3361320495605469, generator loss: 0.689068615436554\n",
      "Epoch: 291, discriminator loss: 1.3368456363677979, generator loss: 0.6867961883544922\n",
      "Epoch: 292, discriminator loss: 1.3470990657806396, generator loss: 0.6974124908447266\n",
      "Epoch: 293, discriminator loss: 1.322596549987793, generator loss: 0.6939328908920288\n",
      "Epoch: 294, discriminator loss: 1.3460716009140015, generator loss: 0.6957669258117676\n",
      "Epoch: 295, discriminator loss: 1.3593626022338867, generator loss: 0.7018372416496277\n",
      "Epoch: 296, discriminator loss: 1.3391388654708862, generator loss: 0.6949266195297241\n",
      "Epoch: 297, discriminator loss: 1.3218775987625122, generator loss: 0.6963120102882385\n",
      "Epoch: 298, discriminator loss: 1.3445274829864502, generator loss: 0.6984390020370483\n",
      "Epoch: 299, discriminator loss: 1.32853364944458, generator loss: 0.7064644694328308\n",
      "Epoch: 300, discriminator loss: 1.314813494682312, generator loss: 0.6966003179550171\n",
      "Epoch: 301, discriminator loss: 1.3281428813934326, generator loss: 0.6912606358528137\n",
      "Epoch: 302, discriminator loss: 1.338974952697754, generator loss: 0.7150335311889648\n",
      "Epoch: 303, discriminator loss: 1.369014859199524, generator loss: 0.7160220146179199\n",
      "Epoch: 304, discriminator loss: 1.336695909500122, generator loss: 0.6875032186508179\n",
      "Epoch: 305, discriminator loss: 1.3278779983520508, generator loss: 0.7119083404541016\n",
      "Epoch: 306, discriminator loss: 1.3435571193695068, generator loss: 0.7035888433456421\n",
      "Epoch: 307, discriminator loss: 1.3335256576538086, generator loss: 0.6963189244270325\n",
      "Epoch: 308, discriminator loss: 1.3281878232955933, generator loss: 0.6890779733657837\n",
      "Epoch: 309, discriminator loss: 1.360365867614746, generator loss: 0.7009531855583191\n",
      "Epoch: 310, discriminator loss: 1.3419620990753174, generator loss: 0.6912172436714172\n",
      "Epoch: 311, discriminator loss: 1.3418898582458496, generator loss: 0.7233759760856628\n",
      "Epoch: 312, discriminator loss: 1.3550293445587158, generator loss: 0.6649011969566345\n",
      "Epoch: 313, discriminator loss: 1.3482972383499146, generator loss: 0.6965045928955078\n",
      "Epoch: 314, discriminator loss: 1.3479564189910889, generator loss: 0.677428126335144\n",
      "Epoch: 315, discriminator loss: 1.3981852531433105, generator loss: 0.678226113319397\n",
      "Epoch: 316, discriminator loss: 1.3646032810211182, generator loss: 0.6875137090682983\n",
      "Epoch: 317, discriminator loss: 1.4123317003250122, generator loss: 0.6705857515335083\n",
      "Epoch: 318, discriminator loss: 1.3853634595870972, generator loss: 0.6995621919631958\n",
      "Epoch: 319, discriminator loss: 1.3681833744049072, generator loss: 0.6765546798706055\n",
      "Epoch: 320, discriminator loss: 1.3880163431167603, generator loss: 0.6918333768844604\n",
      "Epoch: 321, discriminator loss: 1.363657832145691, generator loss: 0.6845748424530029\n",
      "Epoch: 322, discriminator loss: 1.3863301277160645, generator loss: 0.6550750732421875\n",
      "Epoch: 323, discriminator loss: 1.4011437892913818, generator loss: 0.6708427667617798\n",
      "Epoch: 324, discriminator loss: 1.393046259880066, generator loss: 0.6901823878288269\n",
      "Epoch: 325, discriminator loss: 1.417490005493164, generator loss: 0.6783018112182617\n",
      "Epoch: 326, discriminator loss: 1.3471641540527344, generator loss: 0.6915286779403687\n",
      "Epoch: 327, discriminator loss: 1.431382417678833, generator loss: 0.6857067346572876\n",
      "Epoch: 328, discriminator loss: 1.4346874952316284, generator loss: 0.7040165662765503\n",
      "Epoch: 329, discriminator loss: 1.4156054258346558, generator loss: 0.6926825642585754\n",
      "Epoch: 330, discriminator loss: 1.3724076747894287, generator loss: 0.6777198314666748\n",
      "Epoch: 331, discriminator loss: 1.40346097946167, generator loss: 0.6693289279937744\n",
      "Epoch: 332, discriminator loss: 1.4226891994476318, generator loss: 0.6817371249198914\n",
      "Epoch: 333, discriminator loss: 1.3714141845703125, generator loss: 0.669442355632782\n",
      "Epoch: 334, discriminator loss: 1.4238271713256836, generator loss: 0.657913088798523\n",
      "Epoch: 335, discriminator loss: 1.396162748336792, generator loss: 0.7002498507499695\n",
      "Epoch: 336, discriminator loss: 1.4096410274505615, generator loss: 0.6979416012763977\n",
      "Epoch: 337, discriminator loss: 1.4612948894500732, generator loss: 0.6730655431747437\n",
      "Epoch: 338, discriminator loss: 1.4705219268798828, generator loss: 0.6908106803894043\n",
      "Epoch: 339, discriminator loss: 1.4332122802734375, generator loss: 0.6664994955062866\n",
      "Epoch: 340, discriminator loss: 1.384521484375, generator loss: 0.661892294883728\n",
      "Epoch: 341, discriminator loss: 1.4340778589248657, generator loss: 0.6734933257102966\n",
      "Epoch: 342, discriminator loss: 1.4007534980773926, generator loss: 0.6892821192741394\n",
      "Epoch: 343, discriminator loss: 1.4350473880767822, generator loss: 0.6812005043029785\n",
      "Epoch: 344, discriminator loss: 1.4164376258850098, generator loss: 0.691524863243103\n",
      "Epoch: 345, discriminator loss: 1.4279453754425049, generator loss: 0.6891127824783325\n",
      "Epoch: 346, discriminator loss: 1.4281764030456543, generator loss: 0.6983164548873901\n",
      "Epoch: 347, discriminator loss: 1.4249112606048584, generator loss: 0.6966468095779419\n",
      "Epoch: 348, discriminator loss: 1.4047307968139648, generator loss: 0.6964717507362366\n",
      "Epoch: 349, discriminator loss: 1.418897032737732, generator loss: 0.6802393794059753\n",
      "Epoch: 350, discriminator loss: 1.4057435989379883, generator loss: 0.6901691555976868\n",
      "Epoch: 351, discriminator loss: 1.4160950183868408, generator loss: 0.6852571368217468\n",
      "Epoch: 352, discriminator loss: 1.3913207054138184, generator loss: 0.6846820116043091\n",
      "Epoch: 353, discriminator loss: 1.4300830364227295, generator loss: 0.6900953054428101\n",
      "Epoch: 354, discriminator loss: 1.413684368133545, generator loss: 0.689461350440979\n",
      "Epoch: 355, discriminator loss: 1.4239211082458496, generator loss: 0.6905343532562256\n",
      "Epoch: 356, discriminator loss: 1.3914604187011719, generator loss: 0.682124674320221\n",
      "Epoch: 357, discriminator loss: 1.4186508655548096, generator loss: 0.6992868185043335\n",
      "Epoch: 358, discriminator loss: 1.4150733947753906, generator loss: 0.6902666687965393\n",
      "Epoch: 359, discriminator loss: 1.4034756422042847, generator loss: 0.7012524604797363\n",
      "Epoch: 360, discriminator loss: 1.4208667278289795, generator loss: 0.6948203444480896\n",
      "Epoch: 361, discriminator loss: 1.4222846031188965, generator loss: 0.7058857679367065\n",
      "Epoch: 362, discriminator loss: 1.4056414365768433, generator loss: 0.7034961581230164\n",
      "Epoch: 363, discriminator loss: 1.395695447921753, generator loss: 0.7114243507385254\n",
      "Epoch: 364, discriminator loss: 1.3969717025756836, generator loss: 0.7027350068092346\n",
      "Epoch: 365, discriminator loss: 1.4115138053894043, generator loss: 0.7071644067764282\n",
      "Epoch: 366, discriminator loss: 1.4150748252868652, generator loss: 0.7157198190689087\n",
      "Epoch: 367, discriminator loss: 1.4082915782928467, generator loss: 0.7082789540290833\n",
      "Epoch: 368, discriminator loss: 1.374016523361206, generator loss: 0.707548975944519\n",
      "Epoch: 369, discriminator loss: 1.3813045024871826, generator loss: 0.7132447957992554\n",
      "Epoch: 370, discriminator loss: 1.3860375881195068, generator loss: 0.7080780863761902\n",
      "Epoch: 371, discriminator loss: 1.3916491270065308, generator loss: 0.7013761401176453\n",
      "Epoch: 372, discriminator loss: 1.3812328577041626, generator loss: 0.712164044380188\n",
      "Epoch: 373, discriminator loss: 1.3807917833328247, generator loss: 0.7133095860481262\n",
      "Epoch: 374, discriminator loss: 1.3888001441955566, generator loss: 0.712833046913147\n",
      "Epoch: 375, discriminator loss: 1.384131669998169, generator loss: 0.7082204222679138\n",
      "Epoch: 376, discriminator loss: 1.386638879776001, generator loss: 0.7165414690971375\n",
      "Epoch: 377, discriminator loss: 1.3948242664337158, generator loss: 0.7137423753738403\n",
      "Epoch: 378, discriminator loss: 1.3718823194503784, generator loss: 0.7102428674697876\n",
      "Epoch: 379, discriminator loss: 1.3761699199676514, generator loss: 0.7077764272689819\n",
      "Epoch: 380, discriminator loss: 1.384688138961792, generator loss: 0.7116490006446838\n",
      "Epoch: 381, discriminator loss: 1.3767107725143433, generator loss: 0.7154642939567566\n",
      "Epoch: 382, discriminator loss: 1.376475214958191, generator loss: 0.7125283479690552\n",
      "Epoch: 383, discriminator loss: 1.3821552991867065, generator loss: 0.7119708061218262\n",
      "Epoch: 384, discriminator loss: 1.3860664367675781, generator loss: 0.71382075548172\n",
      "Epoch: 385, discriminator loss: 1.3823144435882568, generator loss: 0.7190216183662415\n",
      "Epoch: 386, discriminator loss: 1.3667383193969727, generator loss: 0.7134537696838379\n",
      "Epoch: 387, discriminator loss: 1.3745976686477661, generator loss: 0.6973214745521545\n",
      "Epoch: 388, discriminator loss: 1.3834589719772339, generator loss: 0.709992527961731\n",
      "Epoch: 389, discriminator loss: 1.378007173538208, generator loss: 0.6950691938400269\n",
      "Epoch: 390, discriminator loss: 1.3783531188964844, generator loss: 0.7184528112411499\n",
      "Epoch: 391, discriminator loss: 1.3699276447296143, generator loss: 0.7100943326950073\n",
      "Epoch: 392, discriminator loss: 1.3885157108306885, generator loss: 0.7067369818687439\n",
      "Epoch: 393, discriminator loss: 1.3657636642456055, generator loss: 0.6997724771499634\n",
      "Epoch: 394, discriminator loss: 1.3670045137405396, generator loss: 0.7120216488838196\n",
      "Epoch: 395, discriminator loss: 1.3650075197219849, generator loss: 0.7061271071434021\n",
      "Epoch: 396, discriminator loss: 1.3938653469085693, generator loss: 0.7108367681503296\n",
      "Epoch: 397, discriminator loss: 1.3781180381774902, generator loss: 0.7017431259155273\n",
      "Epoch: 398, discriminator loss: 1.3707854747772217, generator loss: 0.7099148035049438\n",
      "Epoch: 399, discriminator loss: 1.3751344680786133, generator loss: 0.7113171815872192\n",
      "Epoch: 400, discriminator loss: 1.3718922138214111, generator loss: 0.6843312978744507\n",
      "Epoch: 401, discriminator loss: 1.3743221759796143, generator loss: 0.698268473148346\n",
      "Epoch: 402, discriminator loss: 1.3707746267318726, generator loss: 0.6925761699676514\n",
      "Epoch: 403, discriminator loss: 1.3622069358825684, generator loss: 0.6966239213943481\n",
      "Epoch: 404, discriminator loss: 1.390667200088501, generator loss: 0.706458330154419\n",
      "Epoch: 405, discriminator loss: 1.3894767761230469, generator loss: 0.6985105276107788\n",
      "Epoch: 406, discriminator loss: 1.3817636966705322, generator loss: 0.7046465873718262\n",
      "Epoch: 407, discriminator loss: 1.356959581375122, generator loss: 0.7013863325119019\n",
      "Epoch: 408, discriminator loss: 1.3685569763183594, generator loss: 0.6858320236206055\n",
      "Epoch: 409, discriminator loss: 1.411919355392456, generator loss: 0.7018598318099976\n",
      "Epoch: 410, discriminator loss: 1.36191725730896, generator loss: 0.6976500153541565\n",
      "Epoch: 411, discriminator loss: 1.3672174215316772, generator loss: 0.7034456133842468\n",
      "Epoch: 412, discriminator loss: 1.3927441835403442, generator loss: 0.7080494165420532\n",
      "Epoch: 413, discriminator loss: 1.366624355316162, generator loss: 0.7149026393890381\n",
      "Epoch: 414, discriminator loss: 1.3516931533813477, generator loss: 0.7020257115364075\n",
      "Epoch: 415, discriminator loss: 1.39732027053833, generator loss: 0.7110005617141724\n",
      "Epoch: 416, discriminator loss: 1.3506176471710205, generator loss: 0.6861238479614258\n",
      "Epoch: 417, discriminator loss: 1.3635053634643555, generator loss: 0.7034178972244263\n",
      "Epoch: 418, discriminator loss: 1.387727975845337, generator loss: 0.7045183181762695\n",
      "Epoch: 419, discriminator loss: 1.3592615127563477, generator loss: 0.6930597424507141\n",
      "Epoch: 420, discriminator loss: 1.3742977380752563, generator loss: 0.7070651650428772\n",
      "Epoch: 421, discriminator loss: 1.358773946762085, generator loss: 0.6922179460525513\n",
      "Epoch: 422, discriminator loss: 1.35667085647583, generator loss: 0.7042424082756042\n",
      "Epoch: 423, discriminator loss: 1.370826244354248, generator loss: 0.7002929449081421\n",
      "Epoch: 424, discriminator loss: 1.369471549987793, generator loss: 0.7057476043701172\n",
      "Epoch: 425, discriminator loss: 1.3746399879455566, generator loss: 0.7003577351570129\n",
      "Epoch: 426, discriminator loss: 1.402808666229248, generator loss: 0.6921559572219849\n",
      "Epoch: 427, discriminator loss: 1.356082797050476, generator loss: 0.7119900584220886\n",
      "Epoch: 428, discriminator loss: 1.3675822019577026, generator loss: 0.6941704154014587\n",
      "Epoch: 429, discriminator loss: 1.3975286483764648, generator loss: 0.6918083429336548\n",
      "Epoch: 430, discriminator loss: 1.406620740890503, generator loss: 0.7024839520454407\n",
      "Epoch: 431, discriminator loss: 1.3942816257476807, generator loss: 0.6963633298873901\n",
      "Epoch: 432, discriminator loss: 1.3964402675628662, generator loss: 0.7013106346130371\n",
      "Epoch: 433, discriminator loss: 1.374922275543213, generator loss: 0.6937892436981201\n",
      "Epoch: 434, discriminator loss: 1.3727519512176514, generator loss: 0.6955589056015015\n",
      "Epoch: 435, discriminator loss: 1.366433024406433, generator loss: 0.6976717710494995\n",
      "Epoch: 436, discriminator loss: 1.4105572700500488, generator loss: 0.6967133283615112\n",
      "Epoch: 437, discriminator loss: 1.3780226707458496, generator loss: 0.6882022023200989\n",
      "Epoch: 438, discriminator loss: 1.3972994089126587, generator loss: 0.6942203640937805\n",
      "Epoch: 439, discriminator loss: 1.3890949487686157, generator loss: 0.6967613697052002\n",
      "Epoch: 440, discriminator loss: 1.4156105518341064, generator loss: 0.6971789598464966\n",
      "Epoch: 441, discriminator loss: 1.390218734741211, generator loss: 0.6915923953056335\n",
      "Epoch: 442, discriminator loss: 1.3790720701217651, generator loss: 0.6942917704582214\n",
      "Epoch: 443, discriminator loss: 1.371000051498413, generator loss: 0.6871888041496277\n",
      "Epoch: 444, discriminator loss: 1.378618836402893, generator loss: 0.6911650896072388\n",
      "Epoch: 445, discriminator loss: 1.36260986328125, generator loss: 0.6921685934066772\n",
      "Epoch: 446, discriminator loss: 1.366955280303955, generator loss: 0.6938877105712891\n",
      "Epoch: 447, discriminator loss: 1.3886162042617798, generator loss: 0.6929332613945007\n",
      "Epoch: 448, discriminator loss: 1.384840726852417, generator loss: 0.6935568451881409\n",
      "Epoch: 449, discriminator loss: 1.3889877796173096, generator loss: 0.689348578453064\n",
      "Epoch: 450, discriminator loss: 1.384537935256958, generator loss: 0.6875127553939819\n",
      "Epoch: 451, discriminator loss: 1.4158976078033447, generator loss: 0.6977920532226562\n",
      "Epoch: 452, discriminator loss: 1.3905105590820312, generator loss: 0.6917346715927124\n",
      "Epoch: 453, discriminator loss: 1.3927028179168701, generator loss: 0.6853764653205872\n",
      "Epoch: 454, discriminator loss: 1.3911596536636353, generator loss: 0.6974189877510071\n",
      "Epoch: 455, discriminator loss: 1.4046101570129395, generator loss: 0.6973593235015869\n",
      "Epoch: 456, discriminator loss: 1.3883662223815918, generator loss: 0.6931695342063904\n",
      "Epoch: 457, discriminator loss: 1.4020473957061768, generator loss: 0.6829816102981567\n",
      "Epoch: 458, discriminator loss: 1.395168662071228, generator loss: 0.6821226477622986\n",
      "Epoch: 459, discriminator loss: 1.4091898202896118, generator loss: 0.6902008056640625\n",
      "Epoch: 460, discriminator loss: 1.3929896354675293, generator loss: 0.6795004606246948\n",
      "Epoch: 461, discriminator loss: 1.4126735925674438, generator loss: 0.6778304576873779\n",
      "Epoch: 462, discriminator loss: 1.4060224294662476, generator loss: 0.6848205327987671\n",
      "Epoch: 463, discriminator loss: 1.396306037902832, generator loss: 0.7003921270370483\n",
      "Epoch: 464, discriminator loss: 1.3925275802612305, generator loss: 0.6944009065628052\n",
      "Epoch: 465, discriminator loss: 1.3915587663650513, generator loss: 0.6839534640312195\n",
      "Epoch: 466, discriminator loss: 1.3879694938659668, generator loss: 0.6888436079025269\n",
      "Epoch: 467, discriminator loss: 1.4073394536972046, generator loss: 0.6869436502456665\n",
      "Epoch: 468, discriminator loss: 1.4003180265426636, generator loss: 0.7008215188980103\n",
      "Epoch: 469, discriminator loss: 1.3801703453063965, generator loss: 0.7012224197387695\n",
      "Epoch: 470, discriminator loss: 1.398160457611084, generator loss: 0.6984713673591614\n",
      "Epoch: 471, discriminator loss: 1.3971611261367798, generator loss: 0.6896392703056335\n",
      "Epoch: 472, discriminator loss: 1.3922555446624756, generator loss: 0.6868866682052612\n",
      "Epoch: 473, discriminator loss: 1.3879046440124512, generator loss: 0.685142993927002\n",
      "Epoch: 474, discriminator loss: 1.3889145851135254, generator loss: 0.6890881657600403\n",
      "Epoch: 475, discriminator loss: 1.3894014358520508, generator loss: 0.6983004808425903\n",
      "Epoch: 476, discriminator loss: 1.3733065128326416, generator loss: 0.7107226848602295\n",
      "Epoch: 477, discriminator loss: 1.3974041938781738, generator loss: 0.6947424411773682\n",
      "Epoch: 478, discriminator loss: 1.388754963874817, generator loss: 0.6911013722419739\n",
      "Epoch: 479, discriminator loss: 1.3852131366729736, generator loss: 0.7048646807670593\n",
      "Epoch: 480, discriminator loss: 1.3870534896850586, generator loss: 0.6745933294296265\n",
      "Epoch: 481, discriminator loss: 1.3968219757080078, generator loss: 0.6876956820487976\n",
      "Epoch: 482, discriminator loss: 1.4161827564239502, generator loss: 0.6949102878570557\n",
      "Epoch: 483, discriminator loss: 1.3920505046844482, generator loss: 0.6832801699638367\n",
      "Epoch: 484, discriminator loss: 1.3904949426651, generator loss: 0.6931085586547852\n",
      "Epoch: 485, discriminator loss: 1.3734508752822876, generator loss: 0.6915225982666016\n",
      "Epoch: 486, discriminator loss: 1.3719979524612427, generator loss: 0.7089983820915222\n",
      "Epoch: 487, discriminator loss: 1.402300477027893, generator loss: 0.6888241767883301\n",
      "Epoch: 488, discriminator loss: 1.405074119567871, generator loss: 0.679090142250061\n",
      "Epoch: 489, discriminator loss: 1.414236307144165, generator loss: 0.7048708200454712\n",
      "Epoch: 490, discriminator loss: 1.397640585899353, generator loss: 0.6999672055244446\n",
      "Epoch: 491, discriminator loss: 1.3840817213058472, generator loss: 0.701611340045929\n",
      "Epoch: 492, discriminator loss: 1.3708698749542236, generator loss: 0.7017084360122681\n",
      "Epoch: 493, discriminator loss: 1.4170215129852295, generator loss: 0.6818742752075195\n",
      "Epoch: 494, discriminator loss: 1.4350018501281738, generator loss: 0.6885312795639038\n",
      "Epoch: 495, discriminator loss: 1.3782598972320557, generator loss: 0.7022333145141602\n",
      "Epoch: 496, discriminator loss: 1.3210159540176392, generator loss: 0.6920038461685181\n",
      "Epoch: 497, discriminator loss: 1.414747714996338, generator loss: 0.6892246603965759\n",
      "Epoch: 498, discriminator loss: 1.3975825309753418, generator loss: 0.6869887113571167\n",
      "Epoch: 499, discriminator loss: 1.3791719675064087, generator loss: 0.6908235549926758\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 10\n",
    "n_batches = int(n_X_samples / batch_size)\n",
    "for epoch in range(500):\n",
    "    X_epoch = X_train[np.random.permutation(range(n_X_samples))]\n",
    "    for batch_index in range(n_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        X_batch = X_epoch[start_index:end_index]\n",
    "        _, D_loss_value = sess.run([D_solver, D_loss], feed_dict={X: X_batch, Z: sample_Z(batch_size, n_Z_features)})\n",
    "        _, G_loss_value = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(batch_size, n_Z_features)})\n",
    "    print('Epoch: {}, discriminator loss: {}, generator loss: {}'.format(epoch, D_loss_value, G_loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_generated = tf.nn.sigmoid(G_logit(sample_Z(10, n_Z_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3915219 ,  0.19932577,  0.42266262,  0.39455956],\n",
       "       [ 0.65022224,  0.53885132,  0.84583104,  0.73324174],\n",
       "       [ 0.28660852,  0.23787358,  0.4005262 ,  0.43196619],\n",
       "       [ 0.40539929,  0.32836661,  0.56841642,  0.64633626],\n",
       "       [ 0.41151437,  0.39764419,  0.59860539,  0.50286949],\n",
       "       [ 0.21944591,  0.22783263,  0.304773  ,  0.38222897],\n",
       "       [ 0.33324188,  0.26477072,  0.44035298,  0.16930234],\n",
       "       [ 0.51923728,  0.38239533,  0.6946941 ,  0.63129276],\n",
       "       [ 0.34728634,  0.27378714,  0.43921995,  0.11173232],\n",
       "       [ 0.340556  ,  0.32398549,  0.42209229,  0.36254349]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(X_generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
